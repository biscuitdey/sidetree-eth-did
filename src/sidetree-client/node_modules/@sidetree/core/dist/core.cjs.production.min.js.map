{"version":3,"file":"core.cjs.production.min.js","sources":["../node_modules/regenerator-runtime/runtime.js","../src/util/ArrayMethods.ts","../src/util/Compressor.ts","../src/DocumentComposer.ts","../src/util/JsonAsync.ts","../src/OperationUtils.ts","../src/CreateOperation.ts","../src/util/Jwk.ts","../src/util/Jws.ts","../src/DeactivateOperation.ts","../src/RecoverOperation.ts","../src/write/AnchorFile.ts","../src/write/BatchScheduler.ts","../src/write/ChunkFile.ts","../src/DownloadManager.ts","../src/UpdateOperation.ts","../src/write/MapFile.ts","../src/ThroughputLimiter.ts","../src/Observer.ts","../src/Operation.ts","../src/test/generators/OperationGenerator.ts","../src/Resolver.ts","../src/ServiceInfoProvider.ts","../src/FeeManager.ts","../src/ValueTimeLockVerifier.ts","../src/TransactionProcessor.ts","../src/TransactionSelector.ts","../src/LogColor.ts","../src/write/BatchWriter.ts","../src/OperationProcessor.ts","../src/Did.ts","../src/RequestHandler.ts","../src/VersionMetadata.ts","../src/VersionManager.ts"],"sourcesContent":["/**\n * Copyright (c) 2014-present, Facebook, Inc.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\nvar runtime = (function (exports) {\n  \"use strict\";\n\n  var Op = Object.prototype;\n  var hasOwn = Op.hasOwnProperty;\n  var undefined; // More compressible than void 0.\n  var $Symbol = typeof Symbol === \"function\" ? Symbol : {};\n  var iteratorSymbol = $Symbol.iterator || \"@@iterator\";\n  var asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\";\n  var toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\";\n\n  function define(obj, key, value) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n    return obj[key];\n  }\n  try {\n    // IE 8 has a broken Object.defineProperty that only works on DOM objects.\n    define({}, \"\");\n  } catch (err) {\n    define = function(obj, key, value) {\n      return obj[key] = value;\n    };\n  }\n\n  function wrap(innerFn, outerFn, self, tryLocsList) {\n    // If outerFn provided and outerFn.prototype is a Generator, then outerFn.prototype instanceof Generator.\n    var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator;\n    var generator = Object.create(protoGenerator.prototype);\n    var context = new Context(tryLocsList || []);\n\n    // The ._invoke method unifies the implementations of the .next,\n    // .throw, and .return methods.\n    generator._invoke = makeInvokeMethod(innerFn, self, context);\n\n    return generator;\n  }\n  exports.wrap = wrap;\n\n  // Try/catch helper to minimize deoptimizations. Returns a completion\n  // record like context.tryEntries[i].completion. This interface could\n  // have been (and was previously) designed to take a closure to be\n  // invoked without arguments, but in all the cases we care about we\n  // already have an existing method we want to call, so there's no need\n  // to create a new function object. We can even get away with assuming\n  // the method takes exactly one argument, since that happens to be true\n  // in every case, so we don't have to touch the arguments object. The\n  // only additional allocation required is the completion record, which\n  // has a stable shape and so hopefully should be cheap to allocate.\n  function tryCatch(fn, obj, arg) {\n    try {\n      return { type: \"normal\", arg: fn.call(obj, arg) };\n    } catch (err) {\n      return { type: \"throw\", arg: err };\n    }\n  }\n\n  var GenStateSuspendedStart = \"suspendedStart\";\n  var GenStateSuspendedYield = \"suspendedYield\";\n  var GenStateExecuting = \"executing\";\n  var GenStateCompleted = \"completed\";\n\n  // Returning this object from the innerFn has the same effect as\n  // breaking out of the dispatch switch statement.\n  var ContinueSentinel = {};\n\n  // Dummy constructor functions that we use as the .constructor and\n  // .constructor.prototype properties for functions that return Generator\n  // objects. For full spec compliance, you may wish to configure your\n  // minifier not to mangle the names of these two functions.\n  function Generator() {}\n  function GeneratorFunction() {}\n  function GeneratorFunctionPrototype() {}\n\n  // This is a polyfill for %IteratorPrototype% for environments that\n  // don't natively support it.\n  var IteratorPrototype = {};\n  IteratorPrototype[iteratorSymbol] = function () {\n    return this;\n  };\n\n  var getProto = Object.getPrototypeOf;\n  var NativeIteratorPrototype = getProto && getProto(getProto(values([])));\n  if (NativeIteratorPrototype &&\n      NativeIteratorPrototype !== Op &&\n      hasOwn.call(NativeIteratorPrototype, iteratorSymbol)) {\n    // This environment has a native %IteratorPrototype%; use it instead\n    // of the polyfill.\n    IteratorPrototype = NativeIteratorPrototype;\n  }\n\n  var Gp = GeneratorFunctionPrototype.prototype =\n    Generator.prototype = Object.create(IteratorPrototype);\n  GeneratorFunction.prototype = Gp.constructor = GeneratorFunctionPrototype;\n  GeneratorFunctionPrototype.constructor = GeneratorFunction;\n  GeneratorFunction.displayName = define(\n    GeneratorFunctionPrototype,\n    toStringTagSymbol,\n    \"GeneratorFunction\"\n  );\n\n  // Helper for defining the .next, .throw, and .return methods of the\n  // Iterator interface in terms of a single ._invoke method.\n  function defineIteratorMethods(prototype) {\n    [\"next\", \"throw\", \"return\"].forEach(function(method) {\n      define(prototype, method, function(arg) {\n        return this._invoke(method, arg);\n      });\n    });\n  }\n\n  exports.isGeneratorFunction = function(genFun) {\n    var ctor = typeof genFun === \"function\" && genFun.constructor;\n    return ctor\n      ? ctor === GeneratorFunction ||\n        // For the native GeneratorFunction constructor, the best we can\n        // do is to check its .name property.\n        (ctor.displayName || ctor.name) === \"GeneratorFunction\"\n      : false;\n  };\n\n  exports.mark = function(genFun) {\n    if (Object.setPrototypeOf) {\n      Object.setPrototypeOf(genFun, GeneratorFunctionPrototype);\n    } else {\n      genFun.__proto__ = GeneratorFunctionPrototype;\n      define(genFun, toStringTagSymbol, \"GeneratorFunction\");\n    }\n    genFun.prototype = Object.create(Gp);\n    return genFun;\n  };\n\n  // Within the body of any async function, `await x` is transformed to\n  // `yield regeneratorRuntime.awrap(x)`, so that the runtime can test\n  // `hasOwn.call(value, \"__await\")` to determine if the yielded value is\n  // meant to be awaited.\n  exports.awrap = function(arg) {\n    return { __await: arg };\n  };\n\n  function AsyncIterator(generator, PromiseImpl) {\n    function invoke(method, arg, resolve, reject) {\n      var record = tryCatch(generator[method], generator, arg);\n      if (record.type === \"throw\") {\n        reject(record.arg);\n      } else {\n        var result = record.arg;\n        var value = result.value;\n        if (value &&\n            typeof value === \"object\" &&\n            hasOwn.call(value, \"__await\")) {\n          return PromiseImpl.resolve(value.__await).then(function(value) {\n            invoke(\"next\", value, resolve, reject);\n          }, function(err) {\n            invoke(\"throw\", err, resolve, reject);\n          });\n        }\n\n        return PromiseImpl.resolve(value).then(function(unwrapped) {\n          // When a yielded Promise is resolved, its final value becomes\n          // the .value of the Promise<{value,done}> result for the\n          // current iteration.\n          result.value = unwrapped;\n          resolve(result);\n        }, function(error) {\n          // If a rejected Promise was yielded, throw the rejection back\n          // into the async generator function so it can be handled there.\n          return invoke(\"throw\", error, resolve, reject);\n        });\n      }\n    }\n\n    var previousPromise;\n\n    function enqueue(method, arg) {\n      function callInvokeWithMethodAndArg() {\n        return new PromiseImpl(function(resolve, reject) {\n          invoke(method, arg, resolve, reject);\n        });\n      }\n\n      return previousPromise =\n        // If enqueue has been called before, then we want to wait until\n        // all previous Promises have been resolved before calling invoke,\n        // so that results are always delivered in the correct order. If\n        // enqueue has not been called before, then it is important to\n        // call invoke immediately, without waiting on a callback to fire,\n        // so that the async generator function has the opportunity to do\n        // any necessary setup in a predictable way. This predictability\n        // is why the Promise constructor synchronously invokes its\n        // executor callback, and why async functions synchronously\n        // execute code before the first await. Since we implement simple\n        // async functions in terms of async generators, it is especially\n        // important to get this right, even though it requires care.\n        previousPromise ? previousPromise.then(\n          callInvokeWithMethodAndArg,\n          // Avoid propagating failures to Promises returned by later\n          // invocations of the iterator.\n          callInvokeWithMethodAndArg\n        ) : callInvokeWithMethodAndArg();\n    }\n\n    // Define the unified helper method that is used to implement .next,\n    // .throw, and .return (see defineIteratorMethods).\n    this._invoke = enqueue;\n  }\n\n  defineIteratorMethods(AsyncIterator.prototype);\n  AsyncIterator.prototype[asyncIteratorSymbol] = function () {\n    return this;\n  };\n  exports.AsyncIterator = AsyncIterator;\n\n  // Note that simple async functions are implemented on top of\n  // AsyncIterator objects; they just return a Promise for the value of\n  // the final result produced by the iterator.\n  exports.async = function(innerFn, outerFn, self, tryLocsList, PromiseImpl) {\n    if (PromiseImpl === void 0) PromiseImpl = Promise;\n\n    var iter = new AsyncIterator(\n      wrap(innerFn, outerFn, self, tryLocsList),\n      PromiseImpl\n    );\n\n    return exports.isGeneratorFunction(outerFn)\n      ? iter // If outerFn is a generator, return the full iterator.\n      : iter.next().then(function(result) {\n          return result.done ? result.value : iter.next();\n        });\n  };\n\n  function makeInvokeMethod(innerFn, self, context) {\n    var state = GenStateSuspendedStart;\n\n    return function invoke(method, arg) {\n      if (state === GenStateExecuting) {\n        throw new Error(\"Generator is already running\");\n      }\n\n      if (state === GenStateCompleted) {\n        if (method === \"throw\") {\n          throw arg;\n        }\n\n        // Be forgiving, per 25.3.3.3.3 of the spec:\n        // https://people.mozilla.org/~jorendorff/es6-draft.html#sec-generatorresume\n        return doneResult();\n      }\n\n      context.method = method;\n      context.arg = arg;\n\n      while (true) {\n        var delegate = context.delegate;\n        if (delegate) {\n          var delegateResult = maybeInvokeDelegate(delegate, context);\n          if (delegateResult) {\n            if (delegateResult === ContinueSentinel) continue;\n            return delegateResult;\n          }\n        }\n\n        if (context.method === \"next\") {\n          // Setting context._sent for legacy support of Babel's\n          // function.sent implementation.\n          context.sent = context._sent = context.arg;\n\n        } else if (context.method === \"throw\") {\n          if (state === GenStateSuspendedStart) {\n            state = GenStateCompleted;\n            throw context.arg;\n          }\n\n          context.dispatchException(context.arg);\n\n        } else if (context.method === \"return\") {\n          context.abrupt(\"return\", context.arg);\n        }\n\n        state = GenStateExecuting;\n\n        var record = tryCatch(innerFn, self, context);\n        if (record.type === \"normal\") {\n          // If an exception is thrown from innerFn, we leave state ===\n          // GenStateExecuting and loop back for another invocation.\n          state = context.done\n            ? GenStateCompleted\n            : GenStateSuspendedYield;\n\n          if (record.arg === ContinueSentinel) {\n            continue;\n          }\n\n          return {\n            value: record.arg,\n            done: context.done\n          };\n\n        } else if (record.type === \"throw\") {\n          state = GenStateCompleted;\n          // Dispatch the exception by looping back around to the\n          // context.dispatchException(context.arg) call above.\n          context.method = \"throw\";\n          context.arg = record.arg;\n        }\n      }\n    };\n  }\n\n  // Call delegate.iterator[context.method](context.arg) and handle the\n  // result, either by returning a { value, done } result from the\n  // delegate iterator, or by modifying context.method and context.arg,\n  // setting context.delegate to null, and returning the ContinueSentinel.\n  function maybeInvokeDelegate(delegate, context) {\n    var method = delegate.iterator[context.method];\n    if (method === undefined) {\n      // A .throw or .return when the delegate iterator has no .throw\n      // method always terminates the yield* loop.\n      context.delegate = null;\n\n      if (context.method === \"throw\") {\n        // Note: [\"return\"] must be used for ES3 parsing compatibility.\n        if (delegate.iterator[\"return\"]) {\n          // If the delegate iterator has a return method, give it a\n          // chance to clean up.\n          context.method = \"return\";\n          context.arg = undefined;\n          maybeInvokeDelegate(delegate, context);\n\n          if (context.method === \"throw\") {\n            // If maybeInvokeDelegate(context) changed context.method from\n            // \"return\" to \"throw\", let that override the TypeError below.\n            return ContinueSentinel;\n          }\n        }\n\n        context.method = \"throw\";\n        context.arg = new TypeError(\n          \"The iterator does not provide a 'throw' method\");\n      }\n\n      return ContinueSentinel;\n    }\n\n    var record = tryCatch(method, delegate.iterator, context.arg);\n\n    if (record.type === \"throw\") {\n      context.method = \"throw\";\n      context.arg = record.arg;\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    var info = record.arg;\n\n    if (! info) {\n      context.method = \"throw\";\n      context.arg = new TypeError(\"iterator result is not an object\");\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    if (info.done) {\n      // Assign the result of the finished delegate to the temporary\n      // variable specified by delegate.resultName (see delegateYield).\n      context[delegate.resultName] = info.value;\n\n      // Resume execution at the desired location (see delegateYield).\n      context.next = delegate.nextLoc;\n\n      // If context.method was \"throw\" but the delegate handled the\n      // exception, let the outer generator proceed normally. If\n      // context.method was \"next\", forget context.arg since it has been\n      // \"consumed\" by the delegate iterator. If context.method was\n      // \"return\", allow the original .return call to continue in the\n      // outer generator.\n      if (context.method !== \"return\") {\n        context.method = \"next\";\n        context.arg = undefined;\n      }\n\n    } else {\n      // Re-yield the result returned by the delegate method.\n      return info;\n    }\n\n    // The delegate iterator is finished, so forget it and continue with\n    // the outer generator.\n    context.delegate = null;\n    return ContinueSentinel;\n  }\n\n  // Define Generator.prototype.{next,throw,return} in terms of the\n  // unified ._invoke helper method.\n  defineIteratorMethods(Gp);\n\n  define(Gp, toStringTagSymbol, \"Generator\");\n\n  // A Generator should always return itself as the iterator object when the\n  // @@iterator function is called on it. Some browsers' implementations of the\n  // iterator prototype chain incorrectly implement this, causing the Generator\n  // object to not be returned from this call. This ensures that doesn't happen.\n  // See https://github.com/facebook/regenerator/issues/274 for more details.\n  Gp[iteratorSymbol] = function() {\n    return this;\n  };\n\n  Gp.toString = function() {\n    return \"[object Generator]\";\n  };\n\n  function pushTryEntry(locs) {\n    var entry = { tryLoc: locs[0] };\n\n    if (1 in locs) {\n      entry.catchLoc = locs[1];\n    }\n\n    if (2 in locs) {\n      entry.finallyLoc = locs[2];\n      entry.afterLoc = locs[3];\n    }\n\n    this.tryEntries.push(entry);\n  }\n\n  function resetTryEntry(entry) {\n    var record = entry.completion || {};\n    record.type = \"normal\";\n    delete record.arg;\n    entry.completion = record;\n  }\n\n  function Context(tryLocsList) {\n    // The root entry object (effectively a try statement without a catch\n    // or a finally block) gives us a place to store values thrown from\n    // locations where there is no enclosing try statement.\n    this.tryEntries = [{ tryLoc: \"root\" }];\n    tryLocsList.forEach(pushTryEntry, this);\n    this.reset(true);\n  }\n\n  exports.keys = function(object) {\n    var keys = [];\n    for (var key in object) {\n      keys.push(key);\n    }\n    keys.reverse();\n\n    // Rather than returning an object with a next method, we keep\n    // things simple and return the next function itself.\n    return function next() {\n      while (keys.length) {\n        var key = keys.pop();\n        if (key in object) {\n          next.value = key;\n          next.done = false;\n          return next;\n        }\n      }\n\n      // To avoid creating an additional object, we just hang the .value\n      // and .done properties off the next function object itself. This\n      // also ensures that the minifier will not anonymize the function.\n      next.done = true;\n      return next;\n    };\n  };\n\n  function values(iterable) {\n    if (iterable) {\n      var iteratorMethod = iterable[iteratorSymbol];\n      if (iteratorMethod) {\n        return iteratorMethod.call(iterable);\n      }\n\n      if (typeof iterable.next === \"function\") {\n        return iterable;\n      }\n\n      if (!isNaN(iterable.length)) {\n        var i = -1, next = function next() {\n          while (++i < iterable.length) {\n            if (hasOwn.call(iterable, i)) {\n              next.value = iterable[i];\n              next.done = false;\n              return next;\n            }\n          }\n\n          next.value = undefined;\n          next.done = true;\n\n          return next;\n        };\n\n        return next.next = next;\n      }\n    }\n\n    // Return an iterator with no values.\n    return { next: doneResult };\n  }\n  exports.values = values;\n\n  function doneResult() {\n    return { value: undefined, done: true };\n  }\n\n  Context.prototype = {\n    constructor: Context,\n\n    reset: function(skipTempReset) {\n      this.prev = 0;\n      this.next = 0;\n      // Resetting context._sent for legacy support of Babel's\n      // function.sent implementation.\n      this.sent = this._sent = undefined;\n      this.done = false;\n      this.delegate = null;\n\n      this.method = \"next\";\n      this.arg = undefined;\n\n      this.tryEntries.forEach(resetTryEntry);\n\n      if (!skipTempReset) {\n        for (var name in this) {\n          // Not sure about the optimal order of these conditions:\n          if (name.charAt(0) === \"t\" &&\n              hasOwn.call(this, name) &&\n              !isNaN(+name.slice(1))) {\n            this[name] = undefined;\n          }\n        }\n      }\n    },\n\n    stop: function() {\n      this.done = true;\n\n      var rootEntry = this.tryEntries[0];\n      var rootRecord = rootEntry.completion;\n      if (rootRecord.type === \"throw\") {\n        throw rootRecord.arg;\n      }\n\n      return this.rval;\n    },\n\n    dispatchException: function(exception) {\n      if (this.done) {\n        throw exception;\n      }\n\n      var context = this;\n      function handle(loc, caught) {\n        record.type = \"throw\";\n        record.arg = exception;\n        context.next = loc;\n\n        if (caught) {\n          // If the dispatched exception was caught by a catch block,\n          // then let that catch block handle the exception normally.\n          context.method = \"next\";\n          context.arg = undefined;\n        }\n\n        return !! caught;\n      }\n\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        var record = entry.completion;\n\n        if (entry.tryLoc === \"root\") {\n          // Exception thrown outside of any try block that could handle\n          // it, so set the completion value of the entire function to\n          // throw the exception.\n          return handle(\"end\");\n        }\n\n        if (entry.tryLoc <= this.prev) {\n          var hasCatch = hasOwn.call(entry, \"catchLoc\");\n          var hasFinally = hasOwn.call(entry, \"finallyLoc\");\n\n          if (hasCatch && hasFinally) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            } else if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else if (hasCatch) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            }\n\n          } else if (hasFinally) {\n            if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else {\n            throw new Error(\"try statement without catch or finally\");\n          }\n        }\n      }\n    },\n\n    abrupt: function(type, arg) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc <= this.prev &&\n            hasOwn.call(entry, \"finallyLoc\") &&\n            this.prev < entry.finallyLoc) {\n          var finallyEntry = entry;\n          break;\n        }\n      }\n\n      if (finallyEntry &&\n          (type === \"break\" ||\n           type === \"continue\") &&\n          finallyEntry.tryLoc <= arg &&\n          arg <= finallyEntry.finallyLoc) {\n        // Ignore the finally entry if control is not jumping to a\n        // location outside the try/catch block.\n        finallyEntry = null;\n      }\n\n      var record = finallyEntry ? finallyEntry.completion : {};\n      record.type = type;\n      record.arg = arg;\n\n      if (finallyEntry) {\n        this.method = \"next\";\n        this.next = finallyEntry.finallyLoc;\n        return ContinueSentinel;\n      }\n\n      return this.complete(record);\n    },\n\n    complete: function(record, afterLoc) {\n      if (record.type === \"throw\") {\n        throw record.arg;\n      }\n\n      if (record.type === \"break\" ||\n          record.type === \"continue\") {\n        this.next = record.arg;\n      } else if (record.type === \"return\") {\n        this.rval = this.arg = record.arg;\n        this.method = \"return\";\n        this.next = \"end\";\n      } else if (record.type === \"normal\" && afterLoc) {\n        this.next = afterLoc;\n      }\n\n      return ContinueSentinel;\n    },\n\n    finish: function(finallyLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.finallyLoc === finallyLoc) {\n          this.complete(entry.completion, entry.afterLoc);\n          resetTryEntry(entry);\n          return ContinueSentinel;\n        }\n      }\n    },\n\n    \"catch\": function(tryLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc === tryLoc) {\n          var record = entry.completion;\n          if (record.type === \"throw\") {\n            var thrown = record.arg;\n            resetTryEntry(entry);\n          }\n          return thrown;\n        }\n      }\n\n      // The context.catch method must only be called with a location\n      // argument that corresponds to a known catch block.\n      throw new Error(\"illegal catch attempt\");\n    },\n\n    delegateYield: function(iterable, resultName, nextLoc) {\n      this.delegate = {\n        iterator: values(iterable),\n        resultName: resultName,\n        nextLoc: nextLoc\n      };\n\n      if (this.method === \"next\") {\n        // Deliberately forget the last sent value so that we don't\n        // accidentally pass it on to the delegate.\n        this.arg = undefined;\n      }\n\n      return ContinueSentinel;\n    }\n  };\n\n  // Regardless of whether this script is executing as a CommonJS module\n  // or not, return the runtime object so that we can declare the variable\n  // regeneratorRuntime in the outer scope, which allows this module to be\n  // injected easily by `bin/regenerator --include-runtime script.js`.\n  return exports;\n\n}(\n  // If this script is executing as a CommonJS module, use module.exports\n  // as the regeneratorRuntime namespace. Otherwise create a new empty\n  // object. Either way, the resulting object will be used to initialize\n  // the regeneratorRuntime variable at the top of this file.\n  typeof module === \"object\" ? module.exports : {}\n));\n\ntry {\n  regeneratorRuntime = runtime;\n} catch (accidentalStrictMode) {\n  // This module should not be running in strict mode, so the above\n  // assignment should always work unless something is misconfigured. Just\n  // in case runtime.js accidentally runs in strict mode, we can escape\n  // strict mode using a global Function call. This could conceivably fail\n  // if a Content Security Policy forbids using Function, but in that case\n  // the proper solution is to fix the accidental strict mode problem. If\n  // you've misconfigured your bundler to force strict mode and applied a\n  // CSP to forbid Function, and you're not willing to fix either of those\n  // problems, please detail your unique predicament in a GitHub issue.\n  Function(\"r\", \"regeneratorRuntime = r\")(runtime);\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Class containing methods that operates against an array.\n */\nexport default class ArrayMethods {\n  /**\n   * Checkes to see if there are duplicates in the given array.\n   */\n  public static hasDuplicates<T>(array: Array<T>): boolean {\n    const uniqueValues = new Set<T>();\n\n    for (let i = 0; i < array.length; i++) {\n      const value = array[i];\n      if (uniqueValues.has(value)) {\n        return true;\n      }\n      uniqueValues.add(value);\n    }\n\n    return false;\n  }\n\n  /**\n   * Checks that entries in array 2 is not in array 1.\n   */\n  public static areMutuallyExclusive<T>(\n    array1: Array<T>,\n    array2: Array<T>\n  ): boolean {\n    const valuesInArray1 = new Set<T>(array1);\n\n    for (const value of array2) {\n      if (valuesInArray1.has(value)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst pako = require('pako');\n\n/**\n * Encapsulates functionality to compress/decompress data.\n */\nexport default class Compressor {\n  /**\n   * Compresses the data in gzip and return it as buffer.\n   * @param inputAsBuffer The input string to be compressed.\n   */\n  public static async compress(inputAsBuffer: Buffer): Promise<Buffer> {\n    const result = pako.deflate(Buffer.from(inputAsBuffer));\n    return Buffer.from(result);\n  }\n\n  /**\n   * Decompresses the input and returns it as buffer.\n   * @param inputAsBuffer The gzip compressed data.\n   */\n  public static async decompress(inputAsBuffer: Buffer): Promise<Buffer> {\n    const result = pako.inflate(inputAsBuffer);\n    return Buffer.from(result);\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DocumentModel,\n  Encoder,\n  DidState,\n  ErrorCode,\n  SidetreeError,\n  PublicKeyPurpose,\n} from '@sidetree/common';\nimport UpdateOperation from './UpdateOperation';\nimport jsonpatch from 'fast-json-patch';\n\n/**\n * Class that handles the composition of operations into final external-facing document.\n */\nexport default class DocumentComposer {\n  /**\n   * Transforms the given DID state into a DID Document.\n   */\n  public static transformToExternalDocument(\n    didState: DidState,\n    did: string\n  ): any {\n    // If the DID is deactivated.\n    if (didState.nextRecoveryCommitmentHash === undefined) {\n      return { status: 'deactivated' };\n    }\n\n    const document = didState.document as DocumentModel;\n\n    const shortFormDid = did.split('?')[0];\n\n    // Only populate `publicKey` if general purpose exists.\n    // Only populate `authentication` if auth purpose exists.\n    const authentication: any[] = [];\n    const assertionMethod: any[] = [];\n    const capabilityInvocation: any[] = [];\n    const capabilityDelegation: any[] = [];\n    const keyAgreement: any[] = [];\n\n    const public_keys: any[] = [];\n    if (Array.isArray(document.public_keys)) {\n      for (const publicKey of document.public_keys) {\n        const id = '#' + publicKey.id;\n        const didDocumentPublicKey = {\n          id: id,\n          controller: shortFormDid,\n          type: publicKey.type,\n          publicKeyJwk: publicKey.jwk,\n        };\n        const purposeSet: Set<string> = new Set(publicKey.purpose);\n\n        if (purposeSet.has(PublicKeyPurpose.General)) {\n          public_keys.push(didDocumentPublicKey);\n\n          if (purposeSet.has(PublicKeyPurpose.Auth)) {\n            authentication.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.AssertionMethod)) {\n            assertionMethod.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.CapabilityInvocation)) {\n            capabilityInvocation.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.CapabilityDelegation)) {\n            capabilityDelegation.push(id);\n          }\n          if (purposeSet.has(PublicKeyPurpose.KeyAgreement)) {\n            keyAgreement.push(id);\n          }\n        } else if (purposeSet.has(PublicKeyPurpose.Auth)) {\n          authentication.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.AssertionMethod)) {\n          assertionMethod.push(assertionMethod);\n        } else if (purposeSet.has(PublicKeyPurpose.CapabilityInvocation)) {\n          capabilityInvocation.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.CapabilityDelegation)) {\n          capabilityDelegation.push(didDocumentPublicKey);\n        } else if (purposeSet.has(PublicKeyPurpose.KeyAgreement)) {\n          keyAgreement.push(didDocumentPublicKey);\n        }\n      }\n    }\n\n    // Only update `service_endpoints` if the array is present\n    const service_endpoints = [];\n    if (Array.isArray(document.service_endpoints)) {\n      for (const serviceEndpoint of document.service_endpoints) {\n        const didDocumentServiceEndpoint = {\n          id: '#' + serviceEndpoint.id,\n          type: serviceEndpoint.type,\n          serviceEndpoint: serviceEndpoint.endpoint,\n        };\n        service_endpoints.push(didDocumentServiceEndpoint);\n      }\n    }\n\n    const didDocument: any = {\n      id: shortFormDid,\n      '@context': [\n        'https://www.w3.org/ns/did/v1',\n        'https://ns.did.ai/transmute/v1',\n        { '@base': shortFormDid },\n      ],\n    };\n\n    if (public_keys.length !== 0) {\n      didDocument.publicKey = public_keys;\n    }\n\n    if (authentication.length !== 0) {\n      didDocument.authentication = authentication;\n    }\n\n    if (assertionMethod.length !== 0) {\n      didDocument.assertionMethod = assertionMethod;\n    }\n\n    if (capabilityInvocation.length !== 0) {\n      didDocument.capabilityInvocation = capabilityInvocation;\n    }\n\n    if (capabilityDelegation.length !== 0) {\n      didDocument.capabilityDelegation = capabilityDelegation;\n    }\n\n    if (keyAgreement.length !== 0) {\n      didDocument.keyAgreement = keyAgreement;\n    }\n\n    if (service_endpoints.length !== 0) {\n      didDocument.service = service_endpoints;\n    }\n\n    const didResolutionResult: any = {\n      '@context': 'https://w3id.org/did-resolution/v1',\n      didDocument: didDocument,\n      didDocumentMetadata: {\n        recoveryCommitment: didState.nextRecoveryCommitmentHash,\n        updateCommitment: didState.nextUpdateCommitmentHash,\n      },\n    };\n\n    return JSON.parse(JSON.stringify(didResolutionResult));\n  }\n\n  /**\n   * Applies the update operation to the given document.\n   * @returns The resultant document.\n   * @throws SidetreeError if invalid operation is given.\n   */\n  public static async applyUpdateOperation(\n    operation: UpdateOperation,\n    document: any\n  ): Promise<any> {\n    const resultantDocument = DocumentComposer.applyPatches(\n      document,\n      operation.delta!.patches\n    );\n\n    return resultantDocument;\n  }\n\n  /**\n   * Validates the schema of the given full document.\n   * @throws SidetreeError if given document patch fails validation.\n   */\n  private static validateDocument(document: any) {\n    if (document === undefined) {\n      throw new SidetreeError(ErrorCode.DocumentComposerDocumentMissing);\n    }\n\n    const allowedProperties = new Set(['public_keys', 'service_endpoints']);\n    for (const property in document) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerUnknownPropertyInDocument,\n          `Unexpected property ${property} in document.`\n        );\n      }\n    }\n\n    // Verify 'public_keys' property if it exists.\n    if (Object.prototype.hasOwnProperty.call(document, 'public_keys')) {\n      DocumentComposer.validatePublicKeys(document.public_keys);\n    }\n\n    // Verify 'service_endpoints' property if it exists.\n    if (Object.prototype.hasOwnProperty.call(document, 'service_endpoints')) {\n      // Verify each endpoint entry in service_endpoints.\n      DocumentComposer.validateServiceEndpoints(document.service_endpoints);\n    }\n  }\n\n  /**\n   * Validates the schema of the given update document patch.\n   * @throws SidetreeError if given document patch fails validation.\n   */\n  public static validateDocumentPatches(patches: any) {\n    if (!Array.isArray(patches)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerUpdateOperationDocumentPatchesNotArray\n      );\n    }\n\n    for (const patch of patches) {\n      DocumentComposer.validatePatch(patch);\n    }\n  }\n\n  private static validatePatch(patch: any) {\n    const action = patch.action;\n    switch (action) {\n      case 'replace':\n        DocumentComposer.validateDocument(patch.document);\n        break;\n      case 'add-public-keys':\n        DocumentComposer.validateAddPublicKeysPatch(patch);\n        break;\n      case 'remove-public-keys':\n        DocumentComposer.validateRemovePublicKeysPatch(patch);\n        break;\n      case 'add-service-endpoints':\n        DocumentComposer.validateAddServiceEndpointsPatch(patch);\n        break;\n      case 'remove-service-endpoints':\n        DocumentComposer.validateRemoveServiceEndpointsPatch(patch);\n        break;\n      case 'ietf-json-patch':\n        DocumentComposer.validateIetfJsonPatch(patch);\n        break;\n      default:\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchMissingOrUnknownAction\n        );\n    }\n  }\n\n  private static validateIetfJsonPatch(patch: any): void {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n    const error = jsonpatch.validate(patch.patches);\n    if (error) {\n      console.warn(error);\n      throw new SidetreeError(error.name);\n    }\n  }\n\n  private static validateAddPublicKeysPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    DocumentComposer.validatePublicKeys(patch.public_keys);\n  }\n\n  private static validatePublicKeys(public_keys: any) {\n    if (!Array.isArray(public_keys)) {\n      throw new SidetreeError(ErrorCode.DocumentComposerPublicKeysNotArray);\n    }\n\n    const publicKeyIdSet: Set<string> = new Set();\n    for (const publicKey of public_keys) {\n      const publicKeyProperties = Object.keys(publicKey);\n      // the expected fields are id, purpose, type and jwk\n      if (publicKeyProperties.length !== 4) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyMissingOrUnknownProperty\n        );\n      }\n\n      if (typeof publicKey.jwk !== 'object' || Array.isArray(publicKey.jwk)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyJwkMissingOrIncorrectType\n        );\n      }\n\n      if (typeof publicKey.type !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyTypeMissingOrIncorrectType\n        );\n      }\n\n      DocumentComposer.validateId(publicKey.id);\n\n      // 'id' must be unique\n      if (publicKeyIdSet.has(publicKey.id)) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyIdDuplicated\n        );\n      }\n      publicKeyIdSet.add(publicKey.id);\n\n      if (!Array.isArray(publicKey.purpose) || publicKey.purpose.length === 0) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyPurposeMissingOrUnknown\n        );\n      }\n\n      if (publicKey.purpose.length > Object.values(PublicKeyPurpose).length) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPublicKeyPurposeExceedsMaxLength\n        );\n      }\n\n      const validPurposes = new Set(Object.values(PublicKeyPurpose));\n      // Purpose must be one of the valid ones in KeyPurpose\n      for (const purpose of publicKey.purpose) {\n        if (!validPurposes.has(purpose)) {\n          throw new SidetreeError(\n            ErrorCode.DocumentComposerPublicKeyInvalidPurpose\n          );\n        }\n      }\n    }\n  }\n\n  private static validateRemovePublicKeysPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.public_keys)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchPublicKeyIdsNotArray\n      );\n    }\n\n    for (const publicKeyId of patch.public_keys) {\n      if (typeof publicKeyId !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchPublicKeyIdNotString\n        );\n      }\n    }\n  }\n\n  /**\n   * validate update patch for removing service endpoints\n   */\n  private static validateRemoveServiceEndpointsPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.ids)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointIdsNotArray\n      );\n    }\n\n    for (const id of patch.ids) {\n      DocumentComposer.validateId(id);\n    }\n  }\n\n  /**\n   * Validates update patch for adding service endpoints.\n   */\n  private static validateAddServiceEndpointsPatch(patch: any) {\n    const patchProperties = Object.keys(patch);\n    if (patchProperties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchMissingOrUnknownProperty\n      );\n    }\n\n    if (!Array.isArray(patch.service_endpoints)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointsNotArray\n      );\n    }\n\n    DocumentComposer.validateServiceEndpoints(patch.service_endpoints);\n  }\n\n  /**\n   * Validates and parses services endpoints\n   * @param service_endpoints the service endpoints to validate and parse\n   */\n  private static validateServiceEndpoints(service_endpoints: any) {\n    if (!Array.isArray(service_endpoints)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerPatchServiceEndpointsNotArray\n      );\n    }\n\n    for (const serviceEndpoint of service_endpoints) {\n      const serviceEndpointProperties = Object.keys(serviceEndpoint);\n      if (serviceEndpointProperties.length !== 3) {\n        // type, id, and endpoint\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerServiceEndpointMissingOrUnknownProperty\n        );\n      }\n\n      DocumentComposer.validateId(serviceEndpoint.id);\n\n      if (typeof serviceEndpoint.type !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointTypeNotString\n        );\n      }\n      if (serviceEndpoint.type.length > 30) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointTypeTooLong\n        );\n      }\n      if (typeof serviceEndpoint.endpoint !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointNotString\n        );\n      }\n      if (serviceEndpoint.endpoint.length > 100) {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointTooLong\n        );\n      }\n\n      try {\n        // just want to validate url, no need to assign to variable, it will throw if not valid\n        // tslint:disable-next-line\n        new URL(serviceEndpoint.endpoint);\n      } catch {\n        throw new SidetreeError(\n          ErrorCode.DocumentComposerPatchServiceEndpointServiceEndpointNotValidUrl\n        );\n      }\n    }\n  }\n\n  private static validateId(id: any) {\n    if (typeof id !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerIdNotString,\n        `ID not string: ${JSON.stringify(id)} is of type '${typeof id}'`\n      );\n    }\n    if (id.length > 50) {\n      throw new SidetreeError(ErrorCode.DocumentComposerIdTooLong);\n    }\n\n    if (!Encoder.isBase64UrlString(id)) {\n      throw new SidetreeError(\n        ErrorCode.DocumentComposerIdNotUsingBase64UrlCharacterSet\n      );\n    }\n  }\n\n  /**\n   * Applies the given patches in order to the given document.\n   * NOTE: Assumes no schema validation is needed, since validation should've already occurred at the time of the operation being parsed.\n   * @returns The resultant document.\n   */\n  public static applyPatches(document: any, patches: any[]): any {\n    // Loop through and apply all patches.\n    let resultantDocument = document;\n    for (const patch of patches) {\n      resultantDocument = DocumentComposer.applyPatchToDidDocument(\n        resultantDocument,\n        patch\n      );\n    }\n\n    return resultantDocument;\n  }\n\n  /**\n   * Applies the given patch to the given DID Document.\n   */\n  private static applyPatchToDidDocument(\n    document: DocumentModel,\n    patch: any\n  ): any {\n    if (patch.action === 'replace') {\n      return patch.document;\n    } else if (patch.action === 'add-public-keys') {\n      return DocumentComposer.addPublicKeys(document, patch);\n    } else if (patch.action === 'remove-public-keys') {\n      return DocumentComposer.removePublicKeys(document, patch);\n    } else if (patch.action === 'add-service-endpoints') {\n      return DocumentComposer.addServiceEndpoints(document, patch);\n    } else if (patch.action === 'remove-service-endpoints') {\n      return DocumentComposer.removeServiceEndpoints(document, patch);\n    } else if (patch.action === 'ietf-json-patch') {\n      return DocumentComposer.applyIetfJsonPatch(document, patch);\n    }\n  }\n\n  private static applyIetfJsonPatch(document: any, patch: any) {\n    const res = jsonpatch.applyPatch({ ...document }, patch.patches);\n    return res.newDocument;\n  }\n\n  /**\n   * Adds public keys to document.\n   */\n  private static addPublicKeys(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const publicKeyMap = new Map(\n      (document.public_keys || []).map((publicKey) => [publicKey.id, publicKey])\n    );\n\n    // Loop through all given public keys and add them if they don't exist already.\n    for (const publicKey of patch.public_keys) {\n      // NOTE: If a key ID already exists, we will just replace the existing key.\n      // Not throwing error will minimize the need (thus risk) of reusing exposed update reveal value.\n      publicKeyMap.set(publicKey.id, publicKey);\n    }\n\n    document.public_keys = Array.from(publicKeyMap.entries()).map(\n      (pkm: any) => pkm[1]\n    );\n\n    return document;\n  }\n\n  /**\n   * Removes public keys from document.\n   */\n  private static removePublicKeys(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const publicKeyMap = new Map(\n      (document.public_keys || []).map((publicKey) => [publicKey.id, publicKey])\n    );\n\n    // Loop through all given public key IDs and delete them from the existing public key only if it is not a recovery key.\n    for (const publicKey of patch.public_keys) {\n      const existingKey = publicKeyMap.get(publicKey);\n\n      if (existingKey !== undefined) {\n        publicKeyMap.delete(publicKey);\n      }\n      // NOTE: Else we will just treat this key removal as a no-op.\n      // Not throwing error will minimize the need (thus risk) of reusing exposed update reveal value.\n    }\n\n    document.public_keys = Array.from(publicKeyMap.entries()).map(\n      (pkm: any) => pkm[1]\n    );\n\n    return document;\n  }\n\n  private static addServiceEndpoints(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    const service_endpoints = patch.service_endpoints;\n\n    if (document.service_endpoints === undefined) {\n      // create a new array if service did not exist\n      document.service_endpoints = [];\n    }\n\n    const idToIndexMapper = new Map();\n    // map all id and their index\n    for (const idx in document.service_endpoints) {\n      idToIndexMapper.set(document.service_endpoints[idx].id, idx);\n    }\n\n    for (const serviceEndpoint of service_endpoints) {\n      if (idToIndexMapper.has(serviceEndpoint.id)) {\n        const idx = idToIndexMapper.get(serviceEndpoint.id);\n        document.service_endpoints[idx] = serviceEndpoint;\n      } else {\n        document.service_endpoints.push(serviceEndpoint);\n      }\n    }\n\n    return document;\n  }\n\n  private static removeServiceEndpoints(\n    document: DocumentModel,\n    patch: any\n  ): DocumentModel {\n    if (document.service_endpoints === undefined) {\n      return document;\n    }\n\n    const idsToRemove = new Set(patch.ids);\n    document.service_endpoints = document.service_endpoints.filter(\n      (serviceEndpoint) => !idsToRemove.has(serviceEndpoint.id)\n    );\n\n    return document;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst yieldableJson = require('yieldable-json');\n\n/**\n * A JSON library that performs operations asynchronously.\n */\nexport default class JsonAsync {\n  /**\n   * Parses the given operation into a JavaScript object asynchronously,\n   * to allow the event loop a chance to handle requests.\n   */\n  public static async parse(jsonData: Buffer | string): Promise<any> {\n    // Create a promise to wrap the successful/failed read events.\n    const jsonParsePromise = new Promise((resolve, reject) => {\n      yieldableJson.parseAsync(jsonData, (err: any, data: any) => {\n        if (err) {\n          reject(err);\n        } else {\n          resolve(data);\n        }\n      });\n    });\n\n    // Wait until the JSON parsing is completed.\n    const result = await jsonParsePromise;\n    return result;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  Multihash,\n  SidetreeError,\n} from '@sidetree/common';\nimport DocumentComposer from './DocumentComposer';\nimport JsonAsync from './util/JsonAsync';\n\n/**\n * A class that contains Sidetree operation utility methods.\n */\nexport default class OperationUtils {\n  /**\n   * Parses the given encoded delta string into an internal `DeltaModel`.\n   */\n  public static async parseDelta(deltaEncodedString: any): Promise<DeltaModel> {\n    if (typeof deltaEncodedString !== 'string') {\n      throw new SidetreeError(ErrorCode.DeltaMissingOrNotString);\n    }\n\n    const deltaJsonString = Encoder.decodeAsString(deltaEncodedString);\n    const delta = await JsonAsync.parse(deltaJsonString);\n\n    const properties = Object.keys(delta);\n    if (properties.length !== 2) {\n      throw new SidetreeError(ErrorCode.DeltaMissingOrUnknownProperty);\n    }\n\n    if (delta.patches === undefined) {\n      throw new SidetreeError(ErrorCode.OperationDocumentPatchesMissing);\n    }\n\n    // Validate `patches` property using the DocumentComposer.\n    DocumentComposer.validateDocumentPatches(delta.patches);\n\n    const nextUpdateCommitment = Encoder.decodeAsBuffer(\n      delta.update_commitment\n    );\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextUpdateCommitment\n    );\n\n    return {\n      patches: delta.patches,\n      update_commitment: delta.update_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  OperationType,\n  ErrorCode,\n  SidetreeError,\n  DeltaModel,\n  OperationModel,\n  Multihash,\n  Encoder,\n} from '@sidetree/common';\nimport OperationUtils from './OperationUtils';\nimport JsonAsync from './util/JsonAsync';\n\ninterface SuffixDataModel {\n  delta_hash: string;\n  recovery_commitment: string;\n}\n\n/**\n * A class that represents a create operation.\n */\nexport default class CreateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Data used to generate the unique DID suffix. */\n  public readonly suffixData: SuffixDataModel;\n\n  /** Delta. */\n  public readonly delta: DeltaModel | undefined;\n\n  /** Encoded string of the suffix data. */\n  public readonly encodedSuffixData: string;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    encodedSuffixData: string,\n    suffixData: SuffixDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.type = OperationType.Create;\n    this.operationBuffer = operationBuffer;\n    this.encodedSuffixData = encodedSuffixData;\n    this.suffixData = suffixData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Computes the DID unique suffix given the encoded suffix data string.\n   */\n  private static computeDidUniqueSuffix(encodedSuffixData: string): string {\n    const suffixDataBuffer = Encoder.decodeAsBuffer(encodedSuffixData);\n    const multihash = Multihash.hash(suffixDataBuffer);\n    const encodedMultihash = Encoder.encode(multihash);\n    return encodedMultihash;\n  }\n\n  /**\n   * Parses the given input as a create operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<CreateOperation> {\n    // Issue #442 - Replace `operationBuffer` in `OperationModel` and `AnchoredOperationModel` with actual operation request\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await CreateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `CreateOperation`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<CreateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const createOperation = await CreateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return createOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `CreateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<CreateOperation> {\n    let expectedPropertyCount = 3;\n    if (anchorFileMode) {\n      expectedPropertyCount = 1;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationMissingOrUnknownProperty\n      );\n    }\n\n    const encodedSuffixData = operationObject.suffix_data;\n    const suffixData = await CreateOperation.parseSuffixData(encodedSuffixData);\n\n    // If not in anchor file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Create) {\n        throw new SidetreeError(ErrorCode.CreateOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      try {\n        delta = await OperationUtils.parseDelta(operationObject.delta);\n      } catch {\n        // For compatibility with data pruning, we have to assume that `delta` may be unavailable,\n        // thus an operation with invalid `delta` needs to be processed as an operation with unavailable `delta`,\n        // so here we let `delta` be `undefined`.\n      }\n    }\n\n    const didUniqueSuffix = CreateOperation.computeDidUniqueSuffix(\n      operationObject.suffix_data\n    );\n    return new CreateOperation(\n      operationBuffer,\n      didUniqueSuffix,\n      encodedSuffixData,\n      suffixData,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSuffixData(\n    suffixDataEncodedString: any\n  ): Promise<SuffixDataModel> {\n    if (typeof suffixDataEncodedString !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationSuffixDataMissingOrNotString\n      );\n    }\n\n    const suffixDataJsonString = Encoder.decodeAsString(\n      suffixDataEncodedString\n    );\n    const suffixData = await JsonAsync.parse(suffixDataJsonString);\n\n    const properties = Object.keys(suffixData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.CreateOperationSuffixDataMissingOrUnknownProperty\n      );\n    }\n\n    const delta_hash = Encoder.decodeAsBuffer(suffixData.delta_hash);\n    const nextRecoveryCommitment = Encoder.decodeAsBuffer(\n      suffixData.recovery_commitment\n    );\n\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextRecoveryCommitment\n    );\n\n    return {\n      delta_hash: suffixData.delta_hash,\n      recovery_commitment: suffixData.recovery_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  SidetreeError,\n  PublicKeyJwkSecp256k1,\n  PublicKeyJwkEd25519,\n  PrivateKeyJwkSecp256k1,\n  PrivateKeyJwkEd25519,\n  PrivateKeyJwk,\n  PublicKeyJwk,\n} from '@sidetree/common';\nimport { JWK } from 'jose';\nimport * as bip39 from 'bip39';\nimport { Ed25519KeyPair } from '@transmute/did-key-ed25519';\nimport hdkey from 'hdkey';\nimport { from as keytoFrom } from '@trust/keyto';\n\n/**\n * Class containing reusable JWK operations.\n */\nexport default class Jwk {\n  /**\n   * Generates ED25519 key pair.\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateEd25519KeyPair(): Promise<\n    [PublicKeyJwkEd25519, PrivateKeyJwkEd25519]\n  > {\n    const keyPair = await JWK.generate('OKP', 'Ed25519');\n    const privateKey = keyPair.toJWK(true) as PrivateKeyJwkEd25519;\n    const publicKey = keyPair.toJWK(false) as PublicKeyJwkEd25519;\n    return [publicKey, privateKey];\n  }\n\n  // Helper method to generate keys from a mnemonic\n  public static async getBufferAtIndex(\n    mnemonic: string,\n    index: number\n  ): Promise<Buffer> {\n    const seed = await bip39.mnemonicToSeed(mnemonic);\n    const root = hdkey.fromMasterSeed(seed);\n    // TODO: 60 is specific to ethereum, we could use another value unique to sidetree\n    const hdPath = `m/44'/60'/0'/0/${index}`;\n    const addrNode = root.derive(hdPath);\n    return addrNode.privateKey;\n  }\n\n  private static async generateEd25519KeyPairFromMnemonic(\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwkEd25519, PrivateKeyJwkEd25519]> {\n    const privateKeyBuffer = await Jwk.getBufferAtIndex(mnemonic, index);\n    const keyPair = await Ed25519KeyPair.generate({\n      seed: privateKeyBuffer,\n    });\n    const ed25519KeyPair = new Ed25519KeyPair(keyPair);\n    const publicKeyJwk = (await ed25519KeyPair.toJwk(\n      false\n    )) as PublicKeyJwkEd25519;\n    const privateKeyJwk = (await ed25519KeyPair.toJwk(\n      true\n    )) as PrivateKeyJwkEd25519;\n    return [publicKeyJwk, privateKeyJwk];\n  }\n\n  /**\n   * Generates SECP256K1 key pair.\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateSecp256k1KeyPair(): Promise<\n    [PublicKeyJwkSecp256k1, PrivateKeyJwkSecp256k1]\n  > {\n    const keyPair = await JWK.generate('EC', 'secp256k1');\n    const publicKey = keyPair.toJWK(false) as PublicKeyJwkSecp256k1;\n    const privateKey = keyPair.toJWK(true) as PrivateKeyJwkSecp256k1;\n    return [publicKey, privateKey];\n  }\n\n  public static async generateJwkKeyPairFromMnemonic(\n    keyType: string,\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwk, PrivateKeyJwk]> {\n    switch (keyType) {\n      case 'secp256k1':\n        return this.generateSecp256k1KeyPairFromMnemonic(mnemonic, index);\n      case 'ed25519':\n        return this.generateEd25519KeyPairFromMnemonic(mnemonic, index);\n      default:\n        throw new Error('Invalid key type');\n    }\n  }\n\n  private static async generateSecp256k1KeyPairFromMnemonic(\n    mnemonic: string,\n    index: number\n  ): Promise<[PublicKeyJwkSecp256k1, PrivateKeyJwkSecp256k1]> {\n    const privateKeyBuffer = await Jwk.getBufferAtIndex(mnemonic, index);\n    const publicKeyJwk = keytoFrom(privateKeyBuffer, 'blk').toJwk('public');\n    publicKeyJwk.crv = 'secp256k1';\n    const privateKeyJwk = keytoFrom(privateKeyBuffer, 'blk').toJwk('private');\n    privateKeyJwk.crv = 'secp256k1';\n    return [publicKeyJwk, privateKeyJwk];\n  }\n\n  /**\n   * Validates the given key is a public key in JWK format allowed by Sidetree.\n   * @throws SidetreeError if given object is not a key in JWK format allowed by Sidetree.\n   */\n  public static validatePublicJwk(jwk: any): void {\n    if (jwk === undefined) {\n      throw new SidetreeError(ErrorCode.JwkUndefined);\n    }\n\n    // TODO: Check validity with JSON schema...\n    const allowedProperties = new Set(['kty', 'crv', 'x', 'y', 'kid']);\n    for (const property in jwk) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.JwkHasUnknownProperty);\n      }\n    }\n\n    switch (jwk.crv) {\n      case 'Ed25519':\n        if (jwk.kty !== 'OKP') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidKty);\n        }\n        if (typeof jwk.x !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeX);\n        }\n        break;\n      case 'secp256k1':\n        if (jwk.kty !== 'EC') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidKty);\n        }\n        if (typeof jwk.x !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeX);\n        }\n        if (typeof jwk.y !== 'string') {\n          throw new SidetreeError(ErrorCode.JwkMissingOrInvalidTypeY);\n        }\n        break;\n      default:\n        throw new SidetreeError(ErrorCode.JwkMissingOrInvalidCrv);\n    }\n  }\n\n  /**\n   * Gets the public key given the private ES256K key.\n   * Mainly used for testing purposes.\n   */\n  public static getCurve25519PublicKey(\n    privateKey: PrivateKeyJwkEd25519\n  ): PublicKeyJwkEd25519 {\n    const keyCopy = Object.assign({}, privateKey);\n\n    // Delete the private key portion.\n    delete keyCopy.d;\n\n    return keyCopy;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Encoder,\n  ErrorCode,\n  SidetreeError,\n  PublicKeyJwk,\n  PrivateKeyJwk,\n} from '@sidetree/common';\nimport { EdDSA } from '@transmute/did-key-ed25519';\nimport { ES256K } from '@transmute/did-key-secp256k1';\n\n/**\n * Class containing reusable JWS operations.\n */\nexport default class Jws {\n  /** Protected header. */\n  public readonly protected: string;\n  /** Payload. */\n  public readonly payload: string;\n  /** Signature. */\n  public readonly signature: string;\n\n  /**\n   * Constructs a JWS object.\n   * @param compactJws Input should be a compact JWS string.\n   */\n  private constructor(compactJws: any) {\n    if (typeof compactJws !== 'string') {\n      throw new SidetreeError(ErrorCode.JwsCompactJwsNotString);\n    }\n\n    const parts = compactJws.split('.');\n    if (parts.length !== 3) {\n      throw new SidetreeError(ErrorCode.JwsCompactJwsInvalid);\n    }\n\n    const protectedHeader = parts[0];\n    const payload = parts[1];\n    const signature = parts[2];\n\n    const decodedProtectedHeadJsonString = Encoder.decodeBase64UrlAsString(\n      protectedHeader\n    );\n    const decodedProtectedHeader = JSON.parse(decodedProtectedHeadJsonString);\n\n    const expectedHeaderPropertyCount = 1; // By default we must have header property is `alg`.\n\n    const headerProperties = Object.keys(decodedProtectedHeader);\n    if (headerProperties.length !== expectedHeaderPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.JwsProtectedHeaderMissingOrUnknownProperty\n      );\n    }\n\n    // Protected header must contain 'alg' property with value 'EdDSA'.\n    if (\n      decodedProtectedHeader.alg !== 'EdDSA' &&\n      decodedProtectedHeader.alg !== 'ES256K'\n    ) {\n      throw new SidetreeError(\n        ErrorCode.JwsProtectedHeaderMissingOrIncorrectAlg\n      );\n    }\n\n    // Must contain Base64URL string 'signature' property.\n    if (!Encoder.isBase64UrlString(signature)) {\n      throw new SidetreeError(ErrorCode.JwsSignatureNotBase64UrlString);\n    }\n\n    // Must contain Base64URL string 'payload' property.\n    if (!Encoder.isBase64UrlString(payload)) {\n      throw new SidetreeError(ErrorCode.JwsPayloadNotBase64UrlString);\n    }\n\n    this.protected = protectedHeader;\n    this.payload = payload;\n    this.signature = signature;\n  }\n\n  /**\n   * Converts this object to a compact JWS string.\n   */\n  public toCompactJws(): string {\n    return Jws.createCompactJws(this.protected, this.payload, this.signature);\n  }\n\n  /**\n   * Verifies the JWS signature.\n   * @returns true if signature is successfully verified, false otherwise.\n   */\n  public async verifySignature(publicKey: PublicKeyJwk): Promise<boolean> {\n    return Jws.verifySignature(\n      this.protected,\n      this.payload,\n      this.signature,\n      publicKey\n    );\n  }\n\n  /**\n   * Verifies the JWS signature.\n   * @returns true if signature is successfully verified, false otherwise.\n   */\n  public static async verifySignature(\n    encodedProtectedHeader: string,\n    encodedPayload: string,\n    signature: string,\n    publicKey: PublicKeyJwk\n  ): Promise<boolean> {\n    const jwsSigningInput =\n      encodedProtectedHeader + '.' + encodedPayload + '.' + signature;\n    const signatureValid = await Jws.verifyCompactJws(\n      jwsSigningInput,\n      publicKey\n    );\n    return signatureValid;\n  }\n\n  /**\n   * Verifies the compact JWS string using the given JWK key.\n   * @returns true if signature is valid; else otherwise.\n   */\n  public static async verifyCompactJws(\n    compactJws: string,\n    jwk: PublicKeyJwk\n  ): Promise<boolean> {\n    try {\n      if (jwk.crv === 'Ed25519') {\n        await EdDSA.verify(compactJws, jwk);\n      } else if (jwk.crv === 'secp256k1') {\n        await ES256K.verify(compactJws, jwk as any);\n      } else {\n        return false;\n      }\n      return true;\n    } catch (error) {\n      console.log(\n        `Input '${compactJws}' failed signature verification: ${SidetreeError.createFromError(\n          ErrorCode.JwsFailedSignatureValidation,\n          error\n        )}`\n      );\n      return false;\n    }\n  }\n\n  /**\n   * Signs the given payload as a compact JWS string.\n   * This is mainly used by tests to create valid test data.\n   */\n  public static async signAsCompactJws(\n    payload: object,\n    privateKey: PrivateKeyJwk,\n    protectedHeader?: any\n  ): Promise<string> {\n    let alg;\n    if (protectedHeader && protectedHeader.alg) {\n      alg = protectedHeader.alg;\n    } else {\n      if (privateKey.crv === 'Ed25519') {\n        alg = 'EdDSA';\n      } else {\n        alg = 'ES256K';\n      }\n    }\n    const header = {\n      ...protectedHeader,\n      alg,\n    };\n    if (privateKey.crv === 'secp256k1') {\n      return await ES256K.sign(payload, privateKey as any, header);\n    }\n    return await EdDSA.sign(payload, privateKey, header);\n  }\n\n  /**\n   * Parses the input as a `Jws` object.\n   */\n  public static parseCompactJws(compactJws: any): Jws {\n    return new Jws(compactJws);\n  }\n\n  /**\n   * Creates a compact JWS string using the given input. No string validation is performed.\n   */\n  public static createCompactJws(\n    protectedHeader: string,\n    payload: string,\n    signature: string\n  ): string {\n    return protectedHeader + '.' + payload + '.' + signature;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\n\ninterface SignedDataModel {\n  didSuffix: string;\n  recovery_key: PublicKeyJwk;\n}\n\n/**\n * A class that represents a deactivate operation.\n */\nexport default class DeactivateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data. */\n  public readonly signedDataJws: Jws;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Deactivate;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n  }\n\n  /**\n   * Parses the given input as a deactivate operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<DeactivateOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await DeactivateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(\n    operationBuffer: Buffer\n  ): Promise<DeactivateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const deactivateOperation = await DeactivateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return deactivateOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `DeactivateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `type` is expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<DeactivateOperation> {\n    let expectedPropertyCount = 3;\n    if (anchorFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationMissingOrInvalidDidUniqueSuffix\n      );\n    }\n\n    const signedDataJws = Jws.parseCompactJws(operationObject.signed_data);\n    const signedData = await DeactivateOperation.parseSignedDataPayload(\n      signedDataJws.payload,\n      operationObject.did_suffix\n    );\n\n    // If not in anchor file mode, we need to validate `type` property.\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Deactivate) {\n        throw new SidetreeError(ErrorCode.DeactivateOperationTypeIncorrect);\n      }\n    }\n\n    return new DeactivateOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedDataJws,\n      signedData\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    deltaEncodedString: string,\n    expectedDidUniqueSuffix: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(deltaEncodedString);\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationSignedDataMissingOrUnknownProperty\n      );\n    }\n\n    if (signedData.did_suffix !== expectedDidUniqueSuffix) {\n      throw new SidetreeError(\n        ErrorCode.DeactivateOperationSignedDidUniqueSuffixMismatch\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.recovery_key);\n\n    return {\n      didSuffix: signedData.did_suffix,\n      recovery_key: signedData.recovery_key,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport OperationUtils from './OperationUtils';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\n\ninterface SignedDataModel {\n  delta_hash: string;\n  recovery_key: PublicKeyJwk;\n  recovery_commitment: string;\n}\n\n/**\n * A class that represents a recover operation.\n */\nexport default class RecoverOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data. */\n  public readonly signedDataJws: Jws;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /** Patch data. */\n  public readonly delta: DeltaModel | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the constructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Recover;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Parses the given input as a recover operation entry in the anchor file.\n   */\n  public static async parseOperationFromAnchorFile(\n    input: any\n  ): Promise<RecoverOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await RecoverOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(\n    operationBuffer: Buffer\n  ): Promise<RecoverOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const recoverOperation = await RecoverOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return recoverOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `RecoverOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param anchorFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    anchorFileMode: boolean\n  ): Promise<RecoverOperation> {\n    let expectedPropertyCount = 4;\n    if (anchorFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationMissingOrInvalidDidUniqueSuffix\n      );\n    }\n\n    const signedDataJws = Jws.parseCompactJws(operationObject.signed_data);\n    const signedData = await RecoverOperation.parseSignedDataPayload(\n      signedDataJws.payload\n    );\n\n    // If not in anchor file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!anchorFileMode) {\n      if (operationObject.type !== OperationType.Recover) {\n        throw new SidetreeError(ErrorCode.RecoverOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      try {\n        delta = await OperationUtils.parseDelta(operationObject.delta);\n      } catch {\n        // For compatibility with data pruning, we have to assume that delta may be unavailable,\n        // thus an operation with invalid delta needs to be processed as an operation with unavailable delta,\n        // so here we let delta be `undefined`.\n      }\n    }\n\n    return new RecoverOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedDataJws,\n      signedData,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    signedDataEncodedString: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(\n      signedDataEncodedString\n    );\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n\n    // TODO: JSON Schema instead of property count type checking...\n    if (properties.length !== 3) {\n      throw new SidetreeError(\n        ErrorCode.RecoverOperationSignedDataMissingOrUnknownProperty\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.recovery_key);\n\n    const delta_hash = Encoder.decodeAsBuffer(signedData.delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n\n    const nextRecoveryCommitmentHash = Encoder.decodeAsBuffer(\n      signedData.recovery_commitment\n    );\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(\n      nextRecoveryCommitmentHash\n    );\n\n    return {\n      delta_hash: signedData.delta_hash,\n      recovery_key: signedData.recovery_key,\n      recovery_commitment: signedData.recovery_commitment,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AnchorFileModel, ErrorCode, SidetreeError } from '@sidetree/common';\nimport ArrayMethods from '../util/ArrayMethods';\nimport Compressor from '../util/Compressor';\nimport CreateOperation from '../CreateOperation';\nimport DeactivateOperation from '../DeactivateOperation';\nimport JsonAsync from '../util/JsonAsync';\nimport RecoverOperation from '../RecoverOperation';\n\n/**\n * Class containing Anchor File related operations.\n */\nexport default class AnchorFile {\n  /**\n   * Class that represents an anchor file.\n   * NOTE: this class is introduced as an internal structure in replacement to `AnchorFileModel`\n   * to keep useful metadata so that repeated computation can be avoided.\n   */\n  private constructor(\n    public readonly model: AnchorFileModel,\n    public readonly didUniqueSuffixes: string[],\n    public readonly createOperations: CreateOperation[],\n    public readonly recoverOperations: RecoverOperation[],\n    public readonly deactivateOperations: DeactivateOperation[]\n  ) {}\n\n  /**\n   * Parses and validates the given anchor file buffer.\n   * @throws `SidetreeError` if failed parsing or validation.\n   */\n  public static async parse(anchorFileBuffer: Buffer): Promise<AnchorFile> {\n    let anchorFileDecompressedBuffer;\n    try {\n      anchorFileDecompressedBuffer = await Compressor.decompress(\n        anchorFileBuffer\n      );\n    } catch (e) {\n      throw SidetreeError.createFromError(\n        ErrorCode.AnchorFileDecompressionFailure,\n        e\n      );\n    }\n\n    let anchorFileModel;\n    try {\n      anchorFileModel = await JsonAsync.parse(anchorFileDecompressedBuffer);\n    } catch (e) {\n      throw SidetreeError.createFromError(ErrorCode.AnchorFileNotJson, e);\n    }\n\n    const allowedProperties = new Set([\n      'map_file_uri',\n      'operations',\n      'writer_lock_id',\n    ]);\n    for (const property in anchorFileModel) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.AnchorFileHasUnknownProperty);\n      }\n    }\n\n    if (\n      !Object.prototype.hasOwnProperty.call(anchorFileModel, 'map_file_uri')\n    ) {\n      throw new SidetreeError(ErrorCode.AnchorFileMapFileHashMissing);\n    }\n\n    if (!Object.prototype.hasOwnProperty.call(anchorFileModel, 'operations')) {\n      throw new SidetreeError(ErrorCode.AnchorFileMissingOperationsProperty);\n    }\n\n    if (\n      Object.prototype.hasOwnProperty.call(anchorFileModel, 'writer_lock_id') &&\n      typeof anchorFileModel.writer_lock_id !== 'string'\n    ) {\n      throw new SidetreeError(ErrorCode.AnchorFileWriterLockIPropertyNotString);\n    }\n\n    // Map file hash validations.\n    const mapFileUri = anchorFileModel.map_file_uri;\n    if (typeof mapFileUri !== 'string') {\n      throw new SidetreeError(ErrorCode.AnchorFileMapFileHashNotString);\n    }\n\n    const allowedOperationsProperties = new Set([\n      'create',\n      'recover',\n      'deactivate',\n    ]);\n    const operations = anchorFileModel.operations;\n    for (const property in operations) {\n      if (!allowedOperationsProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.AnchorFileUnexpectedPropertyInOperations,\n          `Unexpected property ${property} in 'operations' property in anchor file.`\n        );\n      }\n    }\n\n    // Will be populated for later validity check.\n    const didUniqueSuffixes: string[] = [];\n\n    // Validate `create` if exists.\n    const createOperations: CreateOperation[] = [];\n    if (operations.create !== undefined) {\n      if (!Array.isArray(operations.create)) {\n        throw new SidetreeError(ErrorCode.AnchorFileCreatePropertyNotArray);\n      }\n\n      // Validate every create operation.\n      for (const operation of operations.create) {\n        const createOperation = await CreateOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        createOperations.push(createOperation);\n        didUniqueSuffixes.push(createOperation.didUniqueSuffix);\n      }\n    }\n\n    // Validate `recover` if exists.\n    const recoverOperations: RecoverOperation[] = [];\n    if (operations.recover !== undefined) {\n      if (!Array.isArray(operations.recover)) {\n        throw new SidetreeError(ErrorCode.AnchorFileRecoverPropertyNotArray);\n      }\n\n      // Validate every recover operation.\n      for (const operation of operations.recover) {\n        const recoverOperation = await RecoverOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        recoverOperations.push(recoverOperation);\n        didUniqueSuffixes.push(recoverOperation.didUniqueSuffix);\n      }\n    }\n\n    // Validate `deactivate` if exists.\n    const deactivateOperations: DeactivateOperation[] = [];\n    if (operations.deactivate !== undefined) {\n      if (!Array.isArray(operations.deactivate)) {\n        throw new SidetreeError(ErrorCode.AnchorFileDeactivatePropertyNotArray);\n      }\n\n      // Validate every operation.\n      for (const operation of operations.deactivate) {\n        const deactivateOperation = await DeactivateOperation.parseOperationFromAnchorFile(\n          operation\n        );\n        deactivateOperations.push(deactivateOperation);\n        didUniqueSuffixes.push(deactivateOperation.didUniqueSuffix);\n      }\n    }\n\n    if (ArrayMethods.hasDuplicates(didUniqueSuffixes)) {\n      throw new SidetreeError(\n        ErrorCode.AnchorFileMultipleOperationsForTheSameDid\n      );\n    }\n\n    const anchorFile = new AnchorFile(\n      anchorFileModel,\n      didUniqueSuffixes,\n      createOperations,\n      recoverOperations,\n      deactivateOperations\n    );\n    return anchorFile;\n  }\n\n  /**\n   * Creates an `AnchorFileModel`.\n   */\n  public static async createModel(\n    writerLockId: string | undefined,\n    mapFileHash: string,\n    createOperationArray: CreateOperation[],\n    recoverOperationArray: RecoverOperation[],\n    deactivateOperationArray: DeactivateOperation[]\n  ): Promise<AnchorFileModel> {\n    const createOperations = createOperationArray.map((operation) => {\n      return {\n        suffix_data: operation.encodedSuffixData,\n      };\n    });\n\n    const recoverOperations = recoverOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const deactivateOperations = deactivateOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const anchorFileModel = {\n      writer_lock_id: writerLockId,\n      map_file_uri: mapFileHash,\n      operations: {\n        create: createOperations,\n        recover: recoverOperations,\n        deactivate: deactivateOperations,\n      },\n    };\n\n    return anchorFileModel;\n  }\n\n  /**\n   * Creates an anchor file buffer.\n   */\n  public static async createBuffer(\n    writerLockId: string | undefined,\n    mapFileHash: string,\n    createOperations: CreateOperation[],\n    recoverOperations: RecoverOperation[],\n    deactivateOperations: DeactivateOperation[]\n  ): Promise<Buffer> {\n    const anchorFileModel = await AnchorFile.createModel(\n      writerLockId,\n      mapFileHash,\n      createOperations,\n      recoverOperations,\n      deactivateOperations\n    );\n    const anchorFileJson = JSON.stringify(anchorFileModel);\n    const anchorFileBuffer = Buffer.from(anchorFileJson);\n\n    return Compressor.compress(anchorFileBuffer);\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { IBlockchain, IVersionManager } from '@sidetree/common';\nimport timeSpan from 'time-span';\n\n/**\n * Class that performs periodic writing of batches of Sidetree operations to CAS and blockchain.\n */\nexport default class BatchScheduler {\n  /**\n   * Denotes if the periodic batch writing should continue to occur.\n   * Used mainly for test purposes.\n   */\n  private continuePeriodicBatchWriting = false;\n\n  public constructor(\n    private versionManager: IVersionManager,\n    private blockchain: IBlockchain,\n    private batchingIntervalInSeconds: number\n  ) {}\n\n  /**\n   * The function that starts periodically anchoring operation batches to blockchain.\n   */\n  public startPeriodicBatchWriting() {\n    this.continuePeriodicBatchWriting = true;\n    setImmediate(async () => this.writeOperationBatch());\n  }\n\n  /**\n   * Stops periodic batch writing.\n   * Mainly used for test purposes.\n   */\n  public stopPeriodicBatchWriting() {\n    console.info(`Stopped periodic batch writing.`);\n    this.continuePeriodicBatchWriting = false;\n  }\n\n  /**\n   * Processes the operations in the queue.\n   */\n  public async writeOperationBatch() {\n    const endTimer = timeSpan(); // For calcuating time taken to write operations.\n\n    try {\n      console.info('Start operation batch writing...');\n\n      // Get the correct version of the `BatchWriter`.\n      const currentTime = this.blockchain.approximateTime.time;\n      const batchWriter = this.versionManager.getBatchWriter(currentTime);\n\n      await batchWriter.write();\n    } catch (error) {\n      console.error(\n        'Unexpected and unhandled error during batch writing, investigate and fix:'\n      );\n      console.error(error);\n    } finally {\n      console.info(`End batch writing. Duration: ${endTimer.rounded()} ms.`);\n\n      if (this.continuePeriodicBatchWriting) {\n        console.info(\n          `Waiting for ${this.batchingIntervalInSeconds} seconds before writing another batch.`\n        );\n        setTimeout(\n          async () => this.writeOperationBatch(),\n          this.batchingIntervalInSeconds * 1000\n        );\n      }\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ChunkFileModel,\n  ErrorCode,\n  SidetreeError,\n  protocolParameters,\n} from '@sidetree/common';\nimport timeSpan from 'time-span';\nimport CreateOperation from '../CreateOperation';\nimport RecoverOperation from '../RecoverOperation';\nimport UpdateOperation from '../UpdateOperation';\nimport Compressor from '../util/Compressor';\nimport JsonAsync from '../util/JsonAsync';\n\n/**\n * Defines schema of a Chunk File and its related operations.\n * NOTE: Must NOT add properties not defined by Sidetree protocol.\n */\nexport default class ChunkFile {\n  /**\n   * Parses and validates the given chunk file buffer and all the operations within it.\n   * @throws SidetreeError if failed parsing or validation.\n   */\n  public static async parse(chunkFileBuffer: Buffer): Promise<ChunkFileModel> {\n    const endTimer = timeSpan();\n    const decompressedChunkFileBuffer = await Compressor.decompress(\n      chunkFileBuffer\n    );\n    const chunkFileObject = await JsonAsync.parse(decompressedChunkFileBuffer);\n    console.info(`Parsed chunk file in ${endTimer.rounded()} ms.`);\n\n    // Ensure only properties specified by Sidetree protocol are given.\n    const allowedProperties = new Set(['deltas']);\n    for (const property in chunkFileObject) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileUnexpectedProperty,\n          `Unexpected property ${property} in chunk file.`\n        );\n      }\n    }\n\n    this.validateDeltasProperty(chunkFileObject.deltas);\n\n    return chunkFileObject;\n  }\n\n  private static validateDeltasProperty(deltas: any) {\n    // Make sure deltas is an array.\n    if (!(deltas instanceof Array)) {\n      throw new SidetreeError(\n        ErrorCode.ChunkFileDeltasPropertyNotArray,\n        'Invalid chunk file, deltas property is not an array.'\n      );\n    }\n\n    // Validate every encoded delta string.\n    for (const encodedDelta of deltas) {\n      if (typeof encodedDelta !== 'string') {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileDeltasNotArrayOfStrings,\n          'Invalid chunk file, deltas property is not an array of strings.'\n        );\n      }\n\n      const deltaBuffer = Buffer.from(encodedDelta);\n\n      // Verify size of each delta does not exceed the maximum allowed limit.\n      if (deltaBuffer.length > protocolParameters.maxDeltaSizeInBytes) {\n        throw new SidetreeError(\n          ErrorCode.ChunkFileDeltaSizeExceedsLimit,\n          `Operation size of ${deltaBuffer.length} bytes exceeds the allowed limit of ${protocolParameters.maxDeltaSizeInBytes} bytes.`\n        );\n      }\n    }\n  }\n\n  /**\n   * Creates chunk file buffer.\n   */\n  public static async createBuffer(\n    createOperations: CreateOperation[],\n    recoverOperations: RecoverOperation[],\n    updateOperations: UpdateOperation[]\n  ) {\n    const deltas = [];\n    deltas.push(\n      ...createOperations.map((operation) => operation.encodedDelta!)\n    );\n    deltas.push(\n      ...recoverOperations.map((operation) => operation.encodedDelta!)\n    );\n    deltas.push(\n      ...updateOperations.map((operation) => operation.encodedDelta!)\n    );\n\n    const chunkFileModel = {\n      deltas,\n    };\n\n    const rawData = Buffer.from(JSON.stringify(chunkFileModel));\n    const compressedRawData = await Compressor.compress(Buffer.from(rawData));\n\n    return compressedRawData;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as crypto from 'crypto';\nimport { ICas, FetchResult } from '@sidetree/common';\n\n/**\n * Interface containing information regarding each queued CAS download.\n */\ninterface DownloadInfo {\n  /**\n   * A globally unique handle to this download.\n   */\n  handle: Buffer;\n\n  /**\n   * The content hash used to perform the download from CAS.\n   */\n  contentHash: string;\n\n  /**\n   * The maximum allowed content size.\n   */\n  maxSizeInBytes: number;\n\n  /**\n   * The resolve function that will be invoked by the download manager when download is completed\n   * regarless if the download is successful or not.\n   */\n  resolve: (value?: any | PromiseLike<any> | undefined) => void;\n\n  /**\n   * Set to true if download attempt is completed either successfully or unsuccessfully.\n   */\n  completed: boolean;\n\n  /**\n   * Holds the fetch result once the download is completed.\n   */\n  fetchResult?: FetchResult;\n}\n\n/**\n * A download manager class that performs multiple downloads at the same time.\n */\nexport default class DownloadManager {\n  private pendingDownloads: DownloadInfo[] = [];\n  private activeDownloads: Map<Buffer, DownloadInfo> = new Map();\n  private completedDownloads: Map<Buffer, FetchResult> = new Map();\n\n  /**\n   * Constructs the download manager.\n   * @param cas The Content Adressable Store to use for fetching the actual content.\n   */\n  public constructor(public maxConcurrentDownloads: number, private cas: ICas) {\n    // If maximum concurrent CAS download count is NaN, set it to a default value.\n    if (isNaN(maxConcurrentDownloads)) {\n      const defaultmaxConcurrentDownloads = 20;\n      console.info(\n        `Maximum concurrent CAS download count not given, defaulting to ${defaultmaxConcurrentDownloads}.`\n      );\n      this.maxConcurrentDownloads = defaultmaxConcurrentDownloads;\n    }\n  }\n\n  /**\n   * Starts pending downloads if maximum concurrent download count is not reached,\n   * and resolve downloads that are completed, then invokes this same method again,\n   * thus this method must only be invoked once externally as initialization.\n   */\n  public start() {\n    try {\n      // Move all completed downloads in `activeDownloads` to the `completedDownloads` map.\n      const completedDownloadHandles = [];\n      for (const [downloadHandle, downloadInfo] of this.activeDownloads) {\n        if (downloadInfo.completed) {\n          this.completedDownloads.set(\n            downloadHandle,\n            downloadInfo.fetchResult!\n          );\n          completedDownloadHandles.push(downloadHandle);\n\n          // Resolve the promise associated with the download.\n          downloadInfo.resolve();\n        }\n      }\n      for (const downloadHandle of completedDownloadHandles) {\n        this.activeDownloads.delete(downloadHandle);\n      }\n\n      // If maximum concurrent download count is reached, then we can't schedule more downloads.\n      const availableDownloadLanes =\n        this.maxConcurrentDownloads - this.activeDownloads.size;\n      if (availableDownloadLanes <= 0) {\n        return;\n      }\n\n      // Else we can schedule more downloads, but only if there are pending downloads.\n      if (this.pendingDownloads.length === 0) {\n        return;\n      }\n\n      // Keep start downloading the next queued item until all download lanes are full or there is no more item to download.\n      for (\n        let i = 0;\n        i < this.pendingDownloads.length && i < availableDownloadLanes;\n        i++\n      ) {\n        const downloadInfo = this.pendingDownloads[i];\n\n        // Intentionally not awaiting on a download.\n        void this.downloadAsync(downloadInfo);\n        this.activeDownloads.set(downloadInfo.handle, downloadInfo);\n      }\n\n      // Remove active downloads from `pendingDownloads` list.\n      this.pendingDownloads.splice(0, availableDownloadLanes);\n    } catch (error) {\n      console.error(\n        `Encountered unhandled/unexpected error in DownloadManager, must investigate and fix: ${error}`\n      );\n    } finally {\n      setTimeout(async () => this.start(), 1000);\n    }\n  }\n\n  /**\n   * Downloads the content of the given content hash.\n   * @param contentHash Hash of the content to be downloaded.\n   */\n  public async download(\n    contentHash: string,\n    maxSizeInBytes: number\n  ): Promise<FetchResult> {\n    const handle = crypto.randomBytes(32);\n    const fetchPromise = new Promise((resolve) => {\n      const downloadInfo = {\n        handle,\n        contentHash,\n        maxSizeInBytes,\n        resolve,\n        completed: false,\n        content: undefined,\n      };\n      this.pendingDownloads.push(downloadInfo);\n    });\n\n    await fetchPromise;\n\n    const fetchResult = this.completedDownloads.get(handle);\n    this.completedDownloads.delete(handle);\n\n    return fetchResult!;\n  }\n\n  /**\n   * The internal download method that gets called by the main download manager monitoring loop when download lanes are available to download content.\n   * NOTE: This method MUST NEVER throw (more accurately: ALWAYS set downloadInfo.completed = true),\n   * else it will LEAK the available download lanes and in turn hang the Observer.\n   * @param downloadInfo Data structure containing `completed` flag and `fetchResult`,\n   *                     used to signal to the main download manager monitoring loop when the requested download is completed.\n   */\n  private async downloadAsync(downloadInfo: DownloadInfo): Promise<void> {\n    let contentHash = '';\n    try {\n      contentHash = downloadInfo.contentHash;\n\n      const fetchResult = await this.cas.read(\n        contentHash\n        // downloadInfo.maxSizeInBytes\n      );\n\n      downloadInfo.fetchResult = fetchResult;\n    } catch (error) {\n      console.error(\n        `Unexpected error while downloading '${contentHash}, investigate and fix ${error}'.`\n      );\n    } finally {\n      downloadInfo.completed = true;\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DeltaModel,\n  Encoder,\n  ErrorCode,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport JsonAsync from './util/JsonAsync';\nimport Jwk from './util/Jwk';\nimport Jws from './util/Jws';\nimport OperationUtils from './OperationUtils';\n\ninterface SignedDataModel {\n  delta_hash: string;\n  update_key: PublicKeyJwk;\n}\n\n/**\n * A class that represents an update operation.\n */\nexport default class UpdateOperation implements OperationModel {\n  /** The original request buffer sent by the requester. */\n  public readonly operationBuffer: Buffer;\n\n  /** The unique suffix of the DID. */\n  public readonly didUniqueSuffix: string;\n\n  /** The type of operation. */\n  public readonly type: OperationType;\n\n  /** Signed data for the operation. */\n  public readonly signedDataJws: Jws;\n\n  /** Decoded signed data payload. */\n  public readonly signedData: SignedDataModel;\n\n  /** Patch data. */\n  public readonly delta: DeltaModel | undefined;\n\n  /** Encoded string of the delta. */\n  public readonly encodedDelta: string | undefined;\n\n  /**\n   * NOTE: should only be used by `parse()` and `parseObject()` else the contructed instance could be invalid.\n   */\n  private constructor(\n    operationBuffer: Buffer,\n    didUniqueSuffix: string,\n    signedDataJws: Jws,\n    signedData: SignedDataModel,\n    encodedDelta: string | undefined,\n    delta: DeltaModel | undefined\n  ) {\n    this.operationBuffer = operationBuffer;\n    this.type = OperationType.Update;\n    this.didUniqueSuffix = didUniqueSuffix;\n    this.signedDataJws = signedDataJws;\n    this.signedData = signedData;\n    this.encodedDelta = encodedDelta;\n    this.delta = delta;\n  }\n\n  /**\n   * Parses the given input as an update operation entry in the map file.\n   */\n  public static async parseOperationFromMapFile(\n    input: any\n  ): Promise<UpdateOperation> {\n    const operationBuffer = Buffer.from(JSON.stringify(input));\n    const operation = await UpdateOperation.parseObject(\n      input,\n      operationBuffer,\n      true\n    );\n    return operation;\n  }\n\n  /**\n   * Parses the given buffer as a `UpdateOperation`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<UpdateOperation> {\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = await JsonAsync.parse(operationJsonString);\n    const updateOperation = await UpdateOperation.parseObject(\n      operationObject,\n      operationBuffer,\n      false\n    );\n    return updateOperation;\n  }\n\n  /**\n   * Parses the given operation object as a `UpdateOperation`.\n   * The `operationBuffer` given is assumed to be valid and is assigned to the `operationBuffer` directly.\n   * NOTE: This method is purely intended to be used as an optimization method over the `parse` method in that\n   * JSON parsing is not required to be performed more than once when an operation buffer of an unknown operation type is given.\n   * @param mapFileMode If set to true, then `delta` and `type` properties are expected to be absent.\n   */\n  public static async parseObject(\n    operationObject: any,\n    operationBuffer: Buffer,\n    mapFileMode: boolean\n  ): Promise<UpdateOperation> {\n    let expectedPropertyCount = 4;\n    if (mapFileMode) {\n      expectedPropertyCount = 2;\n    }\n\n    const properties = Object.keys(operationObject);\n    if (properties.length !== expectedPropertyCount) {\n      throw new SidetreeError(\n        ErrorCode.UpdateOperationMissingOrUnknownProperty\n      );\n    }\n\n    if (typeof operationObject.did_suffix !== 'string') {\n      throw new SidetreeError(ErrorCode.UpdateOperationMissingDidUniqueSuffix);\n    }\n\n    const signedData = Jws.parseCompactJws(operationObject.signed_data);\n    const signedDataModel = await UpdateOperation.parseSignedDataPayload(\n      signedData.payload\n    );\n\n    // If not in map file mode, we need to validate `type` and `delta` properties.\n    let encodedDelta = undefined;\n    let delta = undefined;\n    if (!mapFileMode) {\n      if (operationObject.type !== OperationType.Update) {\n        throw new SidetreeError(ErrorCode.UpdateOperationTypeIncorrect);\n      }\n\n      encodedDelta = operationObject.delta;\n      delta = await OperationUtils.parseDelta(encodedDelta);\n    }\n\n    return new UpdateOperation(\n      operationBuffer,\n      operationObject.did_suffix,\n      signedData,\n      signedDataModel,\n      encodedDelta,\n      delta\n    );\n  }\n\n  private static async parseSignedDataPayload(\n    signedDataEncodedString: string\n  ): Promise<SignedDataModel> {\n    const signedDataJsonString = Encoder.decodeAsString(\n      signedDataEncodedString\n    );\n    const signedData = await JsonAsync.parse(signedDataJsonString);\n\n    const properties = Object.keys(signedData);\n    if (properties.length !== 2) {\n      throw new SidetreeError(\n        ErrorCode.UpdateOperationSignedDataHasMissingOrUnknownProperty\n      );\n    }\n\n    Jwk.validatePublicJwk(signedData.update_key);\n\n    const delta_hash = Encoder.decodeAsBuffer(signedData.delta_hash);\n    Multihash.verifyHashComputedUsingLatestSupportedAlgorithm(delta_hash);\n\n    return {\n      delta_hash: signedData.delta_hash,\n      update_key: signedData.update_key,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorCode, MapFileModel, SidetreeError } from '@sidetree/common';\nimport UpdateOperation from '../UpdateOperation';\nimport ArrayMethods from '../util/ArrayMethods';\nimport Compressor from '../util/Compressor';\nimport JsonAsync from '../util/JsonAsync';\n\n/**\n * Class containing Map File related operations.\n */\nexport default class MapFile {\n  /**\n   * Class that represents a map file.\n   * NOTE: this class is introduced as an internal structure in replacement to `MapFileModel`\n   * to keep useful metadata so that repeated computation can be avoided.\n   */\n  private constructor(\n    public readonly model: MapFileModel,\n    public readonly didUniqueSuffixes: string[],\n    public readonly updateOperations: UpdateOperation[]\n  ) {}\n\n  /**\n   * Parses and validates the given map file buffer.\n   * @throws `SidetreeError` if failed parsing or validation.\n   */\n  public static async parse(mapFileBuffer: Buffer): Promise<MapFile> {\n    let decompressedBuffer;\n    try {\n      decompressedBuffer = await Compressor.decompress(mapFileBuffer);\n    } catch (error) {\n      throw SidetreeError.createFromError(\n        ErrorCode.MapFileDecompressionFailure,\n        error\n      );\n    }\n\n    let mapFileModel;\n    try {\n      mapFileModel = await JsonAsync.parse(decompressedBuffer);\n    } catch (error) {\n      throw SidetreeError.createFromError(ErrorCode.MapFileNotJson, error);\n    }\n\n    const allowedProperties = new Set(['chunks', 'operations']);\n    for (const property in mapFileModel) {\n      if (!allowedProperties.has(property)) {\n        throw new SidetreeError(ErrorCode.MapFileHasUnknownProperty);\n      }\n    }\n\n    MapFile.validateChunksProperty(mapFileModel.chunks);\n\n    const updateOperations = await MapFile.parseOperationsProperty(\n      mapFileModel.operations\n    );\n    const didUniqueSuffixes = updateOperations.map(\n      (operation) => operation.didUniqueSuffix\n    );\n\n    const mapFile = new MapFile(\n      mapFileModel,\n      didUniqueSuffixes,\n      updateOperations\n    );\n    return mapFile;\n  }\n\n  /**\n   * Validates the given `operations` property, throws error if the property fails validation.\n   */\n  private static async parseOperationsProperty(\n    operations: any\n  ): Promise<UpdateOperation[]> {\n    if (operations === undefined) {\n      return [];\n    }\n\n    const properties = Object.keys(operations);\n    if (properties.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileOperationsPropertyHasMissingOrUnknownProperty\n      );\n    }\n\n    const updateOperations: UpdateOperation[] = [];\n    if (!Array.isArray(operations.update)) {\n      throw new SidetreeError(ErrorCode.MapFileUpdateOperationsNotArray);\n    }\n\n    // Validate each update operation.\n    for (const operation of operations.update) {\n      const updateOperation = await UpdateOperation.parseOperationFromMapFile(\n        operation\n      );\n      updateOperations.push(updateOperation);\n    }\n\n    // Make sure no operation with same DID.\n    const didUniqueSuffixes = updateOperations.map(\n      (operation) => operation.didUniqueSuffix\n    );\n    if (ArrayMethods.hasDuplicates(didUniqueSuffixes)) {\n      throw new SidetreeError(ErrorCode.MapFileMultipleOperationsForTheSameDid);\n    }\n\n    return updateOperations;\n  }\n\n  /**\n   * Validates the given `chunks` property, throws error if the property fails validation.\n   */\n  private static validateChunksProperty(chunks: any) {\n    if (!Array.isArray(chunks)) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunksPropertyMissingOrIncorrectType\n      );\n    }\n\n    // This version expects only one hash.\n    if (chunks.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunksPropertyDoesNotHaveExactlyOneElement\n      );\n    }\n\n    const chunk = chunks[0];\n    const properties = Object.keys(chunk);\n    if (properties.length !== 1) {\n      throw new SidetreeError(\n        ErrorCode.MapFileChunkHasMissingOrUnknownProperty\n      );\n    }\n  }\n\n  /**\n   * Creates the Map File buffer.\n   */\n  public static async createBuffer(\n    chunkFileHash: string,\n    updateOperationArray: UpdateOperation[]\n  ): Promise<Buffer> {\n    const updateOperations = updateOperationArray.map((operation) => {\n      return {\n        did_suffix: operation.didUniqueSuffix,\n        signed_data: operation.signedDataJws.toCompactJws(),\n      };\n    });\n\n    const mapFileModel: MapFileModel = {\n      chunks: [{ chunk_file_uri: chunkFileHash }],\n    };\n\n    // Only insert an `operations` property if there are update operations.\n    if (updateOperations.length > 0) {\n      mapFileModel.operations = {\n        update: updateOperations,\n      };\n    }\n\n    const rawData = JSON.stringify(mapFileModel);\n    const compressedRawData = await Compressor.compress(Buffer.from(rawData));\n\n    return compressedRawData;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { IVersionManager, TransactionModel } from '@sidetree/common';\n\n/**\n * Keeps track of current block and throughput limits based on the state\n */\nexport default class ThroughputLimiter {\n  constructor(private versionManager: IVersionManager) {}\n\n  /**\n   * given a an array of transactions, return an array of qualified transactions per transaction time.\n   * @param transactions array of transactions to filter for\n   */\n  public async getQualifiedTransactions(transactions: TransactionModel[]) {\n    let currentTransactionTime: number | undefined = undefined;\n    const transactionsGroupedByTransactionTime: TransactionModel[][] = [];\n\n    for (const transaction of transactions) {\n      // If transaction is transitioning into a new time, create a new grouping.\n      if (transaction.transactionTime !== currentTransactionTime) {\n        transactionsGroupedByTransactionTime.push([]);\n        currentTransactionTime = transaction.transactionTime;\n      }\n      transactionsGroupedByTransactionTime[\n        transactionsGroupedByTransactionTime.length - 1\n      ].push(transaction);\n    }\n\n    const qualifiedTransactions: TransactionModel[] = [];\n    for (const transactionGroup of transactionsGroupedByTransactionTime) {\n      const transactionSelector = this.versionManager.getTransactionSelector(\n        transactionGroup[0].transactionTime\n      );\n      const qualifiedTransactionsInCurrentGroup = await transactionSelector.selectQualifiedTransactions(\n        transactionGroup\n      );\n      qualifiedTransactions.push(...qualifiedTransactionsInCurrentGroup);\n    }\n    return qualifiedTransactions;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  IBlockchain,\n  IOperationStore,\n  ITransactionProcessor,\n  ITransactionStore,\n  IUnresolvableTransactionStore,\n  IVersionManager,\n  SharedErrorCode,\n  SidetreeError,\n  TransactionModel,\n  TransactionUnderProcessingModel,\n  TransactionProcessingStatus,\n} from '@sidetree/common';\nimport timeSpan from 'time-span';\nimport ThroughputLimiter from './ThroughputLimiter';\n\n/**\n * Class that performs periodic processing of batches of Sidetree operations anchored to the blockchain.\n */\nexport default class Observer {\n  /**\n   * Denotes if the periodic transaction processing should continue to occur.\n   * Used mainly for test purposes.\n   */\n  private continuePeriodicProcessing = false;\n\n  /**\n   * The list of transactions that are being downloaded or processed.\n   */\n  private transactionsUnderProcessing: TransactionUnderProcessingModel[] = [];\n\n  /**\n   * This is the transaction that is used as a timestamp to fetch newer transaction.\n   */\n  private lastKnownTransaction: TransactionModel | undefined;\n\n  private throughputLimiter: ThroughputLimiter;\n\n  public constructor(\n    private versionManager: IVersionManager,\n    private blockchain: IBlockchain,\n    private maxConcurrentDownloads: number,\n    private operationStore: IOperationStore,\n    private transactionStore: ITransactionStore,\n    private unresolvableTransactionStore: IUnresolvableTransactionStore,\n    private observingIntervalInSeconds: number\n  ) {\n    this.throughputLimiter = new ThroughputLimiter(versionManager);\n  }\n\n  public async refreshLastKnownTransaction(): Promise<void> {\n    this.lastKnownTransaction = await this.transactionStore.getLastTransaction();\n  }\n\n  /**\n   * The method that starts the periodic polling and processing of Sidetree operations.\n   */\n  public async startPeriodicProcessing(): Promise<void> {\n    // Initialize the last known transaction before starting processing.\n    await this.refreshLastKnownTransaction();\n\n    console.info(`Starting periodic transactions processing.`);\n    setImmediate(async () => {\n      this.continuePeriodicProcessing = true;\n\n      // tslint:disable-next-line:no-floating-promises - this.processTransactions() never throws.\n      this.processTransactions();\n    });\n  }\n\n  /**\n   * Stops periodic transaction processing.\n   * Mainly used for test purposes.\n   */\n  public stopPeriodicProcessing(): void {\n    console.info(`Stopped periodic transactions processing.`);\n    this.continuePeriodicProcessing = false;\n  }\n\n  /**\n   * Processes new transactions if any, then reprocess a set of unresolvable transactions if any,\n   * then schedules the next round of processing unless `stopPeriodicProcessing()` is invoked.\n   */\n  public async processTransactions(\n    awaitTransactionProcessing = false\n  ): Promise<void> {\n    try {\n      await this.storeConsecutiveTransactionsProcessed(); // Do this in multiple places\n\n      // Keep fetching new Sidetree transactions from blockchain and processing them\n      // until there are no more new transactions or there is a block reorganization.\n      let moreTransactions = false;\n      do {\n        // Get the last transaction to be used as a timestamp to fetch new transactions.\n        const lastKnownTransactionNumber = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionNumber\n          : undefined;\n        const lastKnownTransactionTimeHash = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionTimeHash\n          : undefined;\n        const lastKnownTransactionTime = this.lastKnownTransaction\n          ? this.lastKnownTransaction.transactionTime\n          : 0;\n\n        let invalidTransactionNumberOrTimeHash = false;\n        let readResult;\n        const endTimer = timeSpan(); // Measure time taken to go blockchain read.\n        try {\n          console.info(\n            'Fetching Sidetree transactions from blockchain service...'\n          );\n          const nextTransactionNumber =\n            lastKnownTransactionNumber !== undefined\n              ? lastKnownTransactionNumber + 1\n              : undefined;\n          readResult = await this.blockchain.read(\n            nextTransactionNumber,\n            lastKnownTransactionTimeHash\n          );\n          console.info(\n            `Fetched ${\n              readResult.transactions.length\n            } Sidetree transactions from blockchain service in ${endTimer.rounded()} ms.`\n          );\n        } catch (error) {\n          if (\n            error instanceof SidetreeError &&\n            error.code === SharedErrorCode.InvalidTransactionNumberOrTimeHash\n          ) {\n            console.info(\n              `Invalid transaction number ${lastKnownTransactionNumber} or time hash ${lastKnownTransactionTimeHash} given to blockchain service.`\n            );\n            invalidTransactionNumberOrTimeHash = true;\n          } else {\n            throw error;\n          }\n        }\n\n        const transactions = readResult ? readResult.transactions : [];\n        moreTransactions = readResult ? readResult.moreTransactions : false;\n        let qualifiedTransactions = await this.throughputLimiter.getQualifiedTransactions(\n          transactions\n        );\n        qualifiedTransactions = qualifiedTransactions.sort(\n          (\n            a: { transactionNumber: number },\n            b: { transactionNumber: number }\n          ) => {\n            return a.transactionNumber - b.transactionNumber;\n          }\n        );\n\n        // Queue parallel downloading and processing of chunk files.\n        for (const transaction of qualifiedTransactions) {\n          const awaitingTransaction = {\n            transaction: transaction,\n            processingStatus: TransactionProcessingStatus.Pending,\n          };\n          this.transactionsUnderProcessing.push(awaitingTransaction);\n          if (awaitTransactionProcessing) {\n            await this.processTransaction(transaction, awaitingTransaction);\n          } else {\n            // Intentionally not awaiting on downloading and processing each operation batch.\n            void this.processTransaction(transaction, awaitingTransaction);\n          }\n        }\n\n        // NOTE: Blockchain reorg has happened for sure only if `invalidTransactionNumberOrTimeHash` AND\n        // latest transaction time is less or equal to blockchain service time.\n        // This check will prevent Core from reverting transactions if/when blockchain service is reinitializing its data itself.\n        let blockReorganizationDetected = false;\n        if (invalidTransactionNumberOrTimeHash) {\n          if (\n            lastKnownTransactionTime <= this.blockchain.approximateTime.time\n          ) {\n            blockReorganizationDetected = true;\n            moreTransactions = true;\n          } else {\n            console.info(\n              `Blockchain microservice blockchain time is behind last known transaction time, waiting for blockchain microservice to catch up...`\n            );\n          }\n        }\n\n        // If block reorg is detected, we must wait until no more operation processing is pending,\n        // then revert invalid transaction and operations.\n        if (blockReorganizationDetected) {\n          console.info(`Block reorganization detected.`);\n          await this.waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n            0\n          );\n\n          console.info(`Reverting invalid transactions...`);\n          await this.revertInvalidTransactions();\n          console.info(`Completed reverting invalid transactions.`);\n        } else {\n          // Else it means transaction fetch was successful:\n          // We hold off from fetching more transactions if the list of transactions under processing gets too long.\n          // We will wait for count of transaction being processed to fall to the maximum allowed concurrent downloads\n          // before attempting further transaction fetches.\n          await this.waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n            this.maxConcurrentDownloads\n          );\n        }\n\n        // Update the last known transaction.\n        // NOTE: In case of block reorg, last known transaction will be updated in `this.RevertInvalidTransactions()` method.\n        if (transactions && transactions.length > 0) {\n          this.lastKnownTransaction = transactions[transactions.length - 1];\n        }\n      } while (moreTransactions);\n\n      await this.storeConsecutiveTransactionsProcessed();\n      console.info(\n        'Successfully kicked off downloading/processing of all new Sidetree transactions.'\n      );\n\n      // Continue onto processing unresolvable transactions if any.\n      await this.processUnresolvableTransactions(awaitTransactionProcessing);\n    } catch (error) {\n      console.error(\n        `Encountered unhandled and possibly fatal Observer error, must investigate and fix:`\n      );\n      console.error(error);\n    } finally {\n      if (this.continuePeriodicProcessing) {\n        console.info(\n          `Waiting for ${this.observingIntervalInSeconds} seconds before fetching and processing transactions again.`\n        );\n        setTimeout(\n          async () => this.processTransactions(),\n          this.observingIntervalInSeconds * 1000\n        );\n      }\n    }\n  }\n\n  private async waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo(\n    count: number\n  ): Promise<void> {\n    while (this.transactionsUnderProcessing.length > count) {\n      // Store the consecutively processed transactions in the transaction store.\n      await this.storeConsecutiveTransactionsProcessed();\n\n      // Wait a little before checking again.\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n\n    return;\n  }\n\n  /**\n   * Attempts to fetch and process unresolvable transactions due for retry.\n   * Waits until all unresolvable transactions due for retry are processed.\n   */\n  private async processUnresolvableTransactions(\n    awaitTransactionProcessing = false\n  ): Promise<void> {\n    const endTimer = timeSpan();\n    const unresolvableTransactions = await this.unresolvableTransactionStore.getUnresolvableTransactionsDueForRetry();\n    console.info(\n      `Fetched ${\n        unresolvableTransactions.length\n      } unresolvable transactions to retry in ${endTimer.rounded()} ms.`\n    );\n\n    // Download and process each unresolvable transactions.\n    const unresolvableTransactionStatus = [];\n    for (const transaction of unresolvableTransactions) {\n      const awaitingTransaction = {\n        transaction: transaction,\n        processingStatus: TransactionProcessingStatus.Pending,\n      };\n      unresolvableTransactionStatus.push(awaitingTransaction);\n      // Intentionally not awaiting on downloading and processing each operation batch.\n      if (awaitTransactionProcessing) {\n        await this.processTransaction(transaction, awaitingTransaction);\n      } else {\n        // Intentionally not awaiting on downloading and processing each operation batch.\n        void this.processTransaction(transaction, awaitingTransaction);\n      }\n    }\n\n    // Wait until all unresolvable transactions are processed,\n    while (unresolvableTransactionStatus.length > 0) {\n      // Find the index of the first transaction that is not processed yet.\n      let i = 0;\n      while (\n        i < unresolvableTransactionStatus.length &&\n        unresolvableTransactionStatus[i].processingStatus ===\n          TransactionProcessingStatus.Processed\n      ) {\n        i++;\n      }\n\n      // Trim the parallelized transaction list.\n      unresolvableTransactionStatus.splice(0, i);\n\n      // Wait a little before checking again.\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n  }\n\n  /**\n   * Goes through the `transactionsUnderProcessing` in chronological order, records each processed transaction\n   * in the transaction store and remove it from `transactionsUnderProcessing` until a transaction that has not been processed yet is hit.\n   */\n  private async storeConsecutiveTransactionsProcessed(): Promise<void> {\n    let i = 0;\n    while (\n      i < this.transactionsUnderProcessing.length &&\n      this.transactionsUnderProcessing[i].processingStatus ===\n        TransactionProcessingStatus.Processed\n    ) {\n      await this.transactionStore.addTransaction(\n        this.transactionsUnderProcessing[i].transaction\n      );\n      i++;\n    }\n\n    // Trim the transaction list.\n    this.transactionsUnderProcessing.splice(0, i);\n  }\n\n  /**\n   * Processes the given transaction by passing the transaction to the right version of the transaction processor based on the transaction time.\n   * The transaction processing generically involves first downloading DID operation data from CAS (Content Addressable Storage),\n   * then storing the operations indexed/grouped by DIDs in the persistent operation DB.\n   */\n  private async processTransaction(\n    transaction: TransactionModel,\n    transactionUnderProcessing: TransactionUnderProcessingModel\n  ): Promise<void> {\n    let transactionProcessedSuccessfully;\n\n    try {\n      const transactionProcessor: ITransactionProcessor = this.versionManager.getTransactionProcessor(\n        transaction.transactionTime\n      );\n      transactionProcessedSuccessfully = await transactionProcessor.processTransaction(\n        transaction\n      );\n    } catch (error) {\n      console.error(\n        `Unhandled error encountered processing transaction '${transaction.transactionNumber}'.`\n      );\n      console.error(error);\n      transactionProcessedSuccessfully = false;\n    } finally {\n      // Purposely setting processing status first before rest of the code to prevent any possibility of deadlocking the Observer.\n      console.info(\n        `Finished processing transaction '${transaction.transactionNumber}'.`\n      );\n      transactionUnderProcessing.processingStatus =\n        TransactionProcessingStatus.Processed;\n\n      if (transactionProcessedSuccessfully) {\n        console.info(\n          `Removing transaction '${transaction.transactionNumber}' from unresolvable transactions if exists...`\n        );\n        await this.unresolvableTransactionStore.removeUnresolvableTransaction(\n          transaction\n        );\n      } else {\n        console.info(\n          `Recording failed processing attempt for transaction '${transaction.transactionNumber}'...`\n        );\n        await this.unresolvableTransactionStore.recordUnresolvableTransactionFetchAttempt(\n          transaction\n        );\n      }\n    }\n  }\n\n  /**\n   * Reverts invalid transactions. Used in the event of a block-reorganization.\n   */\n  private async revertInvalidTransactions(): Promise<void> {\n    // Compute a list of exponentially-spaced transactions with their index, starting from the last transaction of the processed transactions.\n    const exponentiallySpacedTransactions = await this.transactionStore.getExponentiallySpacedTransactions();\n\n    // Find a known valid Sidetree transaction that is prior to the block reorganization.\n    const bestKnownValidRecentTransaction = await this.blockchain.getFirstValidTransaction(\n      exponentiallySpacedTransactions\n    );\n\n    const bestKnownValidRecentTransactionNumber =\n      bestKnownValidRecentTransaction === undefined\n        ? undefined\n        : bestKnownValidRecentTransaction.transactionNumber;\n    console.info(\n      `Best known valid recent transaction: ${bestKnownValidRecentTransactionNumber}`\n    );\n\n    // Revert all processed operations that came after the best known valid recent transaction.\n    console.info('Reverting operations...');\n    await this.operationStore.delete(bestKnownValidRecentTransactionNumber);\n\n    // NOTE: MUST do this step LAST to handle incomplete operation rollback due to unexpected scenarios, such as power outage etc.\n    await this.transactionStore.removeTransactionsLaterThan(\n      bestKnownValidRecentTransactionNumber\n    );\n    await this.unresolvableTransactionStore.removeUnresolvableTransactionsLaterThan(\n      bestKnownValidRecentTransactionNumber\n    );\n\n    // Reset the in-memory last known good Transaction so we next processing cycle will fetch from the correct timestamp/maker.\n    this.lastKnownTransaction = bestKnownValidRecentTransaction;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  OperationModel,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport CreateOperation from './CreateOperation';\nimport DeactivateOperation from './DeactivateOperation';\nimport RecoverOperation from './RecoverOperation';\nimport UpdateOperation from './UpdateOperation';\n\n/**\n * A class that contains Sidetree operation utility methods.\n */\nexport default class Operation {\n  /** Maximum allowed encoded reveal value string length. */\n  public static readonly maxEncodedRevealValueLength = 50;\n\n  /**\n   * Parses the given buffer into an `OperationModel`.\n   */\n  public static async parse(operationBuffer: Buffer): Promise<OperationModel> {\n    // Parse request buffer into a JS object.\n    const operationJsonString = operationBuffer.toString();\n    const operationObject = JSON.parse(operationJsonString);\n    const operationType = operationObject.type;\n    const isAnchorFileMode = false;\n\n    if (operationType === OperationType.Create) {\n      return CreateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Update) {\n      return UpdateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Recover) {\n      return RecoverOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else if (operationType === OperationType.Deactivate) {\n      return DeactivateOperation.parseObject(\n        operationObject,\n        operationBuffer,\n        isAnchorFileMode\n      );\n    } else {\n      throw new SidetreeError(ErrorCode.OperationTypeUnknownOrMissing);\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredOperationModel,\n  Encoder,\n  PublicKeyJwk,\n  Multihash,\n  OperationModel,\n  OperationType,\n  PrivateKeyJwk,\n  PublicKeyModel,\n  ServiceEndpointModel,\n  PublicKeyPurpose,\n  DocumentModel,\n  PrivateKeyJwkEd25519,\n} from '@sidetree/common';\nimport * as crypto from 'crypto';\nimport CreateOperation from '../../CreateOperation';\nimport DeactivateOperation from '../../DeactivateOperation';\nimport RecoverOperation from '../../RecoverOperation';\nimport UpdateOperation from '../../UpdateOperation';\nimport Jwk from '../../util/Jwk';\nimport Jws from '../../util/Jws';\n\ninterface AnchoredCreateOperationGenerationInput {\n  transactionNumber: number;\n  transactionTime: number;\n  operationIndex: number;\n}\n\ninterface RecoverOperationGenerationInput {\n  didUniqueSuffix: string;\n  recoveryPrivateKey: PrivateKeyJwk;\n}\n\ninterface GeneratedRecoverOperationData {\n  operationBuffer: Buffer;\n  recoverOperation: RecoverOperation;\n  recoveryPublicKey: PublicKeyJwk;\n  recoveryPrivateKey: PrivateKeyJwk;\n  signingPublicKey: PublicKeyModel;\n  signingPrivateKey: PrivateKeyJwk;\n  update_key: PublicKeyModel;\n  updatePrivateKey: PrivateKeyJwk;\n}\n\n/**\n * A class that can generate valid operations.\n * Mainly useful for testing purposes.\n */\nexport default class OperationGenerator {\n  /**\n   * Generates random hash.\n   */\n  public static generateRandomHash(): string {\n    const randomBuffer = crypto.randomBytes(32);\n    const randomHash = Encoder.encode(Multihash.hash(randomBuffer));\n\n    return randomHash;\n  }\n\n  /**\n   * Generates Ed25519 key pair to be used in an operation. If purpose not supplied, all purposes will be included\n   * Mainly used for testing.\n   * @returns [publicKey, privateKey]\n   */\n  public static async generateKeyPair(\n    id: string,\n    purpose?: PublicKeyPurpose[]\n  ): Promise<[PublicKeyModel, PrivateKeyJwk]> {\n    const [publicKey, privateKey] = await Jwk.generateEd25519KeyPair();\n    const publicKeyModel = {\n      id,\n      type: 'Ed25519VerificationKey2018',\n      jwk: publicKey,\n      purpose: purpose || Object.values(PublicKeyPurpose),\n    };\n\n    return [publicKeyModel, privateKey];\n  }\n\n  /**\n   * Generates an anchored create operation.\n   */\n  public static async generateAnchoredCreateOperation(\n    input: AnchoredCreateOperationGenerationInput\n  ) {\n    const createOperationData = await OperationGenerator.generateCreateOperation();\n\n    const anchoredOperationModel = {\n      type: OperationType.Create,\n      didUniqueSuffix: createOperationData.createOperation.didUniqueSuffix,\n      operationBuffer: createOperationData.createOperation.operationBuffer,\n      transactionNumber: input.transactionNumber,\n      transactionTime: input.transactionTime,\n      operationIndex: input.operationIndex,\n    };\n\n    return {\n      createOperation: createOperationData.createOperation,\n      operationRequest: createOperationData.operationRequest,\n      anchoredOperationModel,\n      recoveryPublicKey: createOperationData.recoveryPublicKey,\n      recoveryPrivateKey: createOperationData.recoveryPrivateKey,\n      updatePublicKey: createOperationData.updatePublicKey,\n      updatePrivateKey: createOperationData.updatePrivateKey,\n      signingPublicKey: createOperationData.signingPublicKey,\n      signingPrivateKey: createOperationData.signingPrivateKey,\n      nextUpdateRevealValueEncodedString:\n        createOperationData.nextUpdateRevealValueEncodedString,\n    };\n  }\n\n  /**\n   * Generates an create operation.\n   */\n  public static async generateCreateOperation() {\n    const signingKeyId = 'signingKey';\n    const [\n      recoveryPublicKey,\n      recoveryPrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      updatePublicKey,\n      updatePrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      signingPublicKey,\n      signingPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(signingKeyId);\n    const service = OperationGenerator.generateServiceEndpoints([\n      'serviceEndpointId123',\n    ]);\n\n    const operationRequest = await OperationGenerator.generateCreateOperationRequest(\n      recoveryPublicKey,\n      updatePublicKey,\n      [signingPublicKey],\n      service\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationRequest));\n\n    const createOperation = await CreateOperation.parse(operationBuffer);\n\n    const nextUpdateRevealValueEncodedString = Multihash.canonicalizeThenHashThenEncode(\n      signingPublicKey.jwk\n    );\n    return {\n      createOperation,\n      operationRequest,\n      recoveryPublicKey,\n      recoveryPrivateKey,\n      updatePublicKey,\n      updatePrivateKey,\n      signingPublicKey,\n      signingPrivateKey,\n      nextUpdateRevealValueEncodedString,\n    };\n  }\n\n  /**\n   * Generates a recover operation.\n   */\n  public static async generateRecoverOperation(\n    input: RecoverOperationGenerationInput\n  ): Promise<GeneratedRecoverOperationData> {\n    const newSigningKeyId = 'newSigningKey';\n    const [\n      newRecoveryPublicKey,\n      newRecoveryPrivateKey,\n    ] = await Jwk.generateEd25519KeyPair();\n    const [\n      newSigningPublicKey,\n      newSigningPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(newSigningKeyId);\n    const [publicKeyToBeInDocument] = await OperationGenerator.generateKeyPair(\n      'newKey'\n    );\n    const services = OperationGenerator.generateServiceEndpoints([\n      'serviceEndpointId123',\n    ]);\n\n    // Generate the next update and recover operation commitment hash reveal value pair.\n    const [\n      update_key,\n      updatePrivateKey,\n    ] = await OperationGenerator.generateKeyPair('update_key');\n\n    const operationJson = await OperationGenerator.generateRecoverOperationRequest(\n      input.didUniqueSuffix,\n      input.recoveryPrivateKey,\n      newRecoveryPublicKey,\n      newSigningPublicKey,\n      services,\n      [publicKeyToBeInDocument]\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationJson));\n    const recoverOperation = await RecoverOperation.parse(operationBuffer);\n\n    return {\n      recoverOperation,\n      operationBuffer,\n      recoveryPublicKey: newRecoveryPublicKey,\n      recoveryPrivateKey: newRecoveryPrivateKey,\n      signingPublicKey: newSigningPublicKey,\n      signingPrivateKey: newSigningPrivateKey,\n      update_key,\n      updatePrivateKey,\n    };\n  }\n\n  /**\n   * Generates an update operation that adds a new key.\n   */\n  public static async generateUpdateOperation(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk\n  ) {\n    const additionalKeyId = `additional-key`;\n    const [\n      additionalPublicKey,\n      additionalPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(additionalKeyId);\n\n    const operationJson = await OperationGenerator.createUpdateOperationRequestForAddingAKey(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      additionalPublicKey,\n      Multihash.canonicalizeThenHashThenEncode(additionalPublicKey)\n    );\n\n    const operationBuffer = Buffer.from(JSON.stringify(operationJson));\n    const updateOperation = await UpdateOperation.parse(operationBuffer);\n\n    return {\n      updateOperation,\n      operationBuffer,\n      additionalKeyId,\n      additionalPublicKey,\n      additionalPrivateKey,\n      nextUpdateKey: additionalPublicKey.jwk,\n    };\n  }\n\n  /**\n   * Creates a named anchored operation model from `OperationModel`.\n   */\n  public static createAnchoredOperationModelFromOperationModel(\n    operationModel: OperationModel,\n    transactionTime: number,\n    transactionNumber: number,\n    operationIndex: number\n  ): AnchoredOperationModel {\n    const anchoredOperationModel: AnchoredOperationModel = {\n      didUniqueSuffix: operationModel.didUniqueSuffix,\n      type: operationModel.type,\n      operationBuffer: operationModel.operationBuffer,\n      operationIndex,\n      transactionNumber,\n      transactionTime,\n    };\n    return anchoredOperationModel;\n  }\n\n  /**\n   * Generates a create operation request.\n   */\n  public static async generateCreateOperationRequest(\n    recoveryPublicKey: PublicKeyJwk,\n    updatePublicKey: PublicKeyJwk,\n    otherPublicKeys: PublicKeyModel[],\n    service_endpoints?: ServiceEndpointModel[]\n  ) {\n    const document: DocumentModel = {\n      public_keys: otherPublicKeys,\n      service_endpoints,\n    };\n\n    const patches = [\n      {\n        action: 'replace',\n        document,\n      },\n    ];\n\n    const delta = {\n      update_commitment: Multihash.canonicalizeThenHashThenEncode(\n        updatePublicKey\n      ),\n      patches,\n    };\n\n    const deltaBuffer = Buffer.from(JSON.stringify(delta));\n    const delta_hash = Encoder.encode(Multihash.hash(deltaBuffer));\n\n    const suffixData = {\n      delta_hash: delta_hash,\n      recovery_commitment: Multihash.canonicalizeThenHashThenEncode(\n        recoveryPublicKey\n      ),\n    };\n\n    const suffixDataEncodedString = Encoder.encode(JSON.stringify(suffixData));\n    const deltaEncodedString = Encoder.encode(deltaBuffer);\n    const operation = {\n      type: OperationType.Create,\n      suffix_data: suffixDataEncodedString,\n      delta: deltaEncodedString,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates an update operation request.\n   */\n  public static async generateUpdateOperationRequest(didUniqueSuffix?: string) {\n    if (didUniqueSuffix === undefined) {\n      didUniqueSuffix = OperationGenerator.generateRandomHash();\n    }\n    const [nextUpdateKey] = await OperationGenerator.generateKeyPair(\n      'nextUpdateKey'\n    );\n    const nextUpdateCommitmentHash = Multihash.canonicalizeThenHashThenEncode(\n      nextUpdateKey.jwk\n    );\n    const anyNewSigningPublicKeyId = 'anyNewKey';\n    const [anyNewSigningKey] = await OperationGenerator.generateKeyPair(\n      anyNewSigningPublicKeyId\n    );\n    const patches = [\n      {\n        action: 'add-public-keys',\n        public_keys: [anyNewSigningKey],\n      },\n    ];\n    const signingKeyId = 'anySigningKeyId';\n    const [\n      signingPublicKey,\n      signingPrivateKey,\n    ] = await OperationGenerator.generateKeyPair(signingKeyId);\n    const request = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      signingPublicKey.jwk,\n      signingPrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    const buffer = Buffer.from(JSON.stringify(request));\n    const updateOperation = await UpdateOperation.parse(buffer);\n\n    return {\n      request,\n      buffer,\n      updateOperation,\n    };\n  }\n\n  /**\n   * Creates an update operation request.\n   */\n  public static async createUpdateOperationRequest(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk,\n    nextUpdateCommitmentHash: string,\n    patches: any\n  ) {\n    const delta = {\n      patches,\n      update_commitment: nextUpdateCommitmentHash,\n    };\n    const deltaJsonString = JSON.stringify(delta);\n    const delta_hash = Encoder.encode(\n      Multihash.hash(Buffer.from(deltaJsonString))\n    );\n    const encodedDeltaString = Encoder.encode(deltaJsonString);\n\n    const signedDataPayloadObject = {\n      update_key: updatePublicKey,\n      delta_hash: delta_hash,\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      updatePrivateKey\n    );\n\n    const updateOperationRequest = {\n      type: OperationType.Update,\n      did_suffix: didUniqueSuffix,\n      delta: encodedDeltaString,\n      signed_data: signedData,\n    };\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Generates a recover operation request.\n   */\n  public static async generateRecoverOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk,\n    newRecoveryPublicKey: PublicKeyJwk,\n    newSigningPublicKey: PublicKeyModel,\n    service_endpoints?: ServiceEndpointModel[],\n    public_keys?: PublicKeyModel[]\n  ) {\n    const document = {\n      public_keys: public_keys,\n      service_endpoints: service_endpoints,\n    };\n    const recoverOperation = await OperationGenerator.createRecoverOperationRequest(\n      didUniqueSuffix,\n      recoveryPrivateKey,\n      newRecoveryPublicKey,\n      Multihash.canonicalizeThenHashThenEncode(newSigningPublicKey.jwk),\n      document\n    );\n    return recoverOperation;\n  }\n\n  /**\n   * Creates a recover operation request.\n   */\n  public static async createRecoverOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk,\n    newRecoveryPublicKey: PublicKeyJwk,\n    nextUpdateCommitmentHash: string,\n    document: any\n  ) {\n    const patches = [\n      {\n        action: 'replace',\n        document,\n      },\n    ];\n\n    const delta = {\n      patches,\n      update_commitment: nextUpdateCommitmentHash,\n    };\n\n    const deltaBuffer = Buffer.from(JSON.stringify(delta));\n    const delta_hash = Encoder.encode(Multihash.hash(deltaBuffer));\n\n    const signedDataPayloadObject = {\n      delta_hash: delta_hash,\n      recovery_key: Jwk.getCurve25519PublicKey(\n        recoveryPrivateKey as PrivateKeyJwkEd25519\n      ),\n      recovery_commitment: Multihash.canonicalizeThenHashThenEncode(\n        newRecoveryPublicKey\n      ),\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      recoveryPrivateKey\n    );\n\n    const deltaEncodedString = Encoder.encode(deltaBuffer);\n    const operation = {\n      type: OperationType.Recover,\n      did_suffix: didUniqueSuffix,\n      signed_data: signedData,\n      delta: deltaEncodedString,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates a deactivate operation request.\n   */\n  public static async createDeactivateOperationRequest(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk\n  ) {\n    const signedDataPayloadObject = {\n      did_suffix: didUniqueSuffix,\n      recovery_key: Jwk.getCurve25519PublicKey(\n        recoveryPrivateKey as PrivateKeyJwkEd25519\n      ),\n    };\n    const signedData = await OperationGenerator.signUsingEd25519(\n      signedDataPayloadObject,\n      recoveryPrivateKey\n    );\n\n    const operation = {\n      type: OperationType.Deactivate,\n      did_suffix: didUniqueSuffix,\n      signed_data: signedData,\n    };\n\n    return operation;\n  }\n\n  /**\n   * Generates a create operation request buffer.\n   * @param nextRecoveryCommitmentHash The encoded commitment hash for the next recovery.\n   * @param nextUpdateCommitmentHash The encoded commitment hash for the next update.\n   */\n  public static async generateCreateOperationBuffer(\n    recoveryPublicKey: PublicKeyJwk,\n    signingPublicKey: PublicKeyModel,\n    service_endpoints?: ServiceEndpointModel[]\n  ): Promise<Buffer> {\n    const operation = await OperationGenerator.generateCreateOperationRequest(\n      recoveryPublicKey,\n      signingPublicKey.jwk,\n      [signingPublicKey],\n      service_endpoints\n    );\n\n    return Buffer.from(JSON.stringify(operation));\n  }\n\n  /**\n   * Creates an update operation for adding a key.\n   */\n  public static async createUpdateOperationRequestForAddingAKey(\n    didUniqueSuffix: string,\n    updatePublicKey: PublicKeyJwk,\n    updatePrivateKey: PrivateKeyJwk,\n    newPublicKey: PublicKeyModel,\n    nextUpdateCommitmentHash: string\n  ) {\n    const patches = [\n      {\n        action: 'add-public-keys',\n        public_keys: [newPublicKey],\n      },\n    ];\n\n    const updateOperationRequest = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Creates an update operation for adding and/or removing hub service endpoints.\n   */\n  public static async createUpdateOperationRequestForHubEndpoints(\n    didUniqueSuffix: string,\n    updatePublicKey: any,\n    updatePrivateKey: PrivateKeyJwk,\n    nextUpdateCommitmentHash: string,\n    idOfServiceEndpointToAdd: string | undefined,\n    idsOfServiceEndpointToRemove: string[]\n  ) {\n    const patches = [];\n\n    if (idOfServiceEndpointToAdd !== undefined) {\n      const patch = {\n        action: 'add-service-endpoints',\n        service_endpoints: OperationGenerator.generateServiceEndpoints([\n          idOfServiceEndpointToAdd,\n        ]),\n      };\n\n      patches.push(patch);\n    }\n\n    if (idsOfServiceEndpointToRemove.length > 0) {\n      const patch = {\n        action: 'remove-service-endpoints',\n        ids: idsOfServiceEndpointToRemove,\n      };\n\n      patches.push(patch);\n    }\n\n    const updateOperationRequest = await OperationGenerator.createUpdateOperationRequest(\n      didUniqueSuffix,\n      updatePublicKey,\n      updatePrivateKey,\n      nextUpdateCommitmentHash,\n      patches\n    );\n\n    return updateOperationRequest;\n  }\n\n  /**\n   * Signs the given payload as a ed25519 compact JWS.\n   */\n  public static async signUsingEd25519(\n    payload: any,\n    privateKey: PrivateKeyJwk\n  ): Promise<string> {\n    const protectedHeader = {\n      alg: 'EdDSA',\n    };\n\n    const compactJws = await Jws.signAsCompactJws(\n      payload,\n      privateKey,\n      protectedHeader\n    );\n    return compactJws;\n  }\n\n  /**\n   * Generates a Deactivate Operation data.\n   */\n  public static async createDeactivateOperation(\n    didUniqueSuffix: string,\n    recoveryPrivateKey: PrivateKeyJwk\n  ) {\n    const operationRequest = await OperationGenerator.createDeactivateOperationRequest(\n      didUniqueSuffix,\n      recoveryPrivateKey\n    );\n    const operationBuffer = Buffer.from(JSON.stringify(operationRequest));\n    const deactivateOperation = await DeactivateOperation.parse(\n      operationBuffer\n    );\n\n    return {\n      operationRequest,\n      operationBuffer,\n      deactivateOperation,\n    };\n  }\n\n  /**\n   * Generates an array of service endpoints with specified ids\n   * @param ids the id field in endpoint.\n   */\n  public static generateServiceEndpoints(ids: string[]): any[] {\n    const service_endpoints = [];\n    for (const id of ids) {\n      service_endpoints.push({\n        id: id,\n        type: 'someType',\n        endpoint: 'https://www.url.com',\n      });\n    }\n    return service_endpoints;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredOperationModel,\n  DidState,\n  IOperationStore,\n  IVersionManager,\n  Multihash,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\n\n/**\n * NOTE: Resolver cannot be versioned because it needs to be aware of `VersionManager` to fetch versioned operation processors.\n */\nexport default class Resolver {\n  public constructor(\n    private versionManager: IVersionManager,\n    private operationStore: IOperationStore\n  ) {}\n\n  /**\n   * Resolve the given DID unique suffix to its latest DID state.\n   * @param didUniqueSuffix The unique suffix of the DID to resolve. e.g. if 'did:sidetree:abc123' is the DID, the unique suffix would be 'abc123'\n   * @returns Final DID state of the DID. Undefined if the unique suffix of the DID is not found or the DID state is not constructable.\n   */\n  public async resolve(didUniqueSuffix: string): Promise<DidState | undefined> {\n    console.info(`Resolving DID unique suffix '${didUniqueSuffix}'...`);\n\n    const operations = await this.operationStore.get(didUniqueSuffix);\n    const operationsByType = Resolver.categorizeOperationsByType(operations);\n\n    // Find and apply a valid create operation.\n    let didState = await this.applyCreateOperation(\n      operationsByType.createOperations\n    );\n\n    // If can't construct an initial DID state.\n    if (didState === undefined) {\n      return undefined;\n    }\n\n    // Apply recovery/deactivate operations until an operation matching the next recovery commitment cannot be found.\n    const recoverAndDeactivateOperations = operationsByType.recoverOperations.concat(\n      operationsByType.deactivateOperations\n    );\n    const recoveryCommitValueToOperationMap = await this.constructCommitValueToOperationLookupMap(\n      recoverAndDeactivateOperations\n    );\n    didState = await this.applyRecoverAndDeactivateOperations(\n      didState,\n      recoveryCommitValueToOperationMap\n    );\n\n    // If the previous applied operation is a deactivate. No need to continue further.\n    if (didState.nextRecoveryCommitmentHash === undefined) {\n      return didState;\n    }\n\n    // Apply update operations until an operation matching the next update commitment cannot be found.\n    const updateCommitValueToOperationMap = await this.constructCommitValueToOperationLookupMap(\n      operationsByType.updateOperations\n    );\n    didState = await this.applyUpdateOperations(\n      didState,\n      updateCommitValueToOperationMap\n    );\n\n    return didState;\n  }\n\n  private static categorizeOperationsByType(\n    operations: AnchoredOperationModel[]\n  ): {\n    createOperations: AnchoredOperationModel[];\n    recoverOperations: AnchoredOperationModel[];\n    updateOperations: AnchoredOperationModel[];\n    deactivateOperations: AnchoredOperationModel[];\n  } {\n    const createOperations = [];\n    const recoverOperations = [];\n    const updateOperations = [];\n    const deactivateOperations = [];\n\n    for (const operation of operations) {\n      if (operation.type === OperationType.Create) {\n        createOperations.push(operation);\n      } else if (operation.type === OperationType.Recover) {\n        recoverOperations.push(operation);\n      } else if (operation.type === OperationType.Update) {\n        updateOperations.push(operation);\n      } else {\n        // This is a deactivate operation.\n        deactivateOperations.push(operation);\n      }\n    }\n    return {\n      createOperations,\n      recoverOperations,\n      updateOperations,\n      deactivateOperations,\n    };\n  }\n\n  /**\n   * Iterate through all duplicates of creates until we can construct an initial DID state (some creates maybe incomplete. eg. without `delta`).\n   */\n  private async applyCreateOperation(\n    createOperations: AnchoredOperationModel[]\n  ): Promise<DidState | undefined> {\n    let didState;\n\n    for (const createOperation of createOperations) {\n      didState = await this.applyOperation(createOperation, undefined);\n\n      // Exit loop as soon as we can construct an initial state.\n      if (didState !== undefined) {\n        break;\n      }\n    }\n\n    return didState;\n  }\n\n  /**\n   * Apply recovery/deactivate operations until an operation matching the next recovery commitment cannot be found.\n   */\n  private async applyRecoverAndDeactivateOperations(\n    startingDidState: DidState,\n    commitValueToOperationMap: Map<string, AnchoredOperationModel[]>\n  ): Promise<DidState> {\n    let didState = startingDidState;\n\n    while (\n      commitValueToOperationMap.has(didState.nextRecoveryCommitmentHash!)\n    ) {\n      let operationsWithCorrectRevealValue: AnchoredOperationModel[] = commitValueToOperationMap.get(\n        didState.nextRecoveryCommitmentHash!\n      )!;\n\n      // Sort using blockchain time.\n      operationsWithCorrectRevealValue = operationsWithCorrectRevealValue.sort(\n        (a, b) => a.transactionNumber - b.transactionNumber\n      );\n\n      const newDidState:\n        | DidState\n        | undefined = await this.applyFirstValidOperation(\n        operationsWithCorrectRevealValue,\n        didState\n      );\n\n      // We are done if we can't find a valid recover/deactivate operation to apply.\n      if (newDidState === undefined) {\n        break;\n      }\n\n      // We reach here if we have successfully computed a new DID state.\n      didState = newDidState;\n\n      // If the previous applied operation is a deactivate. No need to continue further.\n      if (didState.nextRecoveryCommitmentHash === undefined) {\n        return didState;\n      }\n    }\n\n    return didState;\n  }\n\n  /**\n   * Apply update operations until an operation matching the next update commitment cannot be found.\n   */\n  private async applyUpdateOperations(\n    startingDidState: DidState,\n    commitValueToOperationMap: Map<string, AnchoredOperationModel[]>\n  ): Promise<DidState> {\n    let didState = startingDidState;\n\n    while (commitValueToOperationMap.has(didState.nextUpdateCommitmentHash!)) {\n      let operationsWithCorrectRevealValue: AnchoredOperationModel[] = commitValueToOperationMap.get(\n        didState.nextUpdateCommitmentHash!\n      )!;\n\n      // Sort using blockchain time.\n      operationsWithCorrectRevealValue = operationsWithCorrectRevealValue.sort(\n        (a, b) => a.transactionNumber - b.transactionNumber\n      );\n\n      const newDidState:\n        | DidState\n        | undefined = await this.applyFirstValidOperation(\n        operationsWithCorrectRevealValue,\n        didState\n      );\n\n      // We are done if we can't find a valid update operation to apply.\n      if (newDidState === undefined) {\n        break;\n      }\n\n      // We reach here if we have successfully computed a new DID state.\n      didState = newDidState;\n    }\n\n    return didState;\n  }\n\n  /**\n   * Applies the given operation to the given DID state.\n   * @param operation The operation to be applied.\n   * @param didState The DID state to apply the operation on top of.\n   * @returns The resultant `DidState`. The given DID state is return if the given operation cannot be applied.\n   */\n  private async applyOperation(\n    operation: AnchoredOperationModel,\n    didState: DidState | undefined\n  ): Promise<DidState | undefined> {\n    let appliedDidState = didState;\n\n    // NOTE: MUST NOT throw error, else a bad operation can be used to denial resolution for a DID.\n    try {\n      const operationProcessor = this.versionManager.getOperationProcessor(\n        operation.transactionTime\n      );\n\n      appliedDidState = await operationProcessor.apply(\n        operation,\n        appliedDidState\n      );\n    } catch (error) {\n      console.log(\n        `Skipped bad operation for DID ${operation.didUniqueSuffix} at time ${\n          operation.transactionTime\n        }. Error: ${SidetreeError.stringify(error)}`\n      );\n    }\n\n    return appliedDidState;\n  }\n\n  /**\n   * @returns The new DID State if a valid operation is applied, `undefined` otherwise.\n   */\n  private async applyFirstValidOperation(\n    operations: AnchoredOperationModel[],\n    originalDidState: DidState\n  ): Promise<DidState | undefined> {\n    let newDidState = originalDidState;\n\n    // Stop as soon as an operation is applied successfully.\n    for (const operation of operations) {\n      newDidState = (await this.applyOperation(operation, newDidState))!;\n\n      // If operation matching the recovery commitment is applied.\n      if (\n        newDidState.lastOperationTransactionNumber !==\n        originalDidState.lastOperationTransactionNumber\n      ) {\n        return newDidState;\n      }\n    }\n\n    // Else we reach the end of operations without being able to apply any of them.\n    return undefined;\n  }\n\n  /**\n   * Constructs a single commit value -> operation lookup map by looping through each supported hash algorithm,\n   * hashing each operations as key, then adding the result to a map.\n   */\n  private async constructCommitValueToOperationLookupMap(\n    nonCreateOperations: AnchoredOperationModel[]\n  ): Promise<Map<string, AnchoredOperationModel[]>> {\n    const commitValueToOperationMap = new Map<\n      string,\n      AnchoredOperationModel[]\n    >();\n\n    // Loop through each supported algorithm and hash each operation.\n    const allSupportedHashAlgorithms = this.versionManager\n      .allSupportedHashAlgorithms;\n    for (const hashAlgorithm of allSupportedHashAlgorithms) {\n      for (const operation of nonCreateOperations) {\n        const operationProcessor = this.versionManager.getOperationProcessor(\n          operation.transactionTime\n        );\n        const revealValueBuffer = await operationProcessor.getRevealValue(\n          operation\n        );\n\n        const hashOfRevealValue = Multihash.hashThenEncode(\n          revealValueBuffer,\n          hashAlgorithm\n        );\n\n        if (commitValueToOperationMap.has(hashOfRevealValue)) {\n          commitValueToOperationMap.get(hashOfRevealValue)!.push(operation);\n        } else {\n          commitValueToOperationMap.set(hashOfRevealValue, [operation]);\n        }\n      }\n    }\n\n    return commitValueToOperationMap;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ServiceVersionModel } from '@sidetree/common';\n/**\n * Encapsulates the functionality to get the information about the service such as\n * version info.\n */\nexport default class ServiceInfoProvider {\n  private static readonly packageJson = require('../package.json');\n  private serviceName: string;\n\n  constructor(serviceName: string) {\n    this.serviceName = serviceName;\n  }\n\n  /**\n   * Gets the service version from the package.json file.\n   */\n  public getServiceVersion(): ServiceVersionModel {\n    return {\n      name: this.serviceName,\n      version: ServiceInfoProvider.packageJson.version,\n    };\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorCode, protocolParameters, SidetreeError } from '@sidetree/common';\n\n/**\n * Encapsulates the functionality to calculate and verify the blockchain transaction fees.\n */\nexport default class FeeManager {\n  /**\n   * Converts the normalized fee (returned by the blockchain) into the transaction fee to be paid when writing\n   * the current transaction.\n   *\n   * @param normalizedFee The normalized fee for the current transaction.\n   * @param numberOfOperations The number of operations to write.\n   * @param feeMarkupFactor Markup to be added to the calculated fee.\n   *\n   * @throws if the number of operations are <= 0.\n   */\n  public static computeMinimumTransactionFee(\n    normalizedFee: number,\n    numberOfOperations: number\n  ): number {\n    if (numberOfOperations <= 0) {\n      throw new SidetreeError(\n        ErrorCode.OperationCountLessThanZero,\n        `Fee cannot be calculated for the given number of operations: ${numberOfOperations}`\n      );\n    }\n\n    const feePerOperation =\n      normalizedFee *\n      protocolParameters.normalizedFeeToPerOperationFeeMultiplier;\n    const feeForAllOperations = feePerOperation * numberOfOperations;\n\n    // If our calculated-fee is lower than the normalized fee (which can happen if the number of operations is\n    // very low) then the calculated-fee will be ignored by the blockchain miners ... so make sure that we\n    // return at-least the normalized fee.\n    const transactionFee = Math.max(feeForAllOperations, normalizedFee);\n\n    return transactionFee;\n  }\n\n  /**\n   * Verifies that the fee paid for the given transaction is valid; throws if it is not valid.\n   *\n   * @param transactionFeePaid The actual fee paid for that transaction.\n   * @param numberOfOperations The number of operations written.\n   * @param normalizedFee The normalized fee for that transaction.\n   *\n   * @throws if the number of operations is <= 0; if the feepaid is invalid.\n   */\n  public static verifyTransactionFeeAndThrowOnError(\n    transactionFeePaid: number,\n    numberOfOperations: number,\n    normalizedFee: number\n  ): void {\n    // If there are no operations written then someone wrote incorrect data and we are going to throw\n    if (numberOfOperations <= 0) {\n      throw new SidetreeError(\n        ErrorCode.OperationCountLessThanZero,\n        `The number of operations: ${numberOfOperations} must be greater than 0`\n      );\n    }\n\n    if (transactionFeePaid < normalizedFee) {\n      throw new SidetreeError(\n        ErrorCode.TransactionFeePaidLessThanNormalizedFee,\n        `The actual fee paid: ${transactionFeePaid} should be greater than or equal to the normalized fee: ${normalizedFee}`\n      );\n    }\n\n    const actualFeePerOperation = transactionFeePaid / numberOfOperations;\n    const expectedFeePerOperation =\n      normalizedFee *\n      protocolParameters.normalizedFeeToPerOperationFeeMultiplier;\n\n    if (actualFeePerOperation < expectedFeePerOperation) {\n      throw new SidetreeError(\n        ErrorCode.TransactionFeePaidInvalid,\n        `The actual fee paid: ${transactionFeePaid} per number of operations: ${numberOfOperations} should be at least ${expectedFeePerOperation}.`\n      );\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  IVersionMetadataFetcher,\n  protocolParameters,\n  SidetreeError,\n  ValueTimeLockModel,\n} from '@sidetree/common';\n\n/**\n * Encapsulates the functionality to compute and verify the value time lock amounts.\n */\nexport default class ValueTimeLockVerifier {\n  /**\n   * Calculates the maximum number of operations allowed to be written for the given lock information. If\n   * there is no lock then it returns the number of operations which do not require a lock.\n   *\n   * @param valueTimeLock The lock object if exists\n   * @param versionMetadataFetcher The mapper from transaction time to version metadata\n   */\n  public static calculateMaxNumberOfOperationsAllowed(\n    valueTimeLock: ValueTimeLockModel | undefined,\n    versionMetadataFetcher: IVersionMetadataFetcher\n  ) {\n    if (valueTimeLock === undefined) {\n      return protocolParameters.maxNumberOfOperationsForNoValueTimeLock;\n    }\n\n    const versionMetadata = versionMetadataFetcher.getVersionMetadata(\n      valueTimeLock.lockTransactionTime\n    );\n    const normalizedFeeToPerOperationFeeMultiplier =\n      versionMetadata.normalizedFeeToPerOperationFeeMultiplier;\n    const valueTimeLockAmountMultiplier =\n      versionMetadata.valueTimeLockAmountMultiplier;\n\n    // Using the following formula:\n    //  requiredLockAmount = normalizedfee * normalizedFeeMultipier * numberOfOps * valueTimeLockMultiplier\n    //\n    // We are going to find the numberOfOps given the requiredLockAmount\n    const feePerOperation =\n      valueTimeLock.normalizedFee * normalizedFeeToPerOperationFeeMultiplier;\n    const numberOfOpsAllowed =\n      valueTimeLock.amountLocked /\n      (feePerOperation * valueTimeLockAmountMultiplier);\n\n    // Make sure that we are returning an integer; rounding down to make sure that we are not going above\n    // the max limit.\n    const numberOfOpsAllowedInt = Math.floor(numberOfOpsAllowed);\n\n    // Return at least the 'free' operations\n    return Math.max(\n      numberOfOpsAllowedInt,\n      protocolParameters.maxNumberOfOperationsForNoValueTimeLock\n    );\n  }\n\n  /**\n   * Verifies that the value lock object (amount, transaction time range) is correct for the specified number\n   * of operations.\n   *\n   * @param valueTimeLock The value time lock object used for verificiation.\n   * @param numberOfOperations The target number of operations.\n   * @param sidetreeTransactionTime The transaction time where the operations were written.\n   * @param sidetreeTransactionWriter The writer of the transaction.\n   * @param versionMetadataFetcher The mapper from transaction time to version metadata\n   */\n  public static verifyLockAmountAndThrowOnError(\n    valueTimeLock: ValueTimeLockModel | undefined,\n    numberOfOperations: number,\n    sidetreeTransactionTime: number,\n    sidetreeTransactionWriter: string,\n    versionMetadataFetcher: IVersionMetadataFetcher\n  ): void {\n    // If the number of written operations were under the free limit then there's nothing to check\n    if (\n      numberOfOperations <=\n      protocolParameters.maxNumberOfOperationsForNoValueTimeLock\n    ) {\n      return;\n    }\n\n    if (valueTimeLock) {\n      // Check the lock owner\n      if (valueTimeLock.owner !== sidetreeTransactionWriter) {\n        throw new SidetreeError(\n          ErrorCode.ValueTimeLockVerifierTransactionWriterLockOwnerMismatch,\n          `Sidetree transaction writer: ${sidetreeTransactionWriter} - Lock owner: ${valueTimeLock.owner}`\n        );\n      }\n\n      // Check the lock duration\n      if (\n        sidetreeTransactionTime < valueTimeLock.lockTransactionTime ||\n        sidetreeTransactionTime >= valueTimeLock.unlockTransactionTime\n      ) {\n        throw new SidetreeError(\n          ErrorCode.ValueTimeLockVerifierTransactionTimeOutsideLockRange,\n          // tslint:disable-next-line: max-line-length\n          `Sidetree transaction block: ${sidetreeTransactionTime}; lock start time: ${valueTimeLock.lockTransactionTime}; unlock time: ${valueTimeLock.unlockTransactionTime}`\n        );\n      }\n    }\n\n    const maxNumberOfOpsAllowed = this.calculateMaxNumberOfOperationsAllowed(\n      valueTimeLock,\n      versionMetadataFetcher\n    );\n\n    if (numberOfOperations > maxNumberOfOpsAllowed) {\n      throw new SidetreeError(\n        ErrorCode.ValueTimeLockVerifierInvalidNumberOfOperations,\n        `Max number of ops allowed: ${maxNumberOfOpsAllowed}; actual number of ops: ${numberOfOperations}`\n      );\n    }\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredDataSerializer,\n  AnchoredOperationModel,\n  ChunkFileModel,\n  ErrorCode,\n  FetchResultCode,\n  IBlockchain,\n  IOperationStore,\n  ITransactionProcessor,\n  IVersionMetadataFetcher,\n  protocolParameters,\n  SidetreeError,\n  TransactionModel,\n} from '@sidetree/common';\nimport AnchorFile from './write/AnchorFile';\nimport ArrayMethods from './util/ArrayMethods';\nimport ChunkFile from './write/ChunkFile';\nimport DownloadManager from './DownloadManager';\nimport FeeManager from './FeeManager';\nimport JsonAsync from './util/JsonAsync';\nimport MapFile from './write/MapFile';\nimport ValueTimeLockVerifier from './ValueTimeLockVerifier';\n\n/**\n * Implementation of the `ITransactionProcessor`.\n */\nexport default class TransactionProcessor implements ITransactionProcessor {\n  public constructor(\n    private downloadManager: DownloadManager,\n    private operationStore: IOperationStore,\n    private blockchain: IBlockchain,\n    private versionMetadataFetcher: IVersionMetadataFetcher\n  ) {}\n\n  public async processTransaction(\n    transaction: TransactionModel\n  ): Promise<boolean> {\n    try {\n      // Decode the anchor string.\n      const anchoredData = AnchoredDataSerializer.deserialize(\n        transaction.anchorString\n      );\n\n      // Verify enough fee paid.\n      FeeManager.verifyTransactionFeeAndThrowOnError(\n        transaction.transactionFeePaid,\n        anchoredData.numberOfOperations,\n        transaction.normalizedTransactionFee\n      );\n\n      // Download and verify anchor file.\n      const anchorFile = await this.downloadAndVerifyAnchorFile(\n        transaction,\n        anchoredData.anchorFileHash,\n        anchoredData.numberOfOperations\n      );\n\n      // Download and verify map file.\n      const mapFile = await this.downloadAndVerifyMapFile(\n        anchorFile,\n        anchoredData.numberOfOperations\n      );\n\n      // Download and verify chunk file.\n      const chunkFileModel = await this.downloadAndVerifyChunkFile(mapFile);\n\n      // Compose into operations from all the files downloaded.\n      const operations = await this.composeAnchoredOperationModels(\n        transaction,\n        anchorFile,\n        mapFile,\n        chunkFileModel\n      );\n\n      // If the code reaches here, it means that the batch of operations is valid, store the operations.\n      await this.operationStore.put(operations);\n\n      return true;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is potentially related to CAS network connectivity issues, we need to return false to retry later.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          return false;\n        }\n\n        console.info(`Ignoring error: ${error.message}`);\n        return true;\n      } else {\n        console.error(\n          `Unexpected error processing transaction, MUST investigate and fix: ${error.message}`\n        );\n        return false;\n      }\n    }\n  }\n\n  /**\n   * @param batchSize The size of the batch in number of operations.\n   */\n  private async downloadAndVerifyAnchorFile(\n    transaction: TransactionModel,\n    anchorFileHash: string,\n    paidOperationCount: number\n  ): Promise<AnchorFile> {\n    // Verify the number of paid operations does not exceed the maximum allowed limit.\n    if (paidOperationCount > protocolParameters.maxOperationsPerBatch) {\n      throw new SidetreeError(\n        ErrorCode.TransactionProcessorPaidOperationCountExceedsLimit,\n        `Paid batch size of ${paidOperationCount} operations exceeds the allowed limit of ${protocolParameters.maxOperationsPerBatch}.`\n      );\n    }\n\n    console.info(\n      `Downloading anchor file '${anchorFileHash}', max file size limit ${protocolParameters.maxAnchorFileSizeInBytes} bytes...`\n    );\n\n    const fileBuffer = await this.downloadFileFromCas(\n      anchorFileHash,\n      protocolParameters.maxAnchorFileSizeInBytes\n    );\n    const anchorFile = await AnchorFile.parse(fileBuffer);\n\n    const operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;\n    if (operationCountInAnchorFile > paidOperationCount) {\n      throw new SidetreeError(\n        ErrorCode.AnchorFileOperationCountExceededPaidLimit,\n        `Operation count ${operationCountInAnchorFile} in anchor file exceeded limit of : ${paidOperationCount}`\n      );\n    }\n\n    // Verify required lock if one was needed.\n    const valueTimeLock = anchorFile.model.writer_lock_id\n      ? await this.blockchain.getValueTimeLock(anchorFile.model.writer_lock_id)\n      : undefined;\n    ValueTimeLockVerifier.verifyLockAmountAndThrowOnError(\n      valueTimeLock,\n      paidOperationCount,\n      transaction.transactionTime,\n      transaction.writer,\n      this.versionMetadataFetcher\n    );\n\n    return anchorFile;\n  }\n\n  /**\n   * NOTE: In order to be forward-compatable with data-pruning feature,\n   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.\n   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),\n   * It is a design choice to hide the complexity of map file downloading and construction within this method,\n   * instead of throwing errors and letting the caller handle them.\n   * @returns `MapFile` if downloaded file is valid; `undefined` otherwise.\n   * @throws SidetreeErrors that are retryable.\n   */\n  private async downloadAndVerifyMapFile(\n    anchorFile: AnchorFile,\n    paidOperationCount: number\n  ): Promise<MapFile | undefined> {\n    try {\n      const anchorFileModel = anchorFile.model;\n      console.info(\n        `Downloading map file '${anchorFileModel.map_file_uri}', max file size limit ${protocolParameters.maxMapFileSizeInBytes}...`\n      );\n\n      const fileBuffer = await this.downloadFileFromCas(\n        anchorFileModel.map_file_uri,\n        protocolParameters.maxMapFileSizeInBytes\n      );\n      const mapFile = await MapFile.parse(fileBuffer);\n\n      // Calulate the max paid update operation count.\n      const operationCountInAnchorFile = anchorFile.didUniqueSuffixes.length;\n      const maxPaidUpdateOperationCount =\n        paidOperationCount - operationCountInAnchorFile;\n\n      // If the actual update operation count is greater than the max paid update operation count, the map file is invalid.\n      const updateOperationCount = mapFile.updateOperations\n        ? mapFile.updateOperations.length\n        : 0;\n      if (updateOperationCount > maxPaidUpdateOperationCount) {\n        return undefined;\n      }\n\n      // If we find operations for the same DID between anchor and map files, the map file is invalid.\n      if (\n        !ArrayMethods.areMutuallyExclusive(\n          anchorFile.didUniqueSuffixes,\n          mapFile.didUniqueSuffixes\n        )\n      ) {\n        return undefined;\n      }\n\n      return mapFile;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is related to CAS network issues, we will surface them so retry can happen.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          throw error;\n        }\n\n        return undefined;\n      } else {\n        console.error(\n          `Unexpected error fetching map file ${\n            anchorFile.model.map_file_uri\n          }, MUST investigate and fix: ${SidetreeError.stringify(error)}`\n        );\n        return undefined;\n      }\n    }\n  }\n\n  /**\n   * NOTE: In order to be forward-compatable with data-pruning feature,\n   * we must continue to process the operations declared in the anchor file even if the map/chunk file is invalid.\n   * This means that this method MUST ONLY throw errors that are retryable (e.g. network or file not found errors),\n   * It is a design choice to hide the complexity of chunk file downloading and construction within this method,\n   * instead of throwing errors and letting the caller handle them.\n   * @returns `ChunkFileModel` if downloaded file is valid; `undefined` otherwise.\n   * @throws SidetreeErrors that are retryable.\n   */\n  private async downloadAndVerifyChunkFile(\n    mapFile: MapFile | undefined\n  ): Promise<ChunkFileModel | undefined> {\n    // Can't download chunk file if map file is not given.\n    if (mapFile === undefined) {\n      return undefined;\n    }\n\n    let chunkFileHash;\n    try {\n      chunkFileHash = mapFile.model.chunks[0].chunk_file_uri;\n      console.info(\n        `Downloading chunk file '${chunkFileHash}', max size limit ${protocolParameters.maxChunkFileSizeInBytes}...`\n      );\n\n      const fileBuffer = await this.downloadFileFromCas(\n        chunkFileHash,\n        protocolParameters.maxChunkFileSizeInBytes\n      );\n      const chunkFileModel = await ChunkFile.parse(fileBuffer);\n\n      return chunkFileModel;\n    } catch (error) {\n      if (error instanceof SidetreeError) {\n        // If error is related to CAS network issues, we will surface them so retry can happen.\n        if (\n          error.code === ErrorCode.CasNotReachable ||\n          error.code === ErrorCode.CasFileNotFound\n        ) {\n          throw error;\n        }\n\n        return undefined;\n      } else {\n        console.error(\n          `Unexpected error fetching chunk file ${chunkFileHash}, MUST investigate and fix: ${SidetreeError.stringify(\n            error\n          )}`\n        );\n        return undefined;\n      }\n    }\n  }\n\n  private async composeAnchoredOperationModels(\n    transaction: TransactionModel,\n    anchorFile: AnchorFile,\n    mapFile: MapFile | undefined,\n    chunkFile: ChunkFileModel | undefined\n  ): Promise<AnchoredOperationModel[]> {\n    const createOperations = anchorFile.createOperations;\n    const recoverOperations = anchorFile.recoverOperations;\n    const deactivateOperations = anchorFile.deactivateOperations;\n    const updateOperations =\n      mapFile && mapFile.updateOperations ? mapFile.updateOperations : [];\n\n    // Add the operations in the following order of types: create, recover, update, deactivate.\n    const operations = [];\n    operations.push(...createOperations);\n    operations.push(...recoverOperations);\n    operations.push(...updateOperations);\n    operations.push(...deactivateOperations);\n\n    // If chunk file is found/given, we need to add `type` and `delta` from chunk file to each operation.\n    // NOTE: there is no delta for deactivate operations.\n    const patchedOperationBuffers: Buffer[] = [];\n    if (chunkFile !== undefined) {\n      // TODO: https://github.com/decentralized-identity/sidetree/issues/442\n      // Use actual operation request object instead of buffer.\n\n      const operationCountExcludingDeactivates =\n        createOperations.length +\n        recoverOperations.length +\n        updateOperations.length;\n      for (\n        let i = 0;\n        i < operationCountExcludingDeactivates && i < chunkFile.deltas.length;\n        i++\n      ) {\n        const operation = operations[i];\n        const operationJsonString = operation.operationBuffer.toString();\n        const operationObject = await JsonAsync.parse(operationJsonString);\n        operationObject.type = operation.type;\n        operationObject.delta = chunkFile.deltas[i];\n\n        const patchedOperationBuffer = Buffer.from(\n          JSON.stringify(operationObject)\n        );\n        patchedOperationBuffers.push(patchedOperationBuffer);\n      }\n    }\n\n    for (let i = 0; i < deactivateOperations.length; i++) {\n      const operation = deactivateOperations[i];\n      const operationJsonString = operation.operationBuffer.toString();\n      const operationObject = await JsonAsync.parse(operationJsonString);\n      operationObject.type = operation.type;\n\n      const patchedOperationBuffer = Buffer.from(\n        JSON.stringify(operationObject)\n      );\n      patchedOperationBuffers.push(patchedOperationBuffer);\n    }\n\n    // Add anchored timestamp to each operation.\n    const anchoredOperationModels = [];\n    for (let i = 0; i < operations.length; i++) {\n      const operation = operations[i];\n\n      const anchoredOperationModel: AnchoredOperationModel = {\n        didUniqueSuffix: operation.didUniqueSuffix,\n        type: operation.type,\n        operationBuffer: patchedOperationBuffers[i],\n        operationIndex: i,\n        transactionNumber: transaction.transactionNumber,\n        transactionTime: transaction.transactionTime,\n      };\n\n      anchoredOperationModels.push(anchoredOperationModel);\n    }\n    return anchoredOperationModels;\n  }\n\n  private async downloadFileFromCas(\n    fileHash: string,\n    maxFileSizeInBytes: number\n  ): Promise<Buffer> {\n    console.info(\n      `Downloading file '${fileHash}', max size limit ${maxFileSizeInBytes}...`\n    );\n\n    const fileFetchResult = await this.downloadManager.download(\n      fileHash,\n      maxFileSizeInBytes\n    );\n\n    if (fileFetchResult.code === FetchResultCode.InvalidHash) {\n      throw new SidetreeError(\n        ErrorCode.CasFileHashNotValid,\n        `File hash '${fileHash}' is not a valid hash.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.MaxSizeExceeded) {\n      throw new SidetreeError(\n        ErrorCode.CasFileTooLarge,\n        `File '${fileHash}' exceeded max size limit of ${maxFileSizeInBytes} bytes.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.NotAFile) {\n      throw new SidetreeError(\n        ErrorCode.CasFileNotAFile,\n        `File hash '${fileHash}' points to a content that is not a file.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.CasNotReachable) {\n      throw new SidetreeError(\n        ErrorCode.CasNotReachable,\n        `CAS not reachable for file '${fileHash}'.`\n      );\n    }\n\n    if (fileFetchResult.code === FetchResultCode.NotFound) {\n      throw new SidetreeError(\n        ErrorCode.CasFileNotFound,\n        `File '${fileHash}' not found.`\n      );\n    }\n\n    console.info(\n      `File '${fileHash}' of size ${\n        fileFetchResult.content!.length\n      } downloaded.`\n    );\n\n    return fileFetchResult.content!;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredDataSerializer,\n  ErrorCode,\n  ITransactionSelector,\n  ITransactionStore,\n  SidetreeError,\n  TransactionModel,\n  protocolParameters,\n} from '@sidetree/common';\nimport PriorityQueue from 'priorityqueue';\n\n/**\n * rate limits how many operations is valid per block\n */\nexport default class TransactionSelector implements ITransactionSelector {\n  private maxNumberOfOperationsPerBlock: number;\n  private maxNumberOfTransactionsPerBlock: number;\n  public constructor(private transactionStore: ITransactionStore) {\n    this.maxNumberOfOperationsPerBlock =\n      protocolParameters.maxNumberOfOperationsPerTransactionTime;\n    this.maxNumberOfTransactionsPerBlock =\n      protocolParameters.maxNumberOfTransactionsPerTransactionTime;\n  }\n\n  private static getTransactionPriorityQueue() {\n    const comparator = (a: TransactionModel, b: TransactionModel) => {\n      // higher fee comes first. If fees are the same, earlier transaction comes first\n      return (\n        a.transactionFeePaid - b.transactionFeePaid ||\n        b.transactionNumber - a.transactionNumber\n      );\n    };\n\n    return new PriorityQueue({ comparator });\n  }\n\n  /**\n   * Returns an array of transactions that should be processed. Ranked by highest fee paid per transaction and up to the\n   * max number of operations per block\n   * @param transactions The transactions that should be ranked and considered to process\n   */\n  public async selectQualifiedTransactions(\n    transactions: TransactionModel[]\n  ): Promise<TransactionModel[]> {\n    if (!transactions.length) {\n      return [];\n    }\n\n    const transactionsPriorityQueue = TransactionSelector.getTransactionPriorityQueue();\n\n    const currentTransactionTime = transactions[0].transactionTime;\n\n    TransactionSelector.validateTransactions(\n      transactions,\n      currentTransactionTime\n    );\n    TransactionSelector.enqueueFirstTransactionFromEachWriter(\n      transactions,\n      currentTransactionTime,\n      transactionsPriorityQueue\n    );\n\n    const [\n      numberOfOperations,\n      numberOfTransactions,\n    ] = await this.getNumberOfOperationsAndTransactionsAlreadyInTransactionTime(\n      currentTransactionTime\n    );\n    const numberOfOperationsToQualify =\n      this.maxNumberOfOperationsPerBlock - numberOfOperations;\n    const numberOfTransactionsToQualify =\n      this.maxNumberOfTransactionsPerBlock - numberOfTransactions;\n\n    const transactionsToReturn = TransactionSelector.getHighestFeeTransactionsFromCurrentTransactionTime(\n      numberOfOperationsToQualify,\n      numberOfTransactionsToQualify,\n      transactionsPriorityQueue\n    );\n\n    return transactionsToReturn;\n  }\n\n  private static validateTransactions(\n    transactions: TransactionModel[],\n    currentTransactionTime: number\n  ) {\n    for (const transaction of transactions) {\n      // expect all transactions to be in the same transaction time\n      if (transaction.transactionTime !== currentTransactionTime) {\n        throw new SidetreeError(\n          ErrorCode.TransactionsNotInSameBlock,\n          'transaction must be in the same block to perform rate limiting, investigate and fix'\n        );\n      }\n    }\n  }\n\n  private static enqueueFirstTransactionFromEachWriter(\n    transactions: TransactionModel[],\n    currentTransactionTime: number,\n    transactionsPriorityQueue: any\n  ) {\n    const writerToTransactionNumberMap = new Map();\n    // if multiple transactions have the same writer, take the first one in the array and enqueue into transactionPriorityQueue\n    for (const transaction of transactions) {\n      // only 1 transaction is allowed per writer\n      if (writerToTransactionNumberMap.has(transaction.writer)) {\n        const acceptedTransactionNumber = writerToTransactionNumberMap.get(\n          transaction.writer\n        );\n        // tslint:disable-next-line:max-line-length\n        console.info(\n          `Multiple transactions found in transaction time ${currentTransactionTime} from writer ${transaction.writer}, considering transaction ${acceptedTransactionNumber} and ignoring ${transaction.transactionNumber}`\n        );\n      } else {\n        transactionsPriorityQueue.push(transaction);\n        writerToTransactionNumberMap.set(\n          transaction.writer,\n          transaction.transactionNumber\n        );\n      }\n    }\n  }\n\n  private async getNumberOfOperationsAndTransactionsAlreadyInTransactionTime(\n    transactionTime: number\n  ): Promise<number[]> {\n    const transactions = await this.transactionStore.getTransactionsStartingFrom(\n      transactionTime,\n      transactionTime\n    );\n    let numberOfOperations = 0;\n    if (transactions) {\n      for (const transaction of transactions) {\n        try {\n          const numOfOperationsInCurrentTransaction = AnchoredDataSerializer.deserialize(\n            transaction.anchorString\n          ).numberOfOperations;\n          numberOfOperations += numOfOperationsInCurrentTransaction;\n        } catch (e) {\n          console.debug(\n            `Error thrown in TransactionSelector: ${JSON.stringify(\n              e,\n              Object.getOwnPropertyNames(e)\n            )}`\n          );\n          console.info(\n            `Transaction with anchor string ${transaction.anchorString} not considered as selected.`\n          );\n        }\n      }\n    }\n    const numberOfTransactions = transactions ? transactions.length : 0;\n    return [numberOfOperations, numberOfTransactions];\n  }\n\n  /**\n   * Given transactions within a block, return the ones that should be processed.\n   */\n  private static getHighestFeeTransactionsFromCurrentTransactionTime(\n    numberOfOperationsToQualify: number,\n    numberOfTransactionsToQualify: number,\n    transactionsPriorityQueue: any\n  ): TransactionModel[] {\n    let numberOfOperationsSeen = 0;\n    const transactionsToReturn = [];\n\n    while (\n      transactionsToReturn.length < numberOfTransactionsToQualify &&\n      numberOfOperationsSeen < numberOfOperationsToQualify &&\n      transactionsPriorityQueue.length > 0\n    ) {\n      const currentTransaction = transactionsPriorityQueue.pop();\n      try {\n        const numOfOperationsInCurrentTransaction = AnchoredDataSerializer.deserialize(\n          currentTransaction.anchorString\n        ).numberOfOperations;\n        numberOfOperationsSeen += numOfOperationsInCurrentTransaction;\n        if (numberOfOperationsSeen <= numberOfOperationsToQualify) {\n          transactionsToReturn.push(currentTransaction);\n        }\n      } catch (e) {\n        console.debug(\n          `Error thrown in TransactionSelector: ${JSON.stringify(\n            e,\n            Object.getOwnPropertyNames(e)\n          )}`\n        );\n        console.info(\n          `Transaction with anchor string ${currentTransaction.anchorString} not selected`\n        );\n      }\n    }\n\n    // sort based on transaction number ascending\n    return transactionsToReturn;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport chalk from 'chalk';\n\n/**\n * Abstraction for colored logs.\n */\nexport default class LogColor {\n  /** Method for logging in light blue. */\n  public static lightBlue = chalk.hex('#75b0eb');\n\n  /** Method for logging in green. */\n  public static green = chalk.green;\n\n  /** Method for logging in yellow. */\n  public static yellow = chalk.yellow;\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AnchoredData,\n  AnchoredDataSerializer,\n  IBatchWriter,\n  IBlockchain,\n  ICas,\n  IOperationQueue,\n  OperationType,\n  protocolParameters,\n  IVersionMetadataFetcher,\n  ValueTimeLockModel,\n} from '@sidetree/common';\nimport CreateOperation from '../CreateOperation';\nimport DeactivateOperation from '../DeactivateOperation';\nimport LogColor from '../LogColor';\nimport Operation from '../Operation';\nimport RecoverOperation from '../RecoverOperation';\nimport UpdateOperation from '../UpdateOperation';\nimport AnchorFile from './AnchorFile';\nimport ChunkFile from './ChunkFile';\nimport MapFile from './MapFile';\nimport FeeManager from '../FeeManager';\nimport ValueTimeLockVerifier from '../ValueTimeLockVerifier';\n\n/**\n * Implementation of the `IBatchWriter`.\n */\nexport default class BatchWriter implements IBatchWriter {\n  public constructor(\n    private operationQueue: IOperationQueue,\n    private blockchain: IBlockchain,\n    private cas: ICas,\n    private versionMetadataFetcher: IVersionMetadataFetcher\n  ) {}\n\n  public async write(): Promise<void> {\n    const normalizedFee = await this.blockchain.getFee(\n      this.blockchain.approximateTime.time\n    );\n    const currentLock = await this.blockchain.getWriterValueTimeLock();\n    const numberOfOpsAllowed = this.getNumberOfOperationsAllowed(currentLock);\n\n    // Get the batch of operations to be anchored on the blockchain.\n    const queuedOperations = await this.operationQueue.peek(numberOfOpsAllowed);\n    const numberOfOperations = queuedOperations.length;\n\n    // Do nothing if there is nothing to batch together.\n    if (queuedOperations.length === 0) {\n      console.info(`No queued operations to batch.`);\n      return;\n    }\n\n    console.info(\n      LogColor.lightBlue(\n        `Batch size = ${LogColor.green(`${numberOfOperations}`)}`\n      )\n    );\n\n    const operationModels = await Promise.all(\n      queuedOperations.map(async (queuedOperation) =>\n        Operation.parse(queuedOperation.operationBuffer)\n      )\n    );\n    const createOperations = operationModels.filter(\n      (operation) => operation.type === OperationType.Create\n    ) as CreateOperation[];\n    const recoverOperations = operationModels.filter(\n      (operation) => operation.type === OperationType.Recover\n    ) as RecoverOperation[];\n    const updateOperations = operationModels.filter(\n      (operation) => operation.type === OperationType.Update\n    ) as UpdateOperation[];\n    const deactivateOperations = operationModels.filter(\n      (operation) => operation.type === OperationType.Deactivate\n    ) as DeactivateOperation[];\n\n    // Create the chunk file buffer from the operation models.\n    // NOTE: deactivate operations don't have delta.\n    const chunkFileBuffer = await ChunkFile.createBuffer(\n      createOperations,\n      recoverOperations,\n      updateOperations\n    );\n\n    // Write the chunk file to content addressable store.\n    const chunkFileHash = await this.cas.write(chunkFileBuffer);\n    console.info(\n      LogColor.lightBlue(\n        `Wrote chunk file ${LogColor.green(\n          chunkFileHash\n        )} to content addressable store.`\n      )\n    );\n\n    // Write the map file to content addressable store.\n    const mapFileBuffer = await MapFile.createBuffer(\n      chunkFileHash,\n      updateOperations\n    );\n    const mapFileHash = await this.cas.write(mapFileBuffer);\n    console.info(\n      LogColor.lightBlue(\n        `Wrote map file ${LogColor.green(\n          mapFileHash\n        )} to content addressable store.`\n      )\n    );\n\n    // Write the anchor file to content addressable store.\n    const writerLockId = currentLock ? currentLock.identifier : undefined;\n    const anchorFileBuffer = await AnchorFile.createBuffer(\n      writerLockId,\n      mapFileHash,\n      createOperations,\n      recoverOperations,\n      deactivateOperations\n    );\n    const anchorFileHash = await this.cas.write(anchorFileBuffer);\n    console.info(\n      LogColor.lightBlue(\n        `Wrote anchor file ${LogColor.green(\n          anchorFileHash\n        )} to content addressable store.`\n      )\n    );\n\n    // Anchor the data to the blockchain\n    const dataToBeAnchored: AnchoredData = {\n      anchorFileHash,\n      numberOfOperations,\n    };\n\n    const stringToWriteToBlockchain = AnchoredDataSerializer.serialize(\n      dataToBeAnchored\n    );\n    const fee = FeeManager.computeMinimumTransactionFee(\n      normalizedFee,\n      numberOfOperations\n    );\n    console.info(\n      LogColor.lightBlue(\n        `Writing data to blockchain: ${LogColor.green(\n          stringToWriteToBlockchain\n        )} with minimum fee of: ${LogColor.green(`${fee}`)}`\n      )\n    );\n\n    await this.blockchain.write(stringToWriteToBlockchain, fee);\n\n    // Remove written operations from queue after batch writing has completed successfully.\n    await this.operationQueue.dequeue(queuedOperations.length);\n  }\n\n  private getNumberOfOperationsAllowed(\n    valueTimeLock: ValueTimeLockModel | undefined\n  ): number {\n    const maxNumberOfOpsAllowedByProtocol =\n      protocolParameters.maxOperationsPerBatch;\n    const maxNumberOfOpsAllowedByLock = ValueTimeLockVerifier.calculateMaxNumberOfOperationsAllowed(\n      valueTimeLock,\n      this.versionMetadataFetcher\n    );\n\n    if (maxNumberOfOpsAllowedByLock > maxNumberOfOpsAllowedByProtocol) {\n      // tslint:disable-next-line: max-line-length\n      console.info(\n        `Maximum number of operations allowed by value time lock: ${maxNumberOfOpsAllowedByLock}; Maximum number of operations allowed by protocol: ${maxNumberOfOpsAllowedByProtocol}`\n      );\n    }\n\n    return Math.min(\n      maxNumberOfOpsAllowedByLock,\n      maxNumberOfOpsAllowedByProtocol\n    );\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/* eslint-disable no-case-declarations */\nimport {\n  AnchoredOperationModel,\n  DidState,\n  ErrorCode,\n  IOperationProcessor,\n  JsonCanonicalizer,\n  Multihash,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport CreateOperation from './CreateOperation';\nimport DeactivateOperation from './DeactivateOperation';\nimport DocumentComposer from './DocumentComposer';\nimport Operation from './Operation';\nimport RecoverOperation from './RecoverOperation';\nimport UpdateOperation from './UpdateOperation';\n\n/**\n * Implementation of IOperationProcessor.\n */\nexport default class OperationProcessor implements IOperationProcessor {\n  public async apply(\n    anchoredOperationModel: AnchoredOperationModel,\n    didState: DidState | undefined\n  ): Promise<DidState | undefined> {\n    // If DID state is undefined, then the operation given must be a create operation, otherwise the operation cannot be applied.\n    if (\n      didState === undefined &&\n      anchoredOperationModel.type !== OperationType.Create\n    ) {\n      return undefined;\n    }\n\n    const previousOperationTransactionNumber = didState\n      ? didState.lastOperationTransactionNumber\n      : undefined;\n\n    let appliedDidState: DidState | undefined;\n    if (anchoredOperationModel.type === OperationType.Create) {\n      appliedDidState = await this.applyCreateOperation(\n        anchoredOperationModel,\n        didState\n      );\n    } else if (anchoredOperationModel.type === OperationType.Update) {\n      appliedDidState = await this.applyUpdateOperation(\n        anchoredOperationModel,\n        didState!\n      );\n    } else if (anchoredOperationModel.type === OperationType.Recover) {\n      appliedDidState = await this.applyRecoverOperation(\n        anchoredOperationModel,\n        didState!\n      );\n    } else if (anchoredOperationModel.type === OperationType.Deactivate) {\n      appliedDidState = await this.applyDeactivateOperation(\n        anchoredOperationModel,\n        didState!\n      );\n    } else {\n      throw new SidetreeError(ErrorCode.OperationProcessorUnknownOperationType);\n    }\n\n    try {\n      // If the operation was not applied, log some info in case needed for debugging.\n      if (\n        appliedDidState === undefined ||\n        appliedDidState.lastOperationTransactionNumber ===\n          previousOperationTransactionNumber\n      ) {\n        const index = anchoredOperationModel.operationIndex;\n        const time = anchoredOperationModel.transactionTime;\n        const number = anchoredOperationModel.transactionNumber;\n        const didUniqueSuffix = anchoredOperationModel.didUniqueSuffix;\n        console.debug(\n          `Ignored invalid operation for DID '${didUniqueSuffix}' in transaction '${number}' at time '${time}' at operation index ${index}.`\n        );\n      }\n    } catch (error) {\n      console.log(`Failed logging ${error}.`);\n      // If logging fails, just move on.\n    }\n\n    return appliedDidState;\n  }\n\n  public async getRevealValue(\n    anchoredOperationModel: AnchoredOperationModel\n  ): Promise<Buffer> {\n    if (anchoredOperationModel.type === OperationType.Create) {\n      throw new SidetreeError(\n        ErrorCode.OperationProcessorCreateOperationDoesNotHaveRevealValue\n      );\n    }\n\n    const operation = await Operation.parse(\n      anchoredOperationModel.operationBuffer\n    );\n\n    let revealValueBuffer;\n    switch (operation.type) {\n      case OperationType.Recover:\n        const recoverOperation = operation as RecoverOperation;\n        revealValueBuffer = JsonCanonicalizer.canonicalizeAsBuffer(\n          recoverOperation.signedData.recovery_key\n        );\n        return revealValueBuffer;\n      case OperationType.Update:\n        const updateOperation = operation as UpdateOperation;\n        revealValueBuffer = JsonCanonicalizer.canonicalizeAsBuffer(\n          updateOperation.signedData.update_key\n        );\n        return revealValueBuffer;\n      default:\n        // This is a deactivate.\n        const deactivateOperation = operation as DeactivateOperation;\n        revealValueBuffer = JsonCanonicalizer.canonicalizeAsBuffer(\n          deactivateOperation.signedData.recovery_key\n        );\n        return revealValueBuffer;\n    }\n  }\n\n  /**\n   * @returns new DID state if operation is applied successfully; the given DID state otherwise.\n   */\n  private async applyCreateOperation(\n    anchoredOperationModel: AnchoredOperationModel,\n    didState: DidState | undefined\n  ): Promise<DidState | undefined> {\n    // If DID state is already created by a previous create operation, then we cannot apply a create operation again.\n    if (didState !== undefined) {\n      return didState;\n    }\n\n    const operation = await CreateOperation.parse(\n      anchoredOperationModel.operationBuffer\n    );\n\n    // Ensure actual delta hash matches expected delta hash.\n    const isMatchingDelta = Multihash.isValidHash(\n      operation.encodedDelta,\n      operation.suffixData.delta_hash\n    );\n    if (!isMatchingDelta) {\n      return didState;\n    }\n\n    // Apply the given patches against an empty object.\n    const delta = operation.delta;\n    let document = {};\n    try {\n      if (delta !== undefined) {\n        document = DocumentComposer.applyPatches(document, delta.patches);\n      }\n    } catch (error) {\n      const didUniqueSuffix = anchoredOperationModel.didUniqueSuffix;\n      const transactionNumber = anchoredOperationModel.transactionNumber;\n      console.debug(\n        `Unable to apply document patch in transaction number ${transactionNumber} for DID ${didUniqueSuffix}: ${SidetreeError.stringify(\n          error\n        )}.`\n      );\n\n      // Return the given DID state if error is encountered applying the patches.\n      return didState;\n    }\n\n    const newDidState = {\n      didUniqueSuffix: operation.didUniqueSuffix,\n      document,\n      nextRecoveryCommitmentHash: operation.suffixData.recovery_commitment,\n      nextUpdateCommitmentHash: delta ? delta.update_commitment : undefined,\n      lastOperationTransactionNumber: anchoredOperationModel.transactionNumber,\n    };\n\n    return newDidState;\n  }\n\n  /**\n   * @returns new DID state if operation is applied successfully; the given DID state otherwise.\n   */\n  private async applyUpdateOperation(\n    anchoredOperationModel: AnchoredOperationModel,\n    didState: DidState\n  ): Promise<DidState> {\n    const operation = await UpdateOperation.parse(\n      anchoredOperationModel.operationBuffer\n    );\n\n    // Verify the update key hash.\n    const isValidUpdateKey = Multihash.canonicalizeAndVerify(\n      operation.signedData.update_key,\n      didState.nextUpdateCommitmentHash!\n    );\n\n    if (!isValidUpdateKey) {\n      return didState;\n    }\n\n    // Verify the signature.\n    const signatureIsValid = await operation.signedDataJws.verifySignature(\n      operation.signedData.update_key\n    );\n\n    if (!signatureIsValid) {\n      return didState;\n    }\n\n    // Verify the delta hash against the expected delta hash.\n    const isValidDelta = Multihash.isValidHash(\n      operation.encodedDelta,\n      operation.signedData.delta_hash\n    );\n\n    if (!isValidDelta) {\n      return didState;\n    }\n\n    let resultingDocument;\n    try {\n      resultingDocument = await DocumentComposer.applyUpdateOperation(\n        operation,\n        didState.document\n      );\n    } catch (error) {\n      const didUniqueSuffix = anchoredOperationModel.didUniqueSuffix;\n      const transactionNumber = anchoredOperationModel.transactionNumber;\n      console.debug(\n        `Unable to apply document patch in transaction number ${transactionNumber} for DID ${didUniqueSuffix}: ${SidetreeError.stringify(\n          error\n        )}.`\n      );\n\n      // Return the given DID state if error is encountered applying the patches.\n      return didState;\n    }\n\n    const newDidState = {\n      nextRecoveryCommitmentHash: didState.nextRecoveryCommitmentHash,\n      // New values below.\n      document: resultingDocument,\n      nextUpdateCommitmentHash: operation.delta!.update_commitment,\n      lastOperationTransactionNumber: anchoredOperationModel.transactionNumber,\n    };\n\n    return newDidState;\n  }\n\n  /**\n   * @returns new DID state if operation is applied successfully; the given DID state otherwise.\n   */\n  private async applyRecoverOperation(\n    anchoredOperationModel: AnchoredOperationModel,\n    didState: DidState\n  ): Promise<DidState> {\n    const operation = await RecoverOperation.parse(\n      anchoredOperationModel.operationBuffer\n    );\n\n    // Verify the recovery key hash.\n    const isValidRecoveryKey = Multihash.canonicalizeAndVerify(\n      operation.signedData.recovery_key,\n      didState.nextRecoveryCommitmentHash!\n    );\n    if (!isValidRecoveryKey) {\n      return didState;\n    }\n\n    // Verify the signature.\n    const signatureIsValid = await operation.signedDataJws.verifySignature(\n      operation.signedData.recovery_key\n    );\n    if (!signatureIsValid) {\n      return didState;\n    }\n\n    // Verify the actual delta hash against the expected delta hash.\n    const isMatchingDelta = Multihash.isValidHash(\n      operation.encodedDelta,\n      operation.signedData.delta_hash\n    );\n    if (!isMatchingDelta) {\n      return didState;\n    }\n\n    // Apply the given patches against an empty object.\n    const delta = operation.delta;\n    let document = {};\n    try {\n      if (delta !== undefined) {\n        document = DocumentComposer.applyPatches(document, delta.patches);\n      }\n    } catch (error) {\n      const didUniqueSuffix = anchoredOperationModel.didUniqueSuffix;\n      const transactionNumber = anchoredOperationModel.transactionNumber;\n      console.debug(\n        `Unable to apply document patch in transaction number ${transactionNumber} for DID ${didUniqueSuffix}: ${SidetreeError.stringify(\n          error\n        )}.`\n      );\n\n      // Return the given DID state if error is encountered applying the patches.\n      return didState;\n    }\n\n    const newDidState = {\n      didUniqueSuffix: operation.didUniqueSuffix,\n      document,\n      recovery_key: operation.signedData.recovery_key,\n      nextRecoveryCommitmentHash: operation.signedData.recovery_commitment,\n      nextUpdateCommitmentHash: delta ? delta.update_commitment : undefined,\n      lastOperationTransactionNumber: anchoredOperationModel.transactionNumber,\n    };\n\n    return newDidState;\n  }\n\n  /**\n   * @returns new DID state if operation is applied successfully; the given DID state otherwise.\n   */\n  private async applyDeactivateOperation(\n    anchoredOperationModel: AnchoredOperationModel,\n    didState: DidState\n  ): Promise<DidState> {\n    const operation = await DeactivateOperation.parse(\n      anchoredOperationModel.operationBuffer\n    );\n\n    // Verify the recovery key hash.\n    const isValidRecoveryKey = Multihash.canonicalizeAndVerify(\n      operation.signedData.recovery_key,\n      didState.nextRecoveryCommitmentHash!\n    );\n    if (!isValidRecoveryKey) {\n      return didState;\n    }\n\n    // Verify the signature.\n    const signatureIsValid = await operation.signedDataJws.verifySignature(\n      operation.signedData.recovery_key\n    );\n    if (!signatureIsValid) {\n      return didState;\n    }\n\n    // The operation passes all checks.\n    const newDidState = {\n      document: didState.document,\n      // New values below.\n      recovery_key: undefined,\n      nextRecoveryCommitmentHash: undefined,\n      nextUpdateCommitmentHash: undefined,\n      lastOperationTransactionNumber: anchoredOperationModel.transactionNumber,\n    };\n    return newDidState;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ErrorCode,\n  Multihash,\n  OperationType,\n  SidetreeError,\n} from '@sidetree/common';\nimport CreateOperation from './CreateOperation';\nimport { URL } from 'url';\n\n/**\n * Class containing reusable Sidetree DID related operations.\n */\nexport default class Did {\n  private static readonly initialStateParameterSuffix = 'initial-state';\n\n  /** `true` if DID is short form; `false` if DID is long-form. */\n  public isShortForm: boolean;\n  /** DID method name. */\n  public didMethodName: string;\n  /** DID unique suffix. */\n  public uniqueSuffix: string;\n  /** The create operation if the DID given is long-form, `undefined` otherwise. */\n  public createOperation?: CreateOperation;\n  /** The short form. */\n  public shortForm: string;\n\n  /**\n   * Parses the input string as Sidetree DID.\n   * NOTE: Must not call this constructor directly, use the factory `create` method instead.\n   * @param did Short or long-form DID string.\n   * @param didMethodName The expected DID method given in the DID string. The method throws SidetreeError if mismatch.\n   */\n  private constructor(did: string, didMethodName: string) {\n    this.didMethodName = didMethodName;\n    const didPrefix = `did:${didMethodName}:`;\n\n    if (!did.startsWith(didPrefix)) {\n      throw new SidetreeError(ErrorCode.DidIncorrectPrefix);\n    }\n\n    const indexOfQuestionMarkChar = did.indexOf('?');\n    // If there is no question mark, then DID can only be in short-form.\n    if (indexOfQuestionMarkChar < 0) {\n      this.isShortForm = true;\n    } else {\n      this.isShortForm = false;\n    }\n\n    if (this.isShortForm) {\n      this.uniqueSuffix = did.substring(didPrefix.length);\n    } else {\n      // This is long-form.\n      this.uniqueSuffix = did.substring(\n        didPrefix.length,\n        indexOfQuestionMarkChar\n      );\n    }\n\n    if (this.uniqueSuffix.length === 0) {\n      throw new SidetreeError(ErrorCode.DidNoUniqueSuffix);\n    }\n\n    this.shortForm = didPrefix + this.uniqueSuffix;\n  }\n\n  /**\n   * Parses the input string as Sidetree DID.\n   * @param didString Short or long-form DID string.\n   */\n  public static async create(\n    didString: string,\n    didMethodName: string\n  ): Promise<Did> {\n    const did = new Did(didString, didMethodName);\n\n    // If DID is long-form, ensure the unique suffix constructed from the suffix data matches the short-form DID and populate the `createOperation` property.\n    if (!did.isShortForm) {\n      const initialState = Did.getInitialStateFromDidString(\n        didString,\n        didMethodName\n      );\n      const createOperation = await Did.constructCreateOperationFromInitialState(\n        initialState\n      );\n\n      // NOTE: we cannot use the unique suffix directly from `createOperation.didUniqueSuffix` for comparison,\n      // becasue a given long-form DID may have been created long ago,\n      // thus this version of `CreateOperation.parse()` maybe using a different hashing algorithm than that of the unique DID suffix (short-form).\n      // So we compute the suffix data hash again using the hashing algorithm used by the given unique DID suffix (short-form).\n      const suffixDataHashMatchesUniqueSuffix = Multihash.isValidHash(\n        createOperation.encodedSuffixData,\n        did.uniqueSuffix\n      );\n\n      // If the computed suffix data hash is not the same as the unique suffix given in the DID string, the DID is not valid.\n      if (!suffixDataHashMatchesUniqueSuffix) {\n        throw new SidetreeError(\n          ErrorCode.DidUniqueSuffixFromInitialStateMismatch\n        );\n      }\n\n      did.createOperation = createOperation;\n    }\n\n    return did;\n  }\n\n  private static getInitialStateFromDidString(\n    didString: string,\n    methodNameWithNetworkId: string\n  ): string {\n    let didStringUrl = undefined;\n    try {\n      didStringUrl = new URL(didString);\n    } catch {\n      throw new SidetreeError(ErrorCode.DidInvalidDidString);\n    }\n\n    // TODO: #470 - Support/disambiguate \"network ID\" in method name.\n\n    // Stripping away the potential network ID portion. e.g. 'sidetree:test' -> 'sidetree'\n    const methodName = methodNameWithNetworkId.split(':')[0];\n\n    let queryParamCounter = 0;\n    let initialStateValue;\n\n    // Verify that `-<method-name>-initial-state` is the one and only parameter.\n    for (const [key, value] of didStringUrl.searchParams) {\n      queryParamCounter += 1;\n      if (queryParamCounter > 1) {\n        throw new SidetreeError(ErrorCode.DidLongFormOnlyOneQueryParamAllowed);\n      }\n\n      // expect key to be -<method-name>-initial-state\n      const expectedKey = `-${methodName}-${Did.initialStateParameterSuffix}`;\n      if (key !== expectedKey) {\n        throw new SidetreeError(\n          ErrorCode.DidLongFormOnlyInitialStateParameterIsAllowed\n        );\n      }\n\n      initialStateValue = value;\n    }\n\n    if (initialStateValue === undefined) {\n      throw new SidetreeError(ErrorCode.DidLongFormNoInitialStateFound);\n    }\n\n    return initialStateValue;\n  }\n\n  private static async constructCreateOperationFromInitialState(\n    initialState: string\n  ): Promise<CreateOperation> {\n    // Initial state should be in the format: <suffix-data>.<delta>\n    const firstIndexOfDot = initialState.indexOf('.');\n    if (firstIndexOfDot === -1) {\n      throw new SidetreeError(ErrorCode.DidInitialStateValueContainsNoDot);\n    }\n\n    const lastIndexOfDot = initialState.lastIndexOf('.');\n    if (lastIndexOfDot !== firstIndexOfDot) {\n      throw new SidetreeError(\n        ErrorCode.DidInitialStateValueContainsMoreThanOneDot\n      );\n    }\n\n    if (firstIndexOfDot === initialState.length - 1 || firstIndexOfDot === 0) {\n      throw new SidetreeError(\n        ErrorCode.DidInitialStateValueDoesNotContainTwoParts\n      );\n    }\n\n    const initialStateParts = initialState.split('.');\n    const suffixData = initialStateParts[0];\n    const delta = initialStateParts[1];\n    const createOperationRequest = {\n      type: OperationType.Create,\n      suffix_data: suffixData,\n      delta,\n    };\n    const createOperationBuffer = Buffer.from(\n      JSON.stringify(createOperationRequest)\n    );\n    const createOperation = await CreateOperation.parseObject(\n      createOperationRequest,\n      createOperationBuffer,\n      false\n    );\n\n    return createOperation;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  DidState,\n  ErrorCode,\n  IOperationQueue,\n  IRequestHandler,\n  OperationModel,\n  OperationType,\n  protocolParameters,\n  ResponseModel,\n  ResponseStatus,\n  SidetreeError,\n} from '@sidetree/common';\nimport Did from './Did';\nimport DocumentComposer from './DocumentComposer';\nimport JsonAsync from './util/JsonAsync';\nimport Operation from './Operation';\nimport OperationProcessor from './OperationProcessor';\nimport Resolver from './Resolver';\n\n/**\n * Sidetree operation request handler.\n */\nexport default class RequestHandler implements IRequestHandler {\n  private operationProcessor: OperationProcessor;\n\n  public constructor(\n    private resolver: Resolver,\n    private operationQueue: IOperationQueue,\n    private didMethodName: string\n  ) {\n    this.operationProcessor = new OperationProcessor();\n  }\n\n  /**\n   * Handles an operation request.\n   */\n  public async handleOperationRequest(request: Buffer): Promise<ResponseModel> {\n    console.info(\n      `Handling operation request of size ${request.length} bytes...`\n    );\n\n    // Perform common validation for any write request and parse it into an `OperationModel`.\n    let operationModel: OperationModel;\n    try {\n      const operationRequest = await JsonAsync.parse(request);\n\n      // Check `delta` property data size if they exist in the operation.\n      if (\n        operationRequest.type === OperationType.Create ||\n        operationRequest.type === OperationType.Recover ||\n        operationRequest.type === OperationType.Update\n      ) {\n        const deltaBuffer = Buffer.from(operationRequest.delta);\n        if (deltaBuffer.length > protocolParameters.maxDeltaSizeInBytes) {\n          const errorMessage = `operationDdata byte size of ${deltaBuffer.length} exceeded limit of ${protocolParameters.maxDeltaSizeInBytes}`;\n          console.info(errorMessage);\n          throw new SidetreeError(\n            ErrorCode.RequestHandlerDeltaExceedsMaximumSize,\n            errorMessage\n          );\n        }\n      }\n\n      operationModel = await Operation.parse(request);\n\n      // Reject operation if there is already an operation for the same DID waiting to be batched and anchored.\n      if (await this.operationQueue.contains(operationModel.didUniqueSuffix)) {\n        const errorMessage = `An operation request already exists in queue for DID '${operationModel.didUniqueSuffix}', only one is allowed at a time.`;\n        throw new SidetreeError(\n          ErrorCode.QueueingMultipleOperationsPerDidNotAllowed,\n          errorMessage\n        );\n      }\n    } catch (error) {\n      // Give meaningful/specific error code and message when possible.\n      if (error instanceof SidetreeError) {\n        console.info(`Bad request: ${error.code}`);\n        console.info(`Error message: ${error.message}`);\n        return {\n          status: ResponseStatus.BadRequest,\n          body: { code: error.code, message: error.message },\n        };\n      }\n\n      // Else we give a generic bad request response.\n      console.info(`Bad request: ${error}`);\n      return {\n        status: ResponseStatus.BadRequest,\n      };\n    }\n\n    try {\n      console.info(\n        `Operation type: '${operationModel.type}', DID unique suffix: '${operationModel.didUniqueSuffix}'`\n      );\n\n      // Passed common operation validation, hand off to specific operation handler.\n      let response: ResponseModel;\n      switch (operationModel.type) {\n        case OperationType.Create:\n          response = await this.handleCreateRequest(operationModel);\n          break;\n        // these cases do nothing because we do not know the latest document state unless we resolve.\n        case OperationType.Update:\n        case OperationType.Recover:\n        case OperationType.Deactivate:\n          response = {\n            status: ResponseStatus.Succeeded,\n          };\n          break;\n        default:\n          // Should be an impossible condition, but we defensively check and handle.\n          response = {\n            status: ResponseStatus.BadRequest,\n            body: {\n              code: ErrorCode.RequestHandlerUnknownOperationType,\n              message: `Unsupported operation type '${operationModel.type}'.`,\n            },\n          };\n      }\n\n      // if the operation was processed successfully, queue the original request buffer for batching.\n      if (response.status === ResponseStatus.Succeeded) {\n        await this.operationQueue.enqueue(\n          operationModel.didUniqueSuffix,\n          operationModel.operationBuffer\n        );\n      }\n\n      return response;\n    } catch (error) {\n      // Give meaningful/specific error code and message when possible.\n      if (error instanceof SidetreeError) {\n        console.info(`Sidetree error: ${error.code} ${error.message}`);\n        return {\n          status: ResponseStatus.BadRequest,\n          body: { code: error.code, message: error.message },\n        };\n      }\n\n      console.info(`Unexpected error: ${error}`);\n      return {\n        status: ResponseStatus.ServerError,\n      };\n    }\n  }\n\n  private async handleCreateRequest(\n    operationModel: OperationModel\n  ): Promise<ResponseModel> {\n    const didState = await this.applyCreateOperation(operationModel);\n\n    // Should be an impossible condition, but we defensively check and handle.\n    if (didState === undefined) {\n      return {\n        status: ResponseStatus.BadRequest,\n        body: 'Invalid create operation.',\n      };\n    }\n\n    const did = `did:${this.didMethodName}:${operationModel.didUniqueSuffix}`;\n    const document = DocumentComposer.transformToExternalDocument(\n      didState,\n      did\n    );\n\n    return {\n      status: ResponseStatus.Succeeded,\n      body: document,\n    };\n  }\n\n  /**\n   * Handles resolve operation.\n   * @param shortOrLongFormDid Can either be:\n   *   1. A short-form DID. e.g. 'did:<methodName>:abc' or\n   *   2. A long-form DID. e.g. 'did:<methodName>:<unique-portion>?-<methodName>-initial-state=<encoded-original-did-document>'.\n   */\n  public async handleResolveRequest(\n    shortOrLongFormDid: string\n  ): Promise<ResponseModel> {\n    try {\n      console.info(`Handling resolution request for: ${shortOrLongFormDid}...`);\n\n      const did = await Did.create(shortOrLongFormDid, this.didMethodName);\n\n      let didState: DidState | undefined;\n      if (did.isShortForm) {\n        didState = await this.resolver.resolve(did.uniqueSuffix);\n      } else {\n        didState = await this.resolveLongFormDid(did);\n      }\n\n      if (didState === undefined) {\n        return {\n          status: ResponseStatus.NotFound,\n        };\n      }\n\n      const document = DocumentComposer.transformToExternalDocument(\n        didState,\n        shortOrLongFormDid\n      );\n\n      return {\n        status: ResponseStatus.Succeeded,\n        body: document,\n      };\n    } catch (error) {\n      // Give meaningful/specific error code and message when possible.\n      if (error instanceof SidetreeError) {\n        return {\n          status: ResponseStatus.BadRequest,\n          body: { code: error.code, message: error.message },\n        };\n      }\n\n      console.info(`Unexpected error: ${error}`);\n      return {\n        status: ResponseStatus.ServerError,\n      };\n    }\n  }\n\n  /**\n   * Resolves the given long-form DID by resolving using operations found over the network first;\n   * if no operations found, the given create operation will is used to construct the DID state.\n   */\n  private async resolveLongFormDid(did: Did): Promise<DidState | undefined> {\n    // Attempt to resolve the DID by using operations found from the network first.\n    let didState = await this.resolver.resolve(did.uniqueSuffix);\n\n    // If DID state found then return it.\n    if (didState !== undefined) {\n      return didState;\n    }\n\n    // The code reaches here if this DID is not registered on the ledger.\n\n    didState = await this.applyCreateOperation(did.createOperation!);\n\n    return didState;\n  }\n\n  private async applyCreateOperation(\n    createOperation: OperationModel\n  ): Promise<DidState | undefined> {\n    const operationWithMockedAnchorTime = {\n      didUniqueSuffix: createOperation.didUniqueSuffix,\n      type: OperationType.Create,\n      transactionTime: 0,\n      transactionNumber: 0,\n      operationIndex: 0,\n      operationBuffer: createOperation.operationBuffer,\n    }; // NOTE: The transaction timing does not matter here, we are just computing a \"theoretical\" document if it were anchored on blockchain.\n\n    const newDidState = await this.operationProcessor.apply(\n      operationWithMockedAnchorTime,\n      undefined\n    );\n    return newDidState;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AbstractVersionMetadata, protocolParameters } from '@sidetree/common';\n\n/**\n * Implementation of the abstract VersionMetadata.\n */\nexport default class VersionMetadata extends AbstractVersionMetadata {\n  public hashAlgorithmInMultihashCode: number;\n  public normalizedFeeToPerOperationFeeMultiplier: number;\n  public valueTimeLockAmountMultiplier: number;\n  public constructor() {\n    super();\n    this.hashAlgorithmInMultihashCode =\n      protocolParameters.hashAlgorithmInMultihashCode;\n    this.normalizedFeeToPerOperationFeeMultiplier =\n      protocolParameters.normalizedFeeToPerOperationFeeMultiplier;\n    this.valueTimeLockAmountMultiplier =\n      protocolParameters.valueTimeLockAmountMultiplier;\n  }\n}\n","/*\n * The code in this file originated from\n * @see https://github.com/decentralized-identity/sidetree\n * For the list of changes that was made to the original code\n * @see https://github.com/transmute-industries/sidetree.js/blob/main/reference-implementation-changes.md\n *\n * Copyright 2020 - Transmute Industries Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *     http://www.apache.org/licenses/LICENSE-2.0\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AbstractVersionMetadata,\n  Config,\n  CoreErrorCode,\n  IBatchWriter,\n  IBlockchain,\n  ICas,\n  IOperationProcessor,\n  IOperationStore,\n  IRequestHandler,\n  ITransactionProcessor,\n  ITransactionSelector,\n  ITransactionStore,\n  IVersionManager,\n  IVersionMetadataFetcher,\n  ProtocolVersionModel,\n  SidetreeError,\n  IOperationQueue,\n} from '@sidetree/common';\nimport DownloadManager from './DownloadManager';\nimport Resolver from './Resolver';\nimport { MongoDbOperationQueue } from '@sidetree/db';\nimport TransactionProcessor from './TransactionProcessor';\nimport TransactionSelector from './TransactionSelector';\nimport BatchWriter from './write/BatchWriter';\nimport OperationProcessor from './OperationProcessor';\nimport RequestHandler from './RequestHandler';\nimport VersionMetadata from './VersionMetadata';\n\n/**\n * The class that handles the loading of different versions of protocol codebase.\n */\nexport default class VersionManager\n  implements IVersionManager, IVersionMetadataFetcher {\n  public allSupportedHashAlgorithms: number[] = [];\n\n  // Reverse sorted protocol versions. ie. latest version first.\n  private protocolVersionsReverseSorted: ProtocolVersionModel[];\n\n  private batchWriters: Map<string, IBatchWriter>;\n  private operationProcessors: Map<string, IOperationProcessor>;\n  private operationQueues: Map<string, IOperationQueue>;\n  private requestHandlers: Map<string, IRequestHandler>;\n  private transactionProcessors: Map<string, ITransactionProcessor>;\n  private transactionSelectors: Map<string, ITransactionSelector>;\n  private versionMetadatas: Map<string, AbstractVersionMetadata>;\n\n  public constructor(\n    private config: Config,\n    protocolVersions: ProtocolVersionModel[]\n  ) {\n    // Reverse sort protocol versions.\n    this.protocolVersionsReverseSorted = protocolVersions.sort(\n      (a, b) => b.startingBlockchainTime - a.startingBlockchainTime\n    );\n\n    this.batchWriters = new Map();\n    this.operationProcessors = new Map();\n    this.operationQueues = new Map();\n    this.requestHandlers = new Map();\n    this.transactionProcessors = new Map();\n    this.transactionSelectors = new Map();\n    this.versionMetadatas = new Map();\n  }\n\n  /**\n   * Loads all the versions of the protocol codebase.\n   */\n  public async initialize(\n    blockchain: IBlockchain,\n    cas: ICas,\n    downloadManager: DownloadManager,\n    operationStore: IOperationStore,\n    resolver: Resolver,\n    transactionStore: ITransactionStore\n  ): Promise<void> {\n    // Instantiate rest of the protocol components.\n    // NOTE: In principal each version of the interface implemtnations can have different constructors,\n    // but we currently keep the constructor signature the same as much as possible for simple instance construction,\n    // but it is not inherently \"bad\" if we have to have conditional constructions for each if we have to.\n    for (const protocolVersion of this.protocolVersionsReverseSorted) {\n      const version = protocolVersion.version;\n\n      /* tslint:disable-next-line */\n      const MongoDbOperationQueue = await this.loadDefaultExportsForVersion(\n        version,\n        'MongoDbOperationQueue'\n      );\n      const operationQueue = new MongoDbOperationQueue(\n        this.config.mongoDbConnectionString,\n        this.config.databaseName\n      );\n      await operationQueue.initialize();\n      this.operationQueues.set(version, operationQueue);\n\n      /* tslint:disable-next-line */\n      const TransactionProcessor = await this.loadDefaultExportsForVersion(\n        version,\n        'TransactionProcessor'\n      );\n      const transactionProcessor = new TransactionProcessor(\n        downloadManager,\n        operationStore,\n        blockchain,\n        this\n      );\n      this.transactionProcessors.set(version, transactionProcessor);\n\n      /* tslint:disable-next-line */\n      const TransactionSelector = await this.loadDefaultExportsForVersion(\n        version,\n        'TransactionSelector'\n      );\n      const transactionSelector = new TransactionSelector(transactionStore);\n      this.transactionSelectors.set(version, transactionSelector);\n\n      /* tslint:disable-next-line */\n      const BatchWriter = await this.loadDefaultExportsForVersion(\n        version,\n        'BatchWriter'\n      );\n      const batchWriter = new BatchWriter(\n        operationQueue,\n        blockchain,\n        cas,\n        this\n      );\n      this.batchWriters.set(version, batchWriter);\n\n      /* tslint:disable-next-line */\n      const OperationProcessor = await this.loadDefaultExportsForVersion(\n        version,\n        'OperationProcessor'\n      );\n      const operationProcessor = new OperationProcessor();\n      this.operationProcessors.set(version, operationProcessor);\n\n      /* tslint:disable-next-line */\n      const RequestHandler = await this.loadDefaultExportsForVersion(\n        version,\n        'RequestHandler'\n      );\n      const requestHandler = new RequestHandler(\n        resolver,\n        operationQueue,\n        this.config.didMethodName\n      );\n      this.requestHandlers.set(version, requestHandler);\n\n      /* tslint:disable-next-line */\n      const VersionMetadata = await this.loadDefaultExportsForVersion(\n        version,\n        'VersionMetadata'\n      );\n      const versionMetadata = new VersionMetadata();\n      if (!(versionMetadata instanceof AbstractVersionMetadata)) {\n        throw new SidetreeError(\n          CoreErrorCode.VersionManagerVersionMetadataIncorrectType,\n          `make sure VersionMetaData is properly implemented for version ${version}`\n        );\n      }\n      this.versionMetadatas.set(version, versionMetadata);\n    }\n\n    // Get and cache supported hash algorithms.\n    const hashAlgorithmsWithDuplicates = Array.from(\n      this.versionMetadatas.values(),\n      (value) => value.hashAlgorithmInMultihashCode\n    );\n    this.allSupportedHashAlgorithms = Array.from(\n      new Set(hashAlgorithmsWithDuplicates)\n    ); // This line removes duplicates.\n  }\n\n  /**\n   * Gets the corresponding version of the `IBatchWriter` based on the given blockchain time.\n   */\n  public getBatchWriter(blockchainTime: number): IBatchWriter {\n    const version = this.getVersionString(blockchainTime);\n    const batchWriter = this.batchWriters.get(version);\n\n    if (batchWriter === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerBatchWriterNotFound,\n        `Batch writer for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return batchWriter;\n  }\n\n  /**\n   * Gets the corresponding version of the `IOperationProcessor` based on the given blockchain time.\n   */\n  public getOperationProcessor(blockchainTime: number): IOperationProcessor {\n    const version = this.getVersionString(blockchainTime);\n    const operationProcessor = this.operationProcessors.get(version);\n\n    if (operationProcessor === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerOperationProcessorNotFound,\n        `Operation processor for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return operationProcessor;\n  }\n\n  /**\n   * Gets the corresponding version of the `IRequestHandler` based on the given blockchain time.\n   */\n  public getRequestHandler(blockchainTime: number): IRequestHandler {\n    const version = this.getVersionString(blockchainTime);\n    const requestHandler = this.requestHandlers.get(version);\n\n    if (requestHandler === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerRequestHandlerNotFound,\n        `Request handler for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return requestHandler;\n  }\n\n  /**\n   * Gets the corresponding version of the `TransactionProcessor` based on the given blockchain time.\n   */\n  public getTransactionProcessor(\n    blockchainTime: number\n  ): ITransactionProcessor {\n    const version = this.getVersionString(blockchainTime);\n    const transactionProcessor = this.transactionProcessors.get(version);\n\n    if (transactionProcessor === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerTransactionProcessorNotFound,\n        `Transaction processor for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return transactionProcessor;\n  }\n\n  /**\n   * Gets the corresponding version of the `TransactionSelector` based on the given blockchain time.\n   */\n  public getTransactionSelector(blockchainTime: number): ITransactionSelector {\n    const version = this.getVersionString(blockchainTime);\n    const transactionSelector = this.transactionSelectors.get(version);\n\n    if (transactionSelector === undefined) {\n      throw new SidetreeError(\n        CoreErrorCode.VersionManagerTransactionSelectorNotFound,\n        `Transaction selector for blockchain time ${blockchainTime} not found.`\n      );\n    }\n\n    return transactionSelector;\n  }\n\n  public getVersionMetadata(blockchainTime: number): AbstractVersionMetadata {\n    const versionString = this.getVersionString(blockchainTime);\n    const versionMetadata = this.versionMetadatas.get(versionString);\n    // this is always be defined because if blockchain time is found, version will be defined\n    return versionMetadata!;\n  }\n\n  public getOperationQueue(blockchainTime: number): IOperationQueue {\n    const versionString = this.getVersionString(blockchainTime);\n    const operationQueue = this.operationQueues.get(versionString);\n    // this is always be defined because if blockchain time is found, version will be defined\n    return operationQueue!;\n  }\n\n  /**\n   * Gets the corresponding protocol version string given the blockchain time.\n   */\n  private getVersionString(blockchainTime: number): string {\n    // Iterate through each version to find the right version.\n    for (const protocolVersion of this.protocolVersionsReverseSorted) {\n      if (blockchainTime >= protocolVersion.startingBlockchainTime) {\n        return protocolVersion.version;\n      }\n    }\n\n    throw new SidetreeError(\n      CoreErrorCode.VersionManagerVersionStringNotFound,\n      `Unable to find version string for blockchain time ${blockchainTime}.`\n    );\n  }\n\n  private async loadDefaultExportsForVersion(\n    version: string,\n    className: string\n  ): Promise<any> {\n    if (version === 'latest') {\n      switch (className) {\n        case 'MongoDbOperationQueue':\n          return MongoDbOperationQueue;\n        case 'TransactionProcessor':\n          return TransactionProcessor;\n        case 'TransactionSelector':\n          return TransactionSelector;\n        case 'BatchWriter':\n          return BatchWriter;\n        case 'OperationProcessor':\n          return OperationProcessor;\n        case 'RequestHandler':\n          return RequestHandler;\n        case 'VersionMetadata':\n          return VersionMetadata;\n        default:\n          return;\n      }\n    }\n    return (await import(`./versions/${version}/${className}`)).default;\n  }\n}\n"],"names":["runtime","exports","Op","Object","prototype","hasOwn","hasOwnProperty","$Symbol","Symbol","iteratorSymbol","iterator","asyncIteratorSymbol","asyncIterator","toStringTagSymbol","toStringTag","define","obj","key","value","defineProperty","enumerable","configurable","writable","err","wrap","innerFn","outerFn","self","tryLocsList","generator","create","Generator","context","Context","_invoke","state","method","arg","Error","undefined","done","delegate","delegateResult","maybeInvokeDelegate","ContinueSentinel","sent","_sent","dispatchException","abrupt","record","tryCatch","type","makeInvokeMethod","fn","call","GeneratorFunction","GeneratorFunctionPrototype","IteratorPrototype","this","getProto","getPrototypeOf","NativeIteratorPrototype","values","Gp","defineIteratorMethods","forEach","AsyncIterator","PromiseImpl","previousPromise","callInvokeWithMethodAndArg","resolve","reject","invoke","result","__await","then","unwrapped","error","TypeError","info","resultName","next","nextLoc","pushTryEntry","locs","entry","tryLoc","catchLoc","finallyLoc","afterLoc","tryEntries","push","resetTryEntry","completion","reset","iterable","iteratorMethod","isNaN","length","i","doneResult","constructor","displayName","isGeneratorFunction","genFun","ctor","name","mark","setPrototypeOf","__proto__","awrap","async","Promise","iter","toString","keys","object","reverse","pop","skipTempReset","prev","charAt","slice","stop","rootRecord","rval","exception","handle","loc","caught","hasCatch","hasFinally","finallyEntry","complete","finish","catch","thrown","delegateYield","module","regeneratorRuntime","accidentalStrictMode","Function","ArrayMethods","hasDuplicates","array","uniqueValues","Set","has","add","areMutuallyExclusive","array1","array2","valuesInArray1","pako","require","Compressor","compress","inputAsBuffer","deflate","Buffer","from","decompress","inflate","DocumentComposer","transformToExternalDocument","didState","did","nextRecoveryCommitmentHash","status","document","shortFormDid","split","authentication","assertionMethod","capabilityInvocation","capabilityDelegation","keyAgreement","public_keys","Array","isArray","publicKey","id","didDocumentPublicKey","controller","publicKeyJwk","jwk","purposeSet","purpose","PublicKeyPurpose","General","Auth","AssertionMethod","CapabilityInvocation","CapabilityDelegation","KeyAgreement","service_endpoints","serviceEndpoint","endpoint","didDocument","service","JSON","parse","stringify","didDocumentMetadata","recoveryCommitment","updateCommitment","nextUpdateCommitmentHash","applyUpdateOperation","operation","resultantDocument","applyPatches","delta","patches","validateDocument","SidetreeError","ErrorCode","DocumentComposerDocumentMissing","allowedProperties","property","DocumentComposerUnknownPropertyInDocument","validatePublicKeys","validateServiceEndpoints","validateDocumentPatches","DocumentComposerUpdateOperationDocumentPatchesNotArray","validatePatch","patch","action","validateAddPublicKeysPatch","validateRemovePublicKeysPatch","validateAddServiceEndpointsPatch","validateRemoveServiceEndpointsPatch","validateIetfJsonPatch","DocumentComposerPatchMissingOrUnknownAction","DocumentComposerPatchMissingOrUnknownProperty","jsonpatch","validate","console","warn","DocumentComposerPublicKeysNotArray","publicKeyIdSet","DocumentComposerPublicKeyMissingOrUnknownProperty","DocumentComposerPublicKeyJwkMissingOrIncorrectType","DocumentComposerPublicKeyTypeMissingOrIncorrectType","validateId","DocumentComposerPublicKeyIdDuplicated","DocumentComposerPublicKeyPurposeMissingOrUnknown","DocumentComposerPublicKeyPurposeExceedsMaxLength","validPurposes","DocumentComposerPublicKeyInvalidPurpose","DocumentComposerPatchPublicKeyIdsNotArray","DocumentComposerPatchPublicKeyIdNotString","ids","DocumentComposerPatchServiceEndpointIdsNotArray","DocumentComposerPatchServiceEndpointsNotArray","DocumentComposerServiceEndpointMissingOrUnknownProperty","DocumentComposerPatchServiceEndpointTypeNotString","DocumentComposerPatchServiceEndpointTypeTooLong","DocumentComposerPatchServiceEndpointServiceEndpointNotString","DocumentComposerPatchServiceEndpointServiceEndpointTooLong","URL","DocumentComposerPatchServiceEndpointServiceEndpointNotValidUrl","DocumentComposerIdNotString","DocumentComposerIdTooLong","Encoder","isBase64UrlString","DocumentComposerIdNotUsingBase64UrlCharacterSet","applyPatchToDidDocument","addPublicKeys","removePublicKeys","addServiceEndpoints","removeServiceEndpoints","applyIetfJsonPatch","applyPatch","newDocument","publicKeyMap","Map","map","set","entries","pkm","get","idToIndexMapper","idx","idsToRemove","filter","yieldableJson","JsonAsync","jsonData","jsonParsePromise","parseAsync","data","OperationUtils","parseDelta","deltaEncodedString","DeltaMissingOrNotString","deltaJsonString","decodeAsString","DeltaMissingOrUnknownProperty","OperationDocumentPatchesMissing","nextUpdateCommitment","decodeAsBuffer","update_commitment","Multihash","verifyHashComputedUsingLatestSupportedAlgorithm","CreateOperation","operationBuffer","didUniqueSuffix","encodedSuffixData","suffixData","encodedDelta","OperationType","Create","computeDidUniqueSuffix","suffixDataBuffer","multihash","hash","encode","parseOperationFromAnchorFile","input","parseObject","operationJsonString","operationObject","anchorFileMode","expectedPropertyCount","CreateOperationMissingOrUnknownProperty","suffix_data","parseSuffixData","CreateOperationTypeIncorrect","suffixDataEncodedString","CreateOperationSuffixDataMissingOrNotString","suffixDataJsonString","CreateOperationSuffixDataMissingOrUnknownProperty","delta_hash","nextRecoveryCommitment","recovery_commitment","Jwk","generateEd25519KeyPair","JWK","generate","privateKey","keyPair","toJWK","getBufferAtIndex","mnemonic","index","bip39","root","hdkey","fromMasterSeed","addrNode","derive","generateEd25519KeyPairFromMnemonic","privateKeyBuffer","Ed25519KeyPair","seed","ed25519KeyPair","toJwk","generateSecp256k1KeyPair","generateJwkKeyPairFromMnemonic","keyType","generateSecp256k1KeyPairFromMnemonic","keytoFrom","crv","privateKeyJwk","validatePublicJwk","JwkUndefined","JwkHasUnknownProperty","kty","JwkMissingOrInvalidKty","x","JwkMissingOrInvalidTypeX","y","JwkMissingOrInvalidTypeY","JwkMissingOrInvalidCrv","getCurve25519PublicKey","keyCopy","assign","d","Jws","compactJws","JwsCompactJwsNotString","parts","JwsCompactJwsInvalid","protectedHeader","payload","signature","decodedProtectedHeadJsonString","decodeBase64UrlAsString","decodedProtectedHeader","JwsProtectedHeaderMissingOrUnknownProperty","alg","JwsProtectedHeaderMissingOrIncorrectAlg","JwsSignatureNotBase64UrlString","JwsPayloadNotBase64UrlString","toCompactJws","createCompactJws","verifySignature","encodedProtectedHeader","encodedPayload","jwsSigningInput","verifyCompactJws","EdDSA","verify","ES256K","log","createFromError","JwsFailedSignatureValidation","signAsCompactJws","header","sign","parseCompactJws","DeactivateOperation","signedDataJws","signedData","Deactivate","DeactivateOperationMissingOrUnknownProperty","did_suffix","DeactivateOperationMissingOrInvalidDidUniqueSuffix","signed_data","parseSignedDataPayload","DeactivateOperationTypeIncorrect","expectedDidUniqueSuffix","signedDataJsonString","DeactivateOperationSignedDataMissingOrUnknownProperty","DeactivateOperationSignedDidUniqueSuffixMismatch","recovery_key","didSuffix","RecoverOperation","Recover","RecoverOperationMissingOrUnknownProperty","RecoverOperationMissingOrInvalidDidUniqueSuffix","RecoverOperationTypeIncorrect","signedDataEncodedString","RecoverOperationSignedDataMissingOrUnknownProperty","AnchorFile","model","didUniqueSuffixes","createOperations","recoverOperations","deactivateOperations","anchorFileBuffer","anchorFileDecompressedBuffer","AnchorFileDecompressionFailure","anchorFileModel","AnchorFileNotJson","AnchorFileHasUnknownProperty","AnchorFileMapFileHashMissing","AnchorFileMissingOperationsProperty","writer_lock_id","AnchorFileWriterLockIPropertyNotString","map_file_uri","AnchorFileMapFileHashNotString","allowedOperationsProperties","operations","AnchorFileUnexpectedPropertyInOperations","AnchorFileCreatePropertyNotArray","createOperation","recover","AnchorFileRecoverPropertyNotArray","recoverOperation","deactivate","AnchorFileDeactivatePropertyNotArray","deactivateOperation","AnchorFileMultipleOperationsForTheSameDid","anchorFile","createModel","writerLockId","mapFileHash","createOperationArray","recoverOperationArray","deactivateOperationArray","createBuffer","anchorFileJson","BatchScheduler","versionManager","blockchain","batchingIntervalInSeconds","startPeriodicBatchWriting","continuePeriodicBatchWriting","setImmediate","_this","writeOperationBatch","stopPeriodicBatchWriting","endTimer","timeSpan","batchWriter","getBatchWriter","approximateTime","time","write","rounded","setTimeout","_this2","ChunkFile","chunkFileBuffer","decompressedChunkFileBuffer","chunkFileObject","ChunkFileUnexpectedProperty","validateDeltasProperty","deltas","ChunkFileDeltasPropertyNotArray","ChunkFileDeltasNotArrayOfStrings","deltaBuffer","protocolParameters","maxDeltaSizeInBytes","ChunkFileDeltaSizeExceedsLimit","updateOperations","rawData","DownloadManager","maxConcurrentDownloads","cas","start","completedDownloadHandles","activeDownloads","downloadHandle","downloadInfo","completed","completedDownloads","fetchResult","availableDownloadLanes","size","pendingDownloads","downloadAsync","splice","download","contentHash","maxSizeInBytes","crypto","fetchPromise","content","read","UpdateOperation","Update","parseOperationFromMapFile","mapFileMode","UpdateOperationMissingOrUnknownProperty","UpdateOperationMissingDidUniqueSuffix","signedDataModel","UpdateOperationTypeIncorrect","UpdateOperationSignedDataHasMissingOrUnknownProperty","update_key","MapFile","mapFileBuffer","decompressedBuffer","MapFileDecompressionFailure","mapFileModel","MapFileNotJson","MapFileHasUnknownProperty","validateChunksProperty","chunks","parseOperationsProperty","mapFile","MapFileOperationsPropertyHasMissingOrUnknownProperty","update","MapFileUpdateOperationsNotArray","MapFileMultipleOperationsForTheSameDid","MapFileChunksPropertyMissingOrIncorrectType","MapFileChunksPropertyDoesNotHaveExactlyOneElement","MapFileChunkHasMissingOrUnknownProperty","chunkFileHash","updateOperationArray","chunk_file_uri","ThroughputLimiter","getQualifiedTransactions","transactions","currentTransactionTime","transactionsGroupedByTransactionTime","transaction","transactionTime","qualifiedTransactions","transactionSelector","getTransactionSelector","transactionGroup","selectQualifiedTransactions","Observer","operationStore","transactionStore","unresolvableTransactionStore","observingIntervalInSeconds","throughputLimiter","refreshLastKnownTransaction","getLastTransaction","lastKnownTransaction","startPeriodicProcessing","continuePeriodicProcessing","processTransactions","stopPeriodicProcessing","awaitTransactionProcessing","storeConsecutiveTransactionsProcessed","moreTransactions","lastKnownTransactionNumber","transactionNumber","lastKnownTransactionTimeHash","transactionTimeHash","lastKnownTransactionTime","invalidTransactionNumberOrTimeHash","readResult","nextTransactionNumber","_context5","code","SharedErrorCode","InvalidTransactionNumberOrTimeHash","sort","a","b","transactionsUnderProcessing","awaitingTransaction","processingStatus","TransactionProcessingStatus","Pending","processTransaction","blockReorganizationDetected","waitUntilCountOfTransactionsUnderProcessingIsLessOrEqualTo","revertInvalidTransactions","processUnresolvableTransactions","count","getUnresolvableTransactionsDueForRetry","unresolvableTransactions","unresolvableTransactionStatus","Processed","addTransaction","transactionUnderProcessing","transactionProcessor","getTransactionProcessor","transactionProcessedSuccessfully","removeUnresolvableTransaction","recordUnresolvableTransactionFetchAttempt","getExponentiallySpacedTransactions","exponentiallySpacedTransactions","getFirstValidTransaction","bestKnownValidRecentTransactionNumber","bestKnownValidRecentTransaction","removeTransactionsLaterThan","removeUnresolvableTransactionsLaterThan","Operation","isAnchorFileMode","operationType","OperationTypeUnknownOrMissing","OperationGenerator","generateRandomHash","randomBuffer","generateKeyPair","publicKeyModel","generateAnchoredCreateOperation","generateCreateOperation","createOperationData","operationRequest","anchoredOperationModel","operationIndex","recoveryPublicKey","recoveryPrivateKey","updatePublicKey","updatePrivateKey","signingPublicKey","signingPrivateKey","nextUpdateRevealValueEncodedString","signingKeyId","generateServiceEndpoints","generateCreateOperationRequest","canonicalizeThenHashThenEncode","generateRecoverOperation","newSigningKeyId","newRecoveryPublicKey","newRecoveryPrivateKey","newSigningPublicKey","newSigningPrivateKey","publicKeyToBeInDocument","services","generateRecoverOperationRequest","generateUpdateOperation","additionalKeyId","additionalPublicKey","additionalPrivateKey","createUpdateOperationRequestForAddingAKey","updateOperation","nextUpdateKey","createAnchoredOperationModelFromOperationModel","operationModel","otherPublicKeys","generateUpdateOperationRequest","createUpdateOperationRequest","request","buffer","encodedDeltaString","signedDataPayloadObject","signUsingEd25519","createRecoverOperationRequest","createDeactivateOperationRequest","generateCreateOperationBuffer","newPublicKey","createUpdateOperationRequestForHubEndpoints","idOfServiceEndpointToAdd","idsOfServiceEndpointToRemove","createDeactivateOperation","Resolver","operationsByType","categorizeOperationsByType","applyCreateOperation","recoverAndDeactivateOperations","concat","constructCommitValueToOperationLookupMap","recoveryCommitValueToOperationMap","applyRecoverAndDeactivateOperations","updateCommitValueToOperationMap","applyUpdateOperations","applyOperation","startingDidState","commitValueToOperationMap","operationsWithCorrectRevealValue","applyFirstValidOperation","newDidState","appliedDidState","operationProcessor","getOperationProcessor","apply","originalDidState","lastOperationTransactionNumber","nonCreateOperations","allSupportedHashAlgorithms","hashAlgorithm","getRevealValue","hashOfRevealValue","hashThenEncode","ServiceInfoProvider","serviceName","getServiceVersion","version","packageJson","FeeManager","computeMinimumTransactionFee","normalizedFee","numberOfOperations","OperationCountLessThanZero","Math","max","normalizedFeeToPerOperationFeeMultiplier","verifyTransactionFeeAndThrowOnError","transactionFeePaid","TransactionFeePaidLessThanNormalizedFee","expectedFeePerOperation","TransactionFeePaidInvalid","ValueTimeLockVerifier","calculateMaxNumberOfOperationsAllowed","valueTimeLock","versionMetadataFetcher","maxNumberOfOperationsForNoValueTimeLock","versionMetadata","getVersionMetadata","lockTransactionTime","numberOfOpsAllowedInt","floor","amountLocked","valueTimeLockAmountMultiplier","verifyLockAmountAndThrowOnError","sidetreeTransactionTime","sidetreeTransactionWriter","owner","ValueTimeLockVerifierTransactionWriterLockOwnerMismatch","unlockTransactionTime","ValueTimeLockVerifierTransactionTimeOutsideLockRange","maxNumberOfOpsAllowed","ValueTimeLockVerifierInvalidNumberOfOperations","TransactionProcessor","downloadManager","anchoredData","AnchoredDataSerializer","deserialize","anchorString","normalizedTransactionFee","downloadAndVerifyAnchorFile","anchorFileHash","downloadAndVerifyMapFile","downloadAndVerifyChunkFile","chunkFileModel","composeAnchoredOperationModels","put","_context","CasNotReachable","CasFileNotFound","message","paidOperationCount","maxOperationsPerBatch","TransactionProcessorPaidOperationCountExceedsLimit","maxAnchorFileSizeInBytes","downloadFileFromCas","fileBuffer","operationCountInAnchorFile","AnchorFileOperationCountExceededPaidLimit","getValueTimeLock","writer","maxMapFileSizeInBytes","_context3","maxChunkFileSizeInBytes","_context4","chunkFile","patchedOperationBuffers","operationCountExcludingDeactivates","patchedOperationBuffer","anchoredOperationModels","fileHash","maxFileSizeInBytes","fileFetchResult","FetchResultCode","InvalidHash","CasFileHashNotValid","MaxSizeExceeded","CasFileTooLarge","NotAFile","CasFileNotAFile","NotFound","TransactionSelector","maxNumberOfOperationsPerBlock","maxNumberOfOperationsPerTransactionTime","maxNumberOfTransactionsPerBlock","maxNumberOfTransactionsPerTransactionTime","getTransactionPriorityQueue","PriorityQueue","comparator","transactionsPriorityQueue","validateTransactions","enqueueFirstTransactionFromEachWriter","getNumberOfOperationsAndTransactionsAlreadyInTransactionTime","transactionsToReturn","getHighestFeeTransactionsFromCurrentTransactionTime","TransactionsNotInSameBlock","writerToTransactionNumberMap","acceptedTransactionNumber","getTransactionsStartingFrom","numOfOperationsInCurrentTransaction","e","debug","getOwnPropertyNames","numberOfOperationsToQualify","numberOfTransactionsToQualify","numberOfOperationsSeen","currentTransaction","LogColor","chalk","hex","green","yellow","BatchWriter","operationQueue","getFee","getWriterValueTimeLock","numberOfOpsAllowed","getNumberOfOperationsAllowed","currentLock","peek","queuedOperations","lightBlue","all","queuedOperation","operationModels","identifier","stringToWriteToBlockchain","serialize","fee","dequeue","maxNumberOfOpsAllowedByProtocol","maxNumberOfOpsAllowedByLock","min","OperationProcessor","previousOperationTransactionNumber","applyRecoverOperation","applyDeactivateOperation","OperationProcessorUnknownOperationType","OperationProcessorCreateOperationDoesNotHaveRevealValue","revealValueBuffer","JsonCanonicalizer","canonicalizeAsBuffer","isValidHash","canonicalizeAndVerify","resultingDocument","Did","didMethodName","didPrefix","startsWith","DidIncorrectPrefix","indexOfQuestionMarkChar","indexOf","isShortForm","uniqueSuffix","substring","DidNoUniqueSuffix","shortForm","didString","initialState","getInitialStateFromDidString","constructCreateOperationFromInitialState","DidUniqueSuffixFromInitialStateMismatch","methodNameWithNetworkId","didStringUrl","DidInvalidDidString","initialStateValue","methodName","queryParamCounter","searchParams","DidLongFormOnlyOneQueryParamAllowed","initialStateParameterSuffix","DidLongFormOnlyInitialStateParameterIsAllowed","DidLongFormNoInitialStateFound","firstIndexOfDot","DidInitialStateValueContainsNoDot","lastIndexOf","DidInitialStateValueContainsMoreThanOneDot","DidInitialStateValueDoesNotContainTwoParts","initialStateParts","createOperationRequest","createOperationBuffer","RequestHandler","resolver","handleOperationRequest","errorMessage","RequestHandlerDeltaExceedsMaximumSize","contains","QueueingMultipleOperationsPerDidNotAllowed","ResponseStatus","BadRequest","body","handleCreateRequest","response","Succeeded","RequestHandlerUnknownOperationType","enqueue","ServerError","handleResolveRequest","shortOrLongFormDid","resolveLongFormDid","operationWithMockedAnchorTime","VersionMetadata","hashAlgorithmInMultihashCode","AbstractVersionMetadata","VersionManager","config","protocolVersions","protocolVersionsReverseSorted","startingBlockchainTime","batchWriters","operationProcessors","operationQueues","requestHandlers","transactionProcessors","transactionSelectors","versionMetadatas","initialize","loadDefaultExportsForVersion","MongoDbOperationQueue","mongoDbConnectionString","databaseName","requestHandler","CoreErrorCode","VersionManagerVersionMetadataIncorrectType","hashAlgorithmsWithDuplicates","blockchainTime","getVersionString","VersionManagerBatchWriterNotFound","VersionManagerOperationProcessorNotFound","getRequestHandler","VersionManagerRequestHandlerNotFound","VersionManagerTransactionProcessorNotFound","VersionManagerTransactionSelectorNotFound","versionString","getOperationQueue","protocolVersion","VersionManagerVersionStringNotFound","className"],"mappings":"wqEAOA,IAAIA,EAAW,SAAUC,GAGvB,IAAIC,EAAKC,OAAOC,UACZC,EAASH,EAAGI,eAEZC,EAA4B,mBAAXC,OAAwBA,OAAS,GAClDC,EAAiBF,EAAQG,UAAY,aACrCC,EAAsBJ,EAAQK,eAAiB,kBAC/CC,EAAoBN,EAAQO,aAAe,gBAE/C,SAASC,EAAOC,EAAKC,EAAKC,GAOxB,OANAf,OAAOgB,eAAeH,EAAKC,EAAK,CAC9BC,MAAOA,EACPE,YAAY,EACZC,cAAc,EACdC,UAAU,IAELN,EAAIC,GAEb,IAEEF,EAAO,GAAI,IACX,MAAOQ,GACPR,EAAS,SAASC,EAAKC,EAAKC,GAC1B,OAAOF,EAAIC,GAAOC,GAItB,SAASM,EAAKC,EAASC,EAASC,EAAMC,GAEpC,IACIC,EAAY1B,OAAO2B,QADFJ,GAAWA,EAAQtB,qBAAqB2B,EAAYL,EAAUK,GACtC3B,WACzC4B,EAAU,IAAIC,EAAQL,GAAe,IAMzC,OAFAC,EAAUK,QAsMZ,SAA0BT,EAASE,EAAMK,GACvC,IAAIG,EA/KuB,iBAiL3B,OAAO,SAAgBC,EAAQC,GAC7B,GAhLoB,cAgLhBF,EACF,MAAM,IAAIG,MAAM,gCAGlB,GAnLoB,cAmLhBH,EAA6B,CAC/B,GAAe,UAAXC,EACF,MAAMC,EAKR,MAoQG,CAAEnB,WAzfPqB,EAyfyBC,MAAM,GA9P/B,IAHAR,EAAQI,OAASA,EACjBJ,EAAQK,IAAMA,IAED,CACX,IAAII,EAAWT,EAAQS,SACvB,GAAIA,EAAU,CACZ,IAAIC,EAAiBC,EAAoBF,EAAUT,GACnD,GAAIU,EAAgB,CAClB,GAAIA,IAAmBE,EAAkB,SACzC,OAAOF,GAIX,GAAuB,SAAnBV,EAAQI,OAGVJ,EAAQa,KAAOb,EAAQc,MAAQd,EAAQK,SAElC,GAAuB,UAAnBL,EAAQI,OAAoB,CACrC,GAnNqB,mBAmNjBD,EAEF,MADAA,EAjNc,YAkNRH,EAAQK,IAGhBL,EAAQe,kBAAkBf,EAAQK,SAEN,WAAnBL,EAAQI,QACjBJ,EAAQgB,OAAO,SAAUhB,EAAQK,KAGnCF,EA5NkB,YA8NlB,IAAIc,EAASC,EAASzB,EAASE,EAAMK,GACrC,GAAoB,WAAhBiB,EAAOE,KAAmB,CAO5B,GAJAhB,EAAQH,EAAQQ,KAjOA,YAFK,iBAuOjBS,EAAOZ,MAAQO,EACjB,SAGF,MAAO,CACL1B,MAAO+B,EAAOZ,IACdG,KAAMR,EAAQQ,MAGS,UAAhBS,EAAOE,OAChBhB,EA/OgB,YAkPhBH,EAAQI,OAAS,QACjBJ,EAAQK,IAAMY,EAAOZ,OA9QPe,CAAiB3B,EAASE,EAAMK,GAE7CH,EAcT,SAASqB,EAASG,EAAIrC,EAAKqB,GACzB,IACE,MAAO,CAAEc,KAAM,SAAUd,IAAKgB,EAAGC,KAAKtC,EAAKqB,IAC3C,MAAOd,GACP,MAAO,CAAE4B,KAAM,QAASd,IAAKd,IAhBjCtB,EAAQuB,KAAOA,EAoBf,IAOIoB,EAAmB,GAMvB,SAASb,KACT,SAASwB,KACT,SAASC,KAIT,IAAIC,EAAoB,GACxBA,EAAkBhD,GAAkB,WAClC,OAAOiD,MAGT,IAAIC,EAAWxD,OAAOyD,eAClBC,EAA0BF,GAAYA,EAASA,EAASG,EAAO,MAC/DD,GACAA,IAA4B3D,GAC5BG,EAAOiD,KAAKO,EAAyBpD,KAGvCgD,EAAoBI,GAGtB,IAAIE,EAAKP,EAA2BpD,UAClC2B,EAAU3B,UAAYD,OAAO2B,OAAO2B,GAWtC,SAASO,EAAsB5D,GAC7B,CAAC,OAAQ,QAAS,UAAU6D,SAAQ,SAAS7B,GAC3CrB,EAAOX,EAAWgC,GAAQ,SAASC,GACjC,OAAOqB,KAAKxB,QAAQE,EAAQC,SAkClC,SAAS6B,EAAcrC,EAAWsC,GAgChC,IAAIC,EAgCJV,KAAKxB,QA9BL,SAAiBE,EAAQC,GACvB,SAASgC,IACP,OAAO,IAAIF,GAAY,SAASG,EAASC,IAnC7C,SAASC,EAAOpC,EAAQC,EAAKiC,EAASC,GACpC,IAAItB,EAASC,EAASrB,EAAUO,GAASP,EAAWQ,GACpD,GAAoB,UAAhBY,EAAOE,KAEJ,CACL,IAAIsB,EAASxB,EAAOZ,IAChBnB,EAAQuD,EAAOvD,MACnB,OAAIA,GACiB,iBAAVA,GACPb,EAAOiD,KAAKpC,EAAO,WACdiD,EAAYG,QAAQpD,EAAMwD,SAASC,MAAK,SAASzD,GACtDsD,EAAO,OAAQtD,EAAOoD,EAASC,MAC9B,SAAShD,GACViD,EAAO,QAASjD,EAAK+C,EAASC,MAI3BJ,EAAYG,QAAQpD,GAAOyD,MAAK,SAASC,GAI9CH,EAAOvD,MAAQ0D,EACfN,EAAQG,MACP,SAASI,GAGV,OAAOL,EAAO,QAASK,EAAOP,EAASC,MAvBzCA,EAAOtB,EAAOZ,KAiCZmC,CAAOpC,EAAQC,EAAKiC,EAASC,MAIjC,OAAOH,EAaLA,EAAkBA,EAAgBO,KAChCN,EAGAA,GACEA,KAkHV,SAAS1B,EAAoBF,EAAUT,GACrC,IAAII,EAASK,EAAS/B,SAASsB,EAAQI,QACvC,QA1TEG,IA0TEH,EAAsB,CAKxB,GAFAJ,EAAQS,SAAW,KAEI,UAAnBT,EAAQI,OAAoB,CAE9B,GAAIK,EAAS/B,SAAiB,SAG5BsB,EAAQI,OAAS,SACjBJ,EAAQK,SArUZE,EAsUII,EAAoBF,EAAUT,GAEP,UAAnBA,EAAQI,QAGV,OAAOQ,EAIXZ,EAAQI,OAAS,QACjBJ,EAAQK,IAAM,IAAIyC,UAChB,kDAGJ,OAAOlC,EAGT,IAAIK,EAASC,EAASd,EAAQK,EAAS/B,SAAUsB,EAAQK,KAEzD,GAAoB,UAAhBY,EAAOE,KAIT,OAHAnB,EAAQI,OAAS,QACjBJ,EAAQK,IAAMY,EAAOZ,IACrBL,EAAQS,SAAW,KACZG,EAGT,IAAImC,EAAO9B,EAAOZ,IAElB,OAAM0C,EAOFA,EAAKvC,MAGPR,EAAQS,EAASuC,YAAcD,EAAK7D,MAGpCc,EAAQiD,KAAOxC,EAASyC,QAQD,WAAnBlD,EAAQI,SACVJ,EAAQI,OAAS,OACjBJ,EAAQK,SAzXVE,GAmYFP,EAAQS,SAAW,KACZG,GANEmC,GA3BP/C,EAAQI,OAAS,QACjBJ,EAAQK,IAAM,IAAIyC,UAAU,oCAC5B9C,EAAQS,SAAW,KACZG,GAoDX,SAASuC,EAAaC,GACpB,IAAIC,EAAQ,CAAEC,OAAQF,EAAK,IAEvB,KAAKA,IACPC,EAAME,SAAWH,EAAK,IAGpB,KAAKA,IACPC,EAAMG,WAAaJ,EAAK,GACxBC,EAAMI,SAAWL,EAAK,IAGxB1B,KAAKgC,WAAWC,KAAKN,GAGvB,SAASO,EAAcP,GACrB,IAAIpC,EAASoC,EAAMQ,YAAc,GACjC5C,EAAOE,KAAO,gBACPF,EAAOZ,IACdgD,EAAMQ,WAAa5C,EAGrB,SAAShB,EAAQL,GAIf8B,KAAKgC,WAAa,CAAC,CAAEJ,OAAQ,SAC7B1D,EAAYqC,QAAQkB,EAAczB,MAClCA,KAAKoC,OAAM,GA8Bb,SAAShC,EAAOiC,GACd,GAAIA,EAAU,CACZ,IAAIC,EAAiBD,EAAStF,GAC9B,GAAIuF,EACF,OAAOA,EAAe1C,KAAKyC,GAG7B,GAA6B,mBAAlBA,EAASd,KAClB,OAAOc,EAGT,IAAKE,MAAMF,EAASG,QAAS,CAC3B,IAAIC,GAAK,EAAGlB,EAAO,SAASA,IAC1B,OAASkB,EAAIJ,EAASG,QACpB,GAAI7F,EAAOiD,KAAKyC,EAAUI,GAGxB,OAFAlB,EAAK/D,MAAQ6E,EAASI,GACtBlB,EAAKzC,MAAO,EACLyC,EAOX,OAHAA,EAAK/D,WAzeTqB,EA0eI0C,EAAKzC,MAAO,EAELyC,GAGT,OAAOA,EAAKA,KAAOA,GAKvB,MAAO,CAAEA,KAAMmB,GAIjB,SAASA,IACP,MAAO,CAAElF,WAzfPqB,EAyfyBC,MAAM,GA+MnC,OA5mBAe,EAAkBnD,UAAY2D,EAAGsC,YAAc7C,EAC/CA,EAA2B6C,YAAc9C,EACzCA,EAAkB+C,YAAcvF,EAC9ByC,EACA3C,EACA,qBAaFZ,EAAQsG,oBAAsB,SAASC,GACrC,IAAIC,EAAyB,mBAAXD,GAAyBA,EAAOH,YAClD,QAAOI,IACHA,IAASlD,GAG2B,uBAAnCkD,EAAKH,aAAeG,EAAKC,QAIhCzG,EAAQ0G,KAAO,SAASH,GAQtB,OAPIrG,OAAOyG,eACTzG,OAAOyG,eAAeJ,EAAQhD,IAE9BgD,EAAOK,UAAYrD,EACnBzC,EAAOyF,EAAQ3F,EAAmB,sBAEpC2F,EAAOpG,UAAYD,OAAO2B,OAAOiC,GAC1ByC,GAOTvG,EAAQ6G,MAAQ,SAASzE,GACvB,MAAO,CAAEqC,QAASrC,IAsEpB2B,EAAsBE,EAAc9D,WACpC8D,EAAc9D,UAAUO,GAAuB,WAC7C,OAAO+C,MAETzD,EAAQiE,cAAgBA,EAKxBjE,EAAQ8G,MAAQ,SAAStF,EAASC,EAASC,EAAMC,EAAauC,QACxC,IAAhBA,IAAwBA,EAAc6C,SAE1C,IAAIC,EAAO,IAAI/C,EACb1C,EAAKC,EAASC,EAASC,EAAMC,GAC7BuC,GAGF,OAAOlE,EAAQsG,oBAAoB7E,GAC/BuF,EACAA,EAAKhC,OAAON,MAAK,SAASF,GACxB,OAAOA,EAAOjC,KAAOiC,EAAOvD,MAAQ+F,EAAKhC,WAuKjDjB,EAAsBD,GAEtBhD,EAAOgD,EAAIlD,EAAmB,aAO9BkD,EAAGtD,GAAkB,WACnB,OAAOiD,MAGTK,EAAGmD,SAAW,WACZ,MAAO,sBAkCTjH,EAAQkH,KAAO,SAASC,GACtB,IAAID,EAAO,GACX,IAAK,IAAIlG,KAAOmG,EACdD,EAAKxB,KAAK1E,GAMZ,OAJAkG,EAAKE,UAIE,SAASpC,IACd,KAAOkC,EAAKjB,QAAQ,CAClB,IAAIjF,EAAMkG,EAAKG,MACf,GAAIrG,KAAOmG,EAGT,OAFAnC,EAAK/D,MAAQD,EACbgE,EAAKzC,MAAO,EACLyC,EAQX,OADAA,EAAKzC,MAAO,EACLyC,IAsCXhF,EAAQ6D,OAASA,EAMjB7B,EAAQ7B,UAAY,CAClBiG,YAAapE,EAEb6D,MAAO,SAASyB,GAcd,GAbA7D,KAAK8D,KAAO,EACZ9D,KAAKuB,KAAO,EAGZvB,KAAKb,KAAOa,KAAKZ,WApgBjBP,EAqgBAmB,KAAKlB,MAAO,EACZkB,KAAKjB,SAAW,KAEhBiB,KAAKtB,OAAS,OACdsB,KAAKrB,SAzgBLE,EA2gBAmB,KAAKgC,WAAWzB,QAAQ2B,IAEnB2B,EACH,IAAK,IAAIb,KAAQhD,KAEQ,MAAnBgD,EAAKe,OAAO,IACZpH,EAAOiD,KAAKI,KAAMgD,KACjBT,OAAOS,EAAKgB,MAAM,MACrBhE,KAAKgD,QAnhBXnE,IAyhBFoF,KAAM,WACJjE,KAAKlB,MAAO,EAEZ,IACIoF,EADYlE,KAAKgC,WAAW,GACLG,WAC3B,GAAwB,UAApB+B,EAAWzE,KACb,MAAMyE,EAAWvF,IAGnB,OAAOqB,KAAKmE,MAGd9E,kBAAmB,SAAS+E,GAC1B,GAAIpE,KAAKlB,KACP,MAAMsF,EAGR,IAAI9F,EAAU0B,KACd,SAASqE,EAAOC,EAAKC,GAYnB,OAXAhF,EAAOE,KAAO,QACdF,EAAOZ,IAAMyF,EACb9F,EAAQiD,KAAO+C,EAEXC,IAGFjG,EAAQI,OAAS,OACjBJ,EAAQK,SApjBZE,KAujBY0F,EAGZ,IAAK,IAAI9B,EAAIzC,KAAKgC,WAAWQ,OAAS,EAAGC,GAAK,IAAKA,EAAG,CACpD,IAAId,EAAQ3B,KAAKgC,WAAWS,GACxBlD,EAASoC,EAAMQ,WAEnB,GAAqB,SAAjBR,EAAMC,OAIR,OAAOyC,EAAO,OAGhB,GAAI1C,EAAMC,QAAU5B,KAAK8D,KAAM,CAC7B,IAAIU,EAAW7H,EAAOiD,KAAK+B,EAAO,YAC9B8C,EAAa9H,EAAOiD,KAAK+B,EAAO,cAEpC,GAAI6C,GAAYC,EAAY,CAC1B,GAAIzE,KAAK8D,KAAOnC,EAAME,SACpB,OAAOwC,EAAO1C,EAAME,UAAU,GACzB,GAAI7B,KAAK8D,KAAOnC,EAAMG,WAC3B,OAAOuC,EAAO1C,EAAMG,iBAGjB,GAAI0C,GACT,GAAIxE,KAAK8D,KAAOnC,EAAME,SACpB,OAAOwC,EAAO1C,EAAME,UAAU,OAG3B,CAAA,IAAI4C,EAMT,MAAM,IAAI7F,MAAM,0CALhB,GAAIoB,KAAK8D,KAAOnC,EAAMG,WACpB,OAAOuC,EAAO1C,EAAMG,gBAU9BxC,OAAQ,SAASG,EAAMd,GACrB,IAAK,IAAI8D,EAAIzC,KAAKgC,WAAWQ,OAAS,EAAGC,GAAK,IAAKA,EAAG,CACpD,IAAId,EAAQ3B,KAAKgC,WAAWS,GAC5B,GAAId,EAAMC,QAAU5B,KAAK8D,MACrBnH,EAAOiD,KAAK+B,EAAO,eACnB3B,KAAK8D,KAAOnC,EAAMG,WAAY,CAChC,IAAI4C,EAAe/C,EACnB,OAIA+C,IACU,UAATjF,GACS,aAATA,IACDiF,EAAa9C,QAAUjD,GACvBA,GAAO+F,EAAa5C,aAGtB4C,EAAe,MAGjB,IAAInF,EAASmF,EAAeA,EAAavC,WAAa,GAItD,OAHA5C,EAAOE,KAAOA,EACdF,EAAOZ,IAAMA,EAET+F,GACF1E,KAAKtB,OAAS,OACdsB,KAAKuB,KAAOmD,EAAa5C,WAClB5C,GAGFc,KAAK2E,SAASpF,IAGvBoF,SAAU,SAASpF,EAAQwC,GACzB,GAAoB,UAAhBxC,EAAOE,KACT,MAAMF,EAAOZ,IAcf,MAXoB,UAAhBY,EAAOE,MACS,aAAhBF,EAAOE,KACTO,KAAKuB,KAAOhC,EAAOZ,IACM,WAAhBY,EAAOE,MAChBO,KAAKmE,KAAOnE,KAAKrB,IAAMY,EAAOZ,IAC9BqB,KAAKtB,OAAS,SACdsB,KAAKuB,KAAO,OACa,WAAhBhC,EAAOE,MAAqBsC,IACrC/B,KAAKuB,KAAOQ,GAGP7C,GAGT0F,OAAQ,SAAS9C,GACf,IAAK,IAAIW,EAAIzC,KAAKgC,WAAWQ,OAAS,EAAGC,GAAK,IAAKA,EAAG,CACpD,IAAId,EAAQ3B,KAAKgC,WAAWS,GAC5B,GAAId,EAAMG,aAAeA,EAGvB,OAFA9B,KAAK2E,SAAShD,EAAMQ,WAAYR,EAAMI,UACtCG,EAAcP,GACPzC,IAKb2F,MAAS,SAASjD,GAChB,IAAK,IAAIa,EAAIzC,KAAKgC,WAAWQ,OAAS,EAAGC,GAAK,IAAKA,EAAG,CACpD,IAAId,EAAQ3B,KAAKgC,WAAWS,GAC5B,GAAId,EAAMC,SAAWA,EAAQ,CAC3B,IAAIrC,EAASoC,EAAMQ,WACnB,GAAoB,UAAhB5C,EAAOE,KAAkB,CAC3B,IAAIqF,EAASvF,EAAOZ,IACpBuD,EAAcP,GAEhB,OAAOmD,GAMX,MAAM,IAAIlG,MAAM,0BAGlBmG,cAAe,SAAS1C,EAAUf,EAAYE,GAa5C,OAZAxB,KAAKjB,SAAW,CACd/B,SAAUoD,EAAOiC,GACjBf,WAAYA,EACZE,QAASA,GAGS,SAAhBxB,KAAKtB,SAGPsB,KAAKrB,SA7rBPE,GAgsBOK,IAQJ3C,GAOsByI,EAAOzI,SAGtC,IACE0I,mBAAqB3I,EACrB,MAAO4I,GAUPC,SAAS,IAAK,yBAAdA,CAAwC7I,gCCptBrB8I,oCAILC,cAAP,SAAwBC,WACvBC,EAAe,IAAIC,IAEhB/C,EAAI,EAAGA,EAAI6C,EAAM9C,OAAQC,IAAK,KAC/BjF,EAAQ8H,EAAM7C,MAChB8C,EAAaE,IAAIjI,UACZ,EAET+H,EAAaG,IAAIlI,UAGZ,KAMKmI,qBAAP,SACLC,EACAC,aAEMC,EAAiB,IAAIN,IAAOI,OAEdC,qBACdC,EAAeL,oBACV,SAIJ,QCpCLM,EAAOC,QAAQ,QAKAC,oCAKCC,oCAAb,WAAsBC,+EACrBpF,EAASgF,EAAKK,QAAQC,OAAOC,KAAKH,sBACjCE,OAAOC,KAAKvF,uGAODwF,sCAAb,WAAwBJ,+EACvBpF,EAASgF,EAAKS,QAAQL,qBACrBE,OAAOC,KAAKvF,0GCPF0F,oCAILC,4BAAP,SACLC,EACAC,WAG4C/H,IAAxC8H,EAASE,iCACJ,CAAEC,OAAQ,mBAGbC,EAAWJ,EAASI,SAEpBC,EAAeJ,EAAIK,MAAM,KAAK,GAI9BC,EAAwB,GACxBC,EAAyB,GACzBC,EAA8B,GAC9BC,EAA8B,GAC9BC,EAAsB,GAEtBC,EAAqB,MACvBC,MAAMC,QAAQV,EAASQ,2BACDR,EAASQ,4BAAa,KAAnCG,UACHC,EAAK,IAAMD,EAAUC,GACrBC,EAAuB,CAC3BD,GAAIA,EACJE,WAAYb,EACZvH,KAAMiI,EAAUjI,KAChBqI,aAAcJ,EAAUK,KAEpBC,EAA0B,IAAIxC,IAAIkC,EAAUO,SAE9CD,EAAWvC,IAAIyC,mBAAiBC,UAClCZ,EAAYtF,KAAK2F,GAEbI,EAAWvC,IAAIyC,mBAAiBE,OAClClB,EAAejF,KAAK0F,GAElBK,EAAWvC,IAAIyC,mBAAiBG,kBAClClB,EAAgBlF,KAAK0F,GAEnBK,EAAWvC,IAAIyC,mBAAiBI,uBAClClB,EAAqBnF,KAAK0F,GAExBK,EAAWvC,IAAIyC,mBAAiBK,uBAClClB,EAAqBpF,KAAK0F,GAExBK,EAAWvC,IAAIyC,mBAAiBM,eAClClB,EAAarF,KAAK0F,IAEXK,EAAWvC,IAAIyC,mBAAiBE,MACzClB,EAAejF,KAAK2F,GACXI,EAAWvC,IAAIyC,mBAAiBG,iBACzClB,EAAgBlF,KAAKkF,GACZa,EAAWvC,IAAIyC,mBAAiBI,sBACzClB,EAAqBnF,KAAK2F,GACjBI,EAAWvC,IAAIyC,mBAAiBK,sBACzClB,EAAqBpF,KAAK2F,GACjBI,EAAWvC,IAAIyC,mBAAiBM,eACzClB,EAAarF,KAAK2F,OAMlBa,EAAoB,MACtBjB,MAAMC,QAAQV,EAAS0B,iCACK1B,EAAS0B,kCAAmB,KAA/CC,UAMTD,EAAkBxG,KALiB,CACjC0F,GAAI,IAAMe,EAAgBf,GAC1BlI,KAAMiJ,EAAgBjJ,KACtBiJ,gBAAiBA,EAAgBC,eAMjCC,EAAmB,CACvBjB,GAAIX,aACQ,CACV,+BACA,iCACA,SAAWA,YAIY,IAAvBO,EAAY/E,SACdoG,EAAYlB,UAAYH,GAGI,IAA1BL,EAAe1E,SACjBoG,EAAY1B,eAAiBA,GAGA,IAA3BC,EAAgB3E,SAClBoG,EAAYzB,gBAAkBA,GAGI,IAAhCC,EAAqB5E,SACvBoG,EAAYxB,qBAAuBA,GAGD,IAAhCC,EAAqB7E,SACvBoG,EAAYvB,qBAAuBA,GAGT,IAAxBC,EAAa9E,SACfoG,EAAYtB,aAAeA,GAGI,IAA7BmB,EAAkBjG,SACpBoG,EAAYC,QAAUJ,GAYjBK,KAAKC,MAAMD,KAAKE,UATU,YACnB,qCACZJ,YAAaA,EACbK,oBAAqB,CACnBC,mBAAoBvC,EAASE,2BAC7BsC,iBAAkBxC,EAASyC,gCAYbC,gDAAb,WACLC,EACAvC,+EAEMwC,EAAoB9C,EAAiB+C,aACzCzC,EACAuC,EAAUG,MAAOC,2BAGZH,wGAOMI,iBAAP,SAAwB5C,WACblI,IAAbkI,QACI,IAAI6C,gBAAcC,YAAUC,qCAG9BC,EAAoB,IAAIvE,IAAI,CAAC,cAAe,0BAC7C,IAAMwE,KAAYjD,MAChBgD,EAAkBtE,IAAIuE,SACnB,IAAIJ,gBACRC,YAAUI,iEACaD,mBAMzBvN,OAAOC,UAAUE,eAAegD,KAAKmH,EAAU,gBACjDN,EAAiByD,mBAAmBnD,EAASQ,aAI3C9K,OAAOC,UAAUE,eAAegD,KAAKmH,EAAU,sBAEjDN,EAAiB0D,yBAAyBpD,EAAS0B,sBAQzC2B,wBAAP,SAA+BV,OAC/BlC,MAAMC,QAAQiC,SACX,IAAIE,gBACRC,YAAUQ,sEAIMX,kBAClBjD,EAAiB6D,0BAINA,cAAP,SAAqBC,UACZA,EAAMC,YAEd,UACH/D,EAAiBkD,iBAAiBY,EAAMxD,oBAErC,kBACHN,EAAiBgE,2BAA2BF,aAEzC,qBACH9D,EAAiBiE,8BAA8BH,aAE5C,wBACH9D,EAAiBkE,iCAAiCJ,aAE/C,2BACH9D,EAAiBmE,oCAAoCL,aAElD,kBACH9D,EAAiBoE,sBAAsBN,uBAGjC,IAAIX,gBACRC,YAAUiB,iDAKHD,sBAAP,SAA6BN,MAEJ,IADP9N,OAAOgH,KAAK8G,GAChB/H,aACZ,IAAIoH,gBACRC,YAAUkB,mDAGR5J,EAAQ6J,EAAUC,SAASV,EAAMb,YACnCvI,QACF+J,QAAQC,KAAKhK,GACP,IAAIyI,gBAAczI,EAAM6B,SAInByH,2BAAP,SAAkCF,MAET,IADP9N,OAAOgH,KAAK8G,GAChB/H,aACZ,IAAIoH,gBACRC,YAAUkB,+CAIdtE,EAAiByD,mBAAmBK,EAAMhD,gBAG7B2C,mBAAP,SAA0B3C,OAC3BC,MAAMC,QAAQF,SACX,IAAIqC,gBAAcC,YAAUuB,8CAG9BC,EAA8B,IAAI7F,QAChB+B,kBAAa,KAA1BG,aAG0B,IAFPjL,OAAOgH,KAAKiE,GAEhBlF,aAChB,IAAIoH,gBACRC,YAAUyB,sDAIe,iBAAlB5D,EAAUK,KAAoBP,MAAMC,QAAQC,EAAUK,WACzD,IAAI6B,gBACRC,YAAU0B,uDAIgB,iBAAnB7D,EAAUjI,WACb,IAAImK,gBACRC,YAAU2B,wDAId/E,EAAiBgF,WAAW/D,EAAUC,IAGlC0D,EAAe5F,IAAIiC,EAAUC,UACzB,IAAIiC,gBACRC,YAAU6B,0CAGdL,EAAe3F,IAAIgC,EAAUC,KAExBH,MAAMC,QAAQC,EAAUO,UAAyC,IAA7BP,EAAUO,QAAQzF,aACnD,IAAIoH,gBACRC,YAAU8B,qDAIVjE,EAAUO,QAAQzF,OAAS/F,OAAO2D,OAAO8H,oBAAkB1F,aACvD,IAAIoH,gBACRC,YAAU+B,4DAIRC,EAAgB,IAAIrG,IAAI/I,OAAO2D,OAAO8H,yBAEtBR,EAAUO,4BACzB4D,EAAcpG,mBACX,IAAImE,gBACRC,YAAUiC,6CAOLpB,8BAAP,SAAqCH,MAEZ,IADP9N,OAAOgH,KAAK8G,GAChB/H,aACZ,IAAIoH,gBACRC,YAAUkB,mDAITvD,MAAMC,QAAQ8C,EAAMhD,mBACjB,IAAIqC,gBACRC,YAAUkC,yDAIYxB,EAAMhD,+BACH,+BACnB,IAAIqC,gBACRC,YAAUmC,8CASHpB,oCAAP,SAA2CL,MAElB,IADP9N,OAAOgH,KAAK8G,GAChB/H,aACZ,IAAIoH,gBACRC,YAAUkB,mDAITvD,MAAMC,QAAQ8C,EAAM0B,WACjB,IAAIrC,gBACRC,YAAUqC,+DAIG3B,EAAM0B,oBACrBxF,EAAiBgF,uBAONd,iCAAP,SAAwCJ,MAEf,IADP9N,OAAOgH,KAAK8G,GAChB/H,aACZ,IAAIoH,gBACRC,YAAUkB,mDAITvD,MAAMC,QAAQ8C,EAAM9B,yBACjB,IAAImB,gBACRC,YAAUsC,+CAId1F,EAAiB0D,yBAAyBI,EAAM9B,sBAOnC0B,yBAAP,SAAgC1B,OACjCjB,MAAMC,QAAQgB,SACX,IAAImB,gBACRC,YAAUsC,6DAIgB1D,kBAAmB,KAAtCC,aAEgC,IADPjM,OAAOgH,KAAKiF,GAChBlG,aAEtB,IAAIoH,gBACRC,YAAUuC,4DAId3F,EAAiBgF,WAAW/C,EAAgBf,IAER,iBAAzBe,EAAgBjJ,WACnB,IAAImK,gBACRC,YAAUwC,sDAGV3D,EAAgBjJ,KAAK+C,OAAS,SAC1B,IAAIoH,gBACRC,YAAUyC,oDAG0B,iBAA7B5D,EAAgBC,eACnB,IAAIiB,gBACRC,YAAU0C,iEAGV7D,EAAgBC,SAASnG,OAAS,UAC9B,IAAIoH,gBACRC,YAAU2C,oEAORC,IAAI/D,EAAgBC,UACxB,eACM,IAAIiB,gBACRC,YAAU6C,qEAMHjB,WAAP,SAAkB9D,MACN,iBAAPA,QACH,IAAIiC,gBACRC,YAAU8C,8CACQ7D,KAAKE,UAAUrB,0BAA0BA,UAG3DA,EAAGnF,OAAS,SACR,IAAIoH,gBAAcC,YAAU+C,+BAG/BC,UAAQC,kBAAkBnF,SACvB,IAAIiC,gBACRC,YAAUkD,oDAUFvD,aAAP,SAAoBzC,EAAe2C,aAEpCH,EAAoBxC,MACJ2C,kBAClBH,EAAoB9C,EAAiBuG,wBACnCzD,kBAKGA,KAMMyD,wBAAP,SACNjG,EACAwD,SAEqB,YAAjBA,EAAMC,OACDD,EAAMxD,SACa,oBAAjBwD,EAAMC,OACR/D,EAAiBwG,cAAclG,EAAUwD,GACtB,uBAAjBA,EAAMC,OACR/D,EAAiByG,iBAAiBnG,EAAUwD,GACzB,0BAAjBA,EAAMC,OACR/D,EAAiB0G,oBAAoBpG,EAAUwD,GAC5B,6BAAjBA,EAAMC,OACR/D,EAAiB2G,uBAAuBrG,EAAUwD,GAC/B,oBAAjBA,EAAMC,OACR/D,EAAiB4G,mBAAmBtG,EAAUwD,QADhD,KAKM8C,mBAAP,SAA0BtG,EAAewD,UACnCS,EAAUsC,gBAAgBvG,GAAYwD,EAAMb,SAC7C6D,eAMEN,cAAP,SACNlG,EACAwD,aAEMiD,EAAe,IAAIC,KACtB1G,EAASQ,aAAe,IAAImG,KAAI,SAAChG,SAAc,CAACA,EAAUC,GAAID,WAIzC6C,EAAMhD,4BAAa,KAAhCG,UAGT8F,EAAaG,IAAIjG,EAAUC,GAAID,UAGjCX,EAASQ,YAAcC,MAAMlB,KAAKkH,EAAaI,WAAWF,KACxD,SAACG,UAAaA,EAAI,MAGb9G,KAMMmG,iBAAP,SACNnG,EACAwD,aAEMiD,EAAe,IAAIC,KACtB1G,EAASQ,aAAe,IAAImG,KAAI,SAAChG,SAAc,CAACA,EAAUC,GAAID,WAIzC6C,EAAMhD,4BAAa,KAAhCG,eAGW7I,IAFA2O,EAAaM,IAAIpG,IAGnC8F,SAAoB9F,UAMxBX,EAASQ,YAAcC,MAAMlB,KAAKkH,EAAaI,WAAWF,KACxD,SAACG,UAAaA,EAAI,MAGb9G,KAGMoG,oBAAP,SACNpG,EACAwD,OAEM9B,EAAoB8B,EAAM9B,uBAEG5J,IAA/BkI,EAAS0B,oBAEX1B,EAAS0B,kBAAoB,QAGzBsF,EAAkB,IAAIN,QAEvB,IAAMO,KAAOjH,EAAS0B,kBACzBsF,EAAgBJ,IAAI5G,EAAS0B,kBAAkBuF,GAAKrG,GAAIqG,iBAG5BvF,kBAAmB,KAAtCC,aACLqF,EAAgBtI,IAAIiD,EAAgBf,IAAK,KACrCqG,EAAMD,EAAgBD,IAAIpF,EAAgBf,IAChDZ,EAAS0B,kBAAkBuF,GAAOtF,OAElC3B,EAAS0B,kBAAkBxG,KAAKyG,UAI7B3B,KAGMqG,uBAAP,SACNrG,EACAwD,WAEmC1L,IAA/BkI,EAAS0B,yBACJ1B,MAGHkH,EAAc,IAAIzI,IAAI+E,EAAM0B,YAClClF,EAAS0B,kBAAoB1B,EAAS0B,kBAAkByF,QACtD,SAACxF,UAAqBuF,EAAYxI,IAAIiD,EAAgBf,OAGjDZ,QC1lBLoH,EAAgBnI,QAAQ,kBAKToI,oCAKCrF,iCAAb,WAAmBsF,+EAElBC,EAAmB,IAAIhL,SAAQ,SAAC1C,EAASC,GAC7CsN,EAAcI,WAAWF,GAAU,SAACxQ,EAAU2Q,GACxC3Q,EACFgD,EAAOhD,GAEP+C,EAAQ4N,kBAMOF,gJCVJG,oCAICC,sCAAb,WAAwBC,+EACK,iBAAvBA,wBACH,IAAI/E,gBAAcC,YAAU+E,uCAG9BC,EAAkBhC,UAAQiC,eAAeH,YAC3BP,EAAUrF,MAAM8F,aAA9BpF,SAGoB,IADPhN,OAAOgH,KAAKgG,GAChBjH,6BACP,IAAIoH,gBAAcC,YAAUkF,8CAGdlQ,IAAlB4K,EAAMC,+BACF,IAAIE,gBAAcC,YAAUmF,gDAIpCvI,EAAiB2D,wBAAwBX,EAAMC,SAEzCuF,EAAuBpC,UAAQqC,eACnCzF,EAAM0F,mBAERC,YAAUC,gDACRJ,qBAGK,CACLvF,QAASD,EAAMC,QACfyF,kBAAmB1F,EAAM0F,2HC1BVG,wBA0BjBC,EACAC,EACAC,EACAC,EACAC,EACAlG,QAEK+F,gBAAkBA,OAClB/P,KAAOmQ,gBAAcC,YACrBN,gBAAkBA,OAClBE,kBAAoBA,OACpBC,WAAaA,OACbC,aAAeA,OACflG,MAAQA,WAMAqG,uBAAP,SAA8BL,OAC9BM,EAAmBlD,UAAQqC,eAAeO,GAC1CO,EAAYZ,YAAUa,KAAKF,UACRlD,UAAQqD,OAAOF,MAOtBG,wDAAb,WACLC,+EAGMb,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAUoH,aAC3Bd,EAAgBe,YACtCD,EACAb,GACA,8IAQgBxG,iCAAb,WAAmBwG,iFAClBe,EAAsBf,EAAgB/L,oBACd4K,EAAUrF,MAAMuH,iBAAxCC,kBACwBjB,EAAgBe,YAC5CE,EACAhB,GACA,8IAYgBc,uCAAb,WACLE,EACAhB,EACAiB,qFAEIC,EAAwB,EACxBD,IACFC,EAAwB,GAGPhU,OAAOgH,KAAK8M,GAChB/N,SAAWiO,wBAClB,IAAI7G,gBACRC,YAAU6G,uDAIRjB,EAAoBc,EAAgBI,qBACjBrB,EAAgBsB,gBAAgBnB,aAAnDC,SAGFC,OAAe9Q,EACf4K,OAAQ5K,EACP2R,sBACCD,EAAgB9Q,OAASmQ,gBAAcC,8BACnC,IAAIjG,gBAAcC,YAAUgH,6CAGpClB,EAAeY,EAAgB9G,0BAEfgF,EAAeC,WAAW6B,EAAgB9G,eAAxDA,2EAQE+F,EAAkBF,EAAgBQ,uBACtCS,EAAgBI,+BAEX,IAAIrB,EACTC,EACAC,EACAC,EACAC,EACAC,EACAlG,2HAIiBmH,2CAAb,WACNE,iFAEuC,iBAA5BA,wBACH,IAAIlH,gBACRC,YAAUkH,2DAIRC,EAAuBnE,UAAQiC,eACnCgC,YAEuB1C,EAAUrF,MAAMiI,aAAnCtB,SAGoB,IADPjT,OAAOgH,KAAKiM,GAChBlN,6BACP,IAAIoH,gBACRC,YAAUoH,iEAIRC,EAAarE,UAAQqC,eAAeQ,EAAWwB,YAC/CC,EAAyBtE,UAAQqC,eACrCQ,EAAW0B,qBAGbhC,YAAUC,gDAAgD6B,GAC1D9B,YAAUC,gDACR8B,qBAGK,CACLD,WAAYxB,EAAWwB,WACvBE,oBAAqB1B,EAAW0B,6HC9KjBC,oCAMCC,kDAAb,sGAGiBC,MAAIC,SAAS,MAAO,yBACpCC,GADAC,UACqBC,OAAM,GAC3BjK,EAAYgK,EAAQC,OAAM,qBACzB,CAACjK,EAAW+J,sGAIDG,4CAAb,WACLC,EACAC,0FAEmBC,iBAAqBF,iBAClCG,EAAOC,EAAMC,uBAGbC,EAAWH,EAAKI,yBADWN,qBAE1BK,EAASV,iHAGGY,8DAAb,WACNR,EACAC,4FAE+BT,EAAIO,iBAAiBC,EAAUC,iBAAxDQ,kBACgBC,iBAAef,SAAS,CAC5CgB,KAAMF,kBAEFG,EAAiB,IAAIF,kCACCE,EAAeC,OACzC,iBADI5K,mBAGuB2K,EAAeC,OAC1C,oCAEK,CAAC5K,iHAQU6K,oDAAb,sGAGiBpB,MAAIC,SAAS,KAAM,2BACnC9J,GADAgK,UACoBC,OAAM,GAC1BF,EAAaC,EAAQC,OAAM,qBAC1B,CAACjK,EAAW+J,sGAGDmB,0DAAb,WACLC,EACAhB,EACAC,uEAEQe,SACD,qBAEA,2DADI7S,KAAK8S,qCAAqCjB,EAAUC,oCAEpD9R,KAAKqS,mCAAmCR,EAAUC,iBAEnD,IAAIlT,MAAM,gIAIDkU,gEAAb,WACNjB,EACAC,4FAE+BT,EAAIO,iBAAiBC,EAAUC,iBACxDhK,EAAeiL,OADfT,SAC2C,OAAOI,MAAM,WACjDM,IAAM,aACbC,EAAgBF,OAAUT,EAAkB,OAAOI,MAAM,YACjDM,IAAM,8BACb,CAAClL,EAAcmL,yGAOVC,kBAAP,SAAyBnL,WAClBlJ,IAARkJ,QACI,IAAI6B,gBAAcC,YAAUsJ,kBAI9BpJ,EAAoB,IAAIvE,IAAI,CAAC,MAAO,MAAO,IAAK,IAAK,YACtD,IAAMwE,KAAYjC,MAChBgC,EAAkBtE,IAAIuE,SACnB,IAAIJ,gBAAcC,YAAUuJ,8BAI9BrL,EAAIiL,SACL,aACa,QAAZjL,EAAIsL,UACA,IAAIzJ,gBAAcC,YAAUyJ,2BAEf,iBAAVvL,EAAIwL,QACP,IAAI3J,gBAAcC,YAAU2J,oCAGjC,eACa,OAAZzL,EAAIsL,UACA,IAAIzJ,gBAAcC,YAAUyJ,2BAEf,iBAAVvL,EAAIwL,QACP,IAAI3J,gBAAcC,YAAU2J,6BAEf,iBAAVzL,EAAI0L,QACP,IAAI7J,gBAAcC,YAAU6J,8CAI9B,IAAI9J,gBAAcC,YAAU8J,4BAQ1BC,uBAAP,SACLnC,OAEMoC,EAAUpX,OAAOqX,OAAO,GAAIrC,iBAG3BoC,EAAQE,EAERF,QCnJUG,wBAYCC,MACQ,iBAAfA,QACH,IAAIrK,gBAAcC,YAAUqK,4BAG9BC,EAAQF,EAAWhN,MAAM,QACV,IAAjBkN,EAAM3R,aACF,IAAIoH,gBAAcC,YAAUuK,0BAG9BC,EAAkBF,EAAM,GACxBG,EAAUH,EAAM,GAChBI,EAAYJ,EAAM,GAElBK,EAAiC3H,UAAQ4H,wBAC7CJ,GAEIK,EAAyB5L,KAAKC,MAAMyL,MAEN,IAEX/X,OAAOgH,KAAKiR,GAChBlS,aACb,IAAIoH,gBACRC,YAAU8K,+CAMmB,UAA/BD,EAAuBE,KACQ,WAA/BF,EAAuBE,UAEjB,IAAIhL,gBACRC,YAAUgL,6CAKThI,UAAQC,kBAAkByH,SACvB,IAAI3K,gBAAcC,YAAUiL,oCAI/BjI,UAAQC,kBAAkBwH,SACvB,IAAI1K,gBAAcC,YAAUkL,6CAGnBV,OACZC,QAAUA,OACVC,UAAYA,6BAMZS,aAAA,kBACEhB,EAAIiB,iBAAiBjV,eAAgBA,KAAKsU,QAAStU,KAAKuU,cAOpDW,2CAAN,WAAsBxN,2FACpBsM,EAAIkB,gBACTlV,eACAA,KAAKsU,QACLtU,KAAKuU,UACL7M,4GAQgBwN,2CAAb,WACLC,EACAC,EACAb,EACA7M,+EAEM2N,EACJF,EAAyB,IAAMC,EAAiB,IAAMb,WAC3BP,EAAIsB,iBAC/BD,EACA3N,oJASgB4N,4CAAb,WACLrB,EACAlM,8EAGkB,YAAZA,EAAIiL,oCACAuC,QAAMC,OAAOvB,EAAYlM,oCACV,cAAZA,EAAIiL,qCACPyC,SAAOD,OAAOvB,EAAYlM,4DAEzB,qCAEF,4CAEPmD,QAAQwK,cACIzB,sCAA8CrK,gBAAc+L,gBACpE9L,YAAU+L,uDAIP,uHAQSC,4CAAb,WACLvB,EACA7C,EACA4C,2EAYMyB,OACDzB,GACHO,IAXEP,GAAmBA,EAAgBO,IAC/BP,EAAgBO,IAEC,YAAnBnD,EAAWuB,IACP,QAEA,WAOa,cAAnBvB,EAAWuB,oCACAyC,SAAOM,KAAKzB,EAAS7C,EAAmBqE,kEAE1CP,QAAMQ,KAAKzB,EAAS7C,EAAYqE,kJAMjCE,gBAAP,SAAuB/B,UACrB,IAAID,EAAIC,MAMHgB,iBAAP,SACLZ,EACAC,EACAC,UAEOF,EAAkB,IAAMC,EAAU,IAAMC,QCzK9B0B,wBAoBjB1G,EACAC,EACA0G,EACAC,QAEK5G,gBAAkBA,OAClB9P,KAAOmQ,gBAAcwG,gBACrB5G,gBAAkBA,OAClB0G,cAAgBA,OAChBC,WAAaA,WAMAhG,wDAAb,WACLC,+EAEMb,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAUoH,aAC3B6F,EAAoB5F,YAC1CD,EACAb,GACA,8IAQgBxG,iCAAb,WACLwG,iFAEMe,EAAsBf,EAAgB/L,oBACd4K,EAAUrF,MAAMuH,iBAAxCC,kBAC4B0F,EAAoB5F,YACpDE,EACAhB,GACA,8IAYgBc,uCAAb,WACLE,EACAhB,EACAiB,+EAEIC,EAAwB,EACxBD,IACFC,EAAwB,GAGPhU,OAAOgH,KAAK8M,GAChB/N,SAAWiO,wBAClB,IAAI7G,gBACRC,YAAUwM,uDAI4B,iBAA/B9F,EAAgB+F,iCACnB,IAAI1M,gBACRC,YAAU0M,kEAIRL,EAAgBlC,EAAIgC,gBAAgBzF,EAAgBiG,uBACjCP,EAAoBQ,uBAC3CP,EAAc5B,QACd/D,EAAgB+F,uBAFZH,SAMD3F,sBACCD,EAAgB9Q,OAASmQ,gBAAcwG,kCACnC,IAAIxM,gBAAcC,YAAU6M,mEAI/B,IAAIT,EACT1G,EACAgB,EAAgB+F,WAChBJ,EACAC,4GAIiBM,kDAAb,WACN9H,EACAgI,iFAEMC,EAAuB/J,UAAQiC,eAAeH,YAC3BP,EAAUrF,MAAM6N,aAAnCT,SAGoB,IADP1Z,OAAOgH,KAAK0S,GAChB3T,6BACP,IAAIoH,gBACRC,YAAUgN,iEAIVV,EAAWG,aAAeK,wBACtB,IAAI/M,gBACRC,YAAUiN,gEAIdzF,EAAI6B,kBAAkBiD,EAAWY,gCAE1B,CACLC,UAAWb,EAAWG,WACtBS,aAAcZ,EAAWY,wHCtIVE,wBA0BjB1H,EACAC,EACA0G,EACAC,EACAxG,EACAlG,QAEK8F,gBAAkBA,OAClB9P,KAAOmQ,gBAAcsH,aACrB1H,gBAAkBA,OAClB0G,cAAgBA,OAChBC,WAAaA,OACbxG,aAAeA,OACflG,MAAQA,WAMK0G,wDAAb,WACLC,+EAEMb,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAUoH,aAC3B6G,EAAiB5G,YACvCD,EACAb,GACA,8IAQgBxG,iCAAb,WACLwG,iFAEMe,EAAsBf,EAAgB/L,oBACd4K,EAAUrF,MAAMuH,iBAAxCC,kBACyB0G,EAAiB5G,YAC9CE,EACAhB,GACA,8IAYgBc,uCAAb,WACLE,EACAhB,EACAiB,mFAEIC,EAAwB,EACxBD,IACFC,EAAwB,GAGPhU,OAAOgH,KAAK8M,GAChB/N,SAAWiO,wBAClB,IAAI7G,gBACRC,YAAUsN,oDAI4B,iBAA/B5G,EAAgB+F,iCACnB,IAAI1M,gBACRC,YAAUuN,+DAIRlB,EAAgBlC,EAAIgC,gBAAgBzF,EAAgBiG,uBACjCS,EAAiBR,uBACxCP,EAAc5B,oBADV6B,SAKFxG,OAAe9Q,EACf4K,OAAQ5K,EACP2R,sBACCD,EAAgB9Q,OAASmQ,gBAAcsH,+BACnC,IAAItN,gBAAcC,YAAUwN,8CAGpC1H,EAAeY,EAAgB9G,0BAEfgF,EAAeC,WAAW6B,EAAgB9G,eAAxDA,6FAQG,IAAIwN,EACT1H,EACAgB,EAAgB+F,WAChBJ,EACAC,EACAxG,EACAlG,2HAIiBgN,kDAAb,WACNa,qFAEMV,EAAuB/J,UAAQiC,eACnCwI,YAEuBlJ,EAAUrF,MAAM6N,aAAnCT,SAKoB,IAHP1Z,OAAOgH,KAAK0S,GAGhB3T,6BACP,IAAIoH,gBACRC,YAAU0N,kEAIdlG,EAAI6B,kBAAkBiD,EAAWY,cAE3B7F,EAAarE,UAAQqC,eAAeiH,EAAWjF,YACrD9B,YAAUC,gDAAgD6B,GAEpDrK,EAA6BgG,UAAQqC,eACzCiH,EAAW/E,qBAEbhC,YAAUC,gDACRxI,qBAGK,CACLqK,WAAYiF,EAAWjF,WACvB6F,aAAcZ,EAAWY,aACzB3F,oBAAqB+E,EAAW/E,6HCrLjBoG,wBAODC,EACAC,EACAC,EACAC,EACAC,cAJAJ,yBACAC,wBACAC,yBACAC,4BACAC,WAOE9O,iCAAb,WAAmB+O,6IAGe7R,EAAWM,WAC9CuR,UADFC,8DAIMnO,gBAAc+L,gBAClB9L,YAAUmO,sEAOY5J,EAAUrF,MAAMgP,WAAxCE,iEAEMrO,gBAAc+L,gBAAgB9L,YAAUqO,gCAG1CnO,EAAoB,IAAIvE,IAAI,CAChC,eACA,aACA,+BAEqByS,qDAChBlO,EAAkBtE,uCACf,IAAImE,gBAAcC,YAAUsO,iEAKnC1b,OAAOC,UAAUE,eAAegD,KAAKqY,EAAiB,uCAEjD,IAAIrO,gBAAcC,YAAUuO,yCAG/B3b,OAAOC,UAAUE,eAAegD,KAAKqY,EAAiB,qCACnD,IAAIrO,gBAAcC,YAAUwO,iDAIlC5b,OAAOC,UAAUE,eAAegD,KAAKqY,EAAiB,mBACZ,iBAAnCA,EAAgBK,sCAEjB,IAAI1O,gBAAcC,YAAU0O,mDAKV,iBADPN,EAAgBO,oCAE3B,IAAI5O,gBAAcC,YAAU4O,wCAG9BC,EAA8B,IAAIlT,IAAI,CAC1C,SACA,UACA,2BAEImT,EAAaV,EAAgBU,8DAE5BD,EAA4BjT,IADxBuE,qCAED,IAAIJ,gBACRC,YAAU+O,gEACa5O,kFAMvB0N,EAA8B,GAG9BC,EAAsC,QAClB9Y,IAAtB8Z,EAAWva,2BACRoJ,MAAMC,QAAQkR,EAAWva,+BACtB,IAAIwL,gBAAcC,YAAUgP,8CAIZF,EAAWva,wDAAxBkL,oBACqBgG,EAAgBa,6BAC5C7G,WAEFqO,EAAiB1V,KAHX6W,UAINpB,EAAkBzV,KAAK6W,EAAgBtJ,oDAKrCoI,EAAwC,QACnB/Y,IAAvB8Z,EAAWI,4BACRvR,MAAMC,QAAQkR,EAAWI,gCACtB,IAAInP,gBAAcC,YAAUmP,+CAIZL,EAAWI,yDAAxBzP,oBACsB2N,EAAiB9G,6BAC9C7G,WAEFsO,EAAkB3V,KAHZgX,UAINvB,EAAkBzV,KAAKgX,EAAiBzJ,oDAKtCqI,EAA8C,QACtBhZ,IAA1B8Z,EAAWO,+BACR1R,MAAMC,QAAQkR,EAAWO,mCACtB,IAAItP,gBAAcC,YAAUsP,kDAIZR,EAAWO,4DAAxB5P,oBACyB2M,EAAoB9F,6BACpD7G,WAEFuO,EAAqB5V,KAHfmX,UAIN1B,EAAkBzV,KAAKmX,EAAoB5J,qDAI3CpK,EAAaC,cAAcqS,0BACvB,IAAI9N,gBACRC,YAAUwP,0DAIRC,EAAa,IAAI9B,EACrBS,EACAP,EACAC,EACAC,EACAC,qBAEKyB,2HAMWC,uCAAb,WACLC,EACAC,EACAC,EACAC,EACAC,mFAEMjC,EAAmB+B,EAAqBhM,KAAI,SAACpE,SAC1C,CACLqH,YAAarH,EAAUmG,sBAIrBmI,EAAoB+B,EAAsBjM,KAAI,SAACpE,SAC5C,CACLgN,WAAYhN,EAAUkG,gBACtBgH,YAAalN,EAAU4M,cAAclB,mBAInC6C,EAAuB+B,EAAyBlM,KAAI,SAACpE,SAClD,CACLgN,WAAYhN,EAAUkG,gBACtBgH,YAAalN,EAAU4M,cAAclB,qCAIjB,CACtBsD,eAAgBkB,EAChBhB,aAAciB,EACdd,WAAY,CACVva,OAAQuZ,EACRoB,QAASnB,EACTsB,WAAYrB,gHAUEgC,wCAAb,WACLL,EACAC,EACA9B,EACAC,EACAC,0FAE8BL,EAAW+B,YACvCC,EACAC,EACA9B,EACAC,EACAC,iBAEIiC,EAAiBhR,KAAKE,kBACtB8O,EAAmBzR,OAAOC,KAAKwT,qBAE9B7T,EAAWC,SAAS4R,kHCjOViC,wBAQTC,EACAC,EACAC,uBAFAF,kBACAC,iCACAC,qCAL6B,6BAWhCC,0BAAA,2BACAC,8BAA+B,EACpCC,uBAAa,qGAAYC,EAAKC,sEAOzBC,yBAAA,WACLtP,QAAQ7J,6CACH+Y,8BAA+B,KAMzBG,+CAAN,kGACCE,EAAWC,aAGfxP,QAAQ7J,KAAK,oCAIPsZ,EAAc3a,KAAKga,eAAeY,eADpB5a,KAAKia,WAAWY,gBAAgBC,eAG9CH,EAAYI,+DAElB7P,QAAQ/J,MACN,6EAEF+J,QAAQ/J,qCAER+J,QAAQ7J,qCAAqCoZ,EAASO,kBAElDhb,KAAKoa,+BACPlP,QAAQ7J,oBACSrB,KAAKka,oEAEtBe,qBACE,qGAAYC,EAAKX,kEACgB,IAAjCva,KAAKka,kKC/CMiB,oCAKCpS,iCAAb,WAAmBqS,uFAClBX,EAAWC,aACyBzU,EAAWM,WACnD6U,iBADIC,kBAGwBjN,EAAUrF,MAAMsS,UAAxCC,SACNpQ,QAAQ7J,6BAA6BoZ,EAASO,kBAGxCjR,EAAoB,IAAIvE,IAAI,CAAC,uBACZ8V,qDAChBvR,EAAkBtE,IADduE,qCAED,IAAIJ,gBACRC,YAAU0R,mDACavR,iEAKxBwR,uBAAuBF,EAAgBG,0BAErCH,4GAGME,uBAAP,SAA8BC,QAE9BA,aAAkBjU,aAChB,IAAIoC,gBACRC,YAAU6R,gCACV,sEAKuBD,kBAAQ,KAAxB9L,aACmB,iBAAjBA,QACH,IAAI/F,gBACRC,YAAU8R,iCACV,uEAIEC,EAAcvV,OAAOC,KAAKqJ,MAG5BiM,EAAYpZ,OAASqZ,qBAAmBC,0BACpC,IAAIlS,gBACRC,YAAUkS,oDACWH,EAAYpZ,8CAA6CqZ,qBAAmBC,mCASrFjC,wCAAb,WACLlC,EACAC,EACAoE,iFAEMP,EAAS,IACRxZ,WAAPwZ,EACK9D,EAAiBjK,KAAI,SAACpE,UAAcA,EAAUqG,iBAEnD8L,EAAOxZ,WAAPwZ,EACK7D,EAAkBlK,KAAI,SAACpE,UAAcA,EAAUqG,iBAEpD8L,EAAOxZ,WAAPwZ,EACKO,EAAiBtO,KAAI,SAACpE,UAAcA,EAAUqG,iBAO7CsM,EAAU5V,OAAOC,KAAKwC,KAAKE,UAJV,CACrByS,OAAAA,cAI8BxV,EAAWC,SAASG,OAAOC,KAAK2V,uJC1D/CC,wBASOC,EAAwCC,+BAAxCD,WAAwCC,wBARvB,wBACU,IAAI3O,4BACF,IAAIA,IAQrDlL,MAAM4Z,KAERjR,QAAQ7J,gFAGH8a,uBAJiC,+BAanCE,MAAA,oCAGGC,EAA2B,OACYtc,KAAKuc,gCAAiB,eAAvDC,OAAgBC,OACtBA,EAAaC,iBACVC,mBAAmBhP,IACtB6O,EACAC,EAAaG,aAEfN,EAAyBra,KAAKua,GAG9BC,EAAa7b,yBAGY0b,sBACtBC,iCAIDM,EACJ7c,KAAKmc,uBAAyBnc,KAAKuc,gBAAgBO,QACjDD,GAA0B,YAKO,IAAjC7c,KAAK+c,iBAAiBva,kBAMxB,IAAIC,EAAI,EACRA,EAAIzC,KAAK+c,iBAAiBva,QAAUC,EAAIoa,EACxCpa,IACA,KACMga,EAAezc,KAAK+c,iBAAiBta,GAGtCzC,KAAKgd,cAAcP,QACnBF,gBAAgB5O,IAAI8O,EAAapY,OAAQoY,QAI3CM,iBAAiBE,OAAO,EAAGJ,GAChC,MAAO1b,GACP+J,QAAQ/J,8FACkFA,WAG1F8Z,qBAAW,qGAAYX,EAAK+B,oDAAS,SAQ5Ba,oCAAN,WACLC,EACAC,0FAEM/Y,EAASgZ,cAAmB,IAC5BC,EAAe,IAAIha,SAAQ,SAAC1C,GAShCsa,EAAK6B,iBAAiB9a,KARD,CACnBoC,OAAAA,EACA8Y,YAAAA,EACAC,eAAAA,EACAxc,QAAAA,EACA8b,WAAW,EACXa,aAAS1e,gBAKPye,gBAEAV,EAAc5c,KAAK2c,mBAAmB7O,IAAIzJ,QAC3CsY,0BAA0BtY,qBAExBuY,6GAUKI,yCAAN,WAAoBP,+EACtBU,EAAc,YAEhBA,EAAcV,EAAaU,qBAEDnd,KAAKoc,IAAIoB,KACjCL,UAIFV,EAAaG,mEAEb1R,QAAQ/J,6CACiCgc,+DAGzCV,EAAaC,WAAY,yICxJVe,wBA0BjBlO,EACAC,EACA0G,EACAC,EACAxG,EACAlG,QAEK8F,gBAAkBA,OAClB9P,KAAOmQ,gBAAc8N,YACrBlO,gBAAkBA,OAClB0G,cAAgBA,OAChBC,WAAaA,OACbxG,aAAeA,OACflG,MAAQA,WAMKkU,qDAAb,WACLvN,+EAEMb,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAUoH,aAC3BqN,EAAgBpN,YACtCD,EACAb,GACA,8IAQgBxG,iCAAb,WAAmBwG,iFAClBe,EAAsBf,EAAgB/L,oBACd4K,EAAUrF,MAAMuH,iBAAxCC,kBACwBkN,EAAgBpN,YAC5CE,EACAhB,GACA,8IAYgBc,uCAAb,WACLE,EACAhB,EACAqO,mFAEInN,EAAwB,EACxBmN,IACFnN,EAAwB,GAGPhU,OAAOgH,KAAK8M,GAChB/N,SAAWiO,wBAClB,IAAI7G,gBACRC,YAAUgU,mDAI4B,iBAA/BtN,EAAgB+F,iCACnB,IAAI1M,gBAAcC,YAAUiU,qDAG9B3H,EAAanC,EAAIgC,gBAAgBzF,EAAgBiG,uBACzBiH,EAAgBhH,uBAC5CN,EAAW7B,oBADPyJ,SAKFpO,OAAe9Q,EACf4K,OAAQ5K,EACP+e,sBACCrN,EAAgB9Q,OAASmQ,gBAAc8N,8BACnC,IAAI9T,gBAAcC,YAAUmU,6CAGpCrO,EAAeY,EAAgB9G,gBACjBgF,EAAeC,WAAWiB,WAAxClG,0CAGK,IAAIgU,EACTlO,EACAgB,EAAgB+F,WAChBH,EACA4H,EACApO,EACAlG,4GAIiBgN,kDAAb,WACNa,mFAEMV,EAAuB/J,UAAQiC,eACnCwI,YAEuBlJ,EAAUrF,MAAM6N,aAAnCT,SAGoB,IADP1Z,OAAOgH,KAAK0S,GAChB3T,6BACP,IAAIoH,gBACRC,YAAUoU,oEAId5M,EAAI6B,kBAAkBiD,EAAW+H,YAE3BhN,EAAarE,UAAQqC,eAAeiH,EAAWjF,YACrD9B,YAAUC,gDAAgD6B,qBAEnD,CACLA,WAAYiF,EAAWjF,WACvBgN,WAAY/H,EAAW+H,oHClKRC,wBAOD1G,EACAC,EACAsE,cAFAvE,yBACAC,wBACAsE,WAOEjT,iCAAb,WAAmBqV,2GAGKnY,EAAWM,WAAW6X,UAAjDC,8DAEMzU,gBAAc+L,gBAClB9L,YAAUyU,mEAOSlQ,EAAUrF,MAAMsV,WAArCE,iEAEM3U,gBAAc+L,gBAAgB9L,YAAU2U,6BAG1CzU,EAAoB,IAAIvE,IAAI,CAAC,SAAU,2BACtB+Y,qDAChBxU,EAAkBtE,uCACf,IAAImE,gBAAcC,YAAU4U,kEAItCN,EAAQO,uBAAuBH,EAAaI,kBAEbR,EAAQS,wBACrCL,EAAa5F,2BAETjB,GAHAsE,UAGqCtO,KACzC,SAACpE,UAAcA,EAAUkG,mBAGrBqP,EAAU,IAAIV,EAClBI,EACA7G,EACAsE,qBAEK6C,2HAMYD,mDAAb,WACNjG,wFAEmB9Z,IAAf8Z,2CACK,cAIiB,IADPlc,OAAOgH,KAAKkV,GAChBnW,6BACP,IAAIoH,gBACRC,YAAUiV,gEAIR9C,EAAsC,GACvCxU,MAAMC,QAAQkR,EAAWoG,8BACtB,IAAInV,gBAAcC,YAAUmV,4CAIZrG,EAAWoG,uDAAxBzV,oBACqBmU,EAAgBE,0BAC5CrU,WAEF0S,EAAiB/Z,+CAIbyV,EAAoBsE,EAAiBtO,KACzC,SAACpE,UAAcA,EAAUkG,oBAEvBpK,EAAaC,cAAcqS,0BACvB,IAAI9N,gBAAcC,YAAUoV,yEAG7BjD,uGAMM0C,uBAAP,SAA8BC,OAC/BnX,MAAMC,QAAQkX,SACX,IAAI/U,gBACRC,YAAUqV,gDAKQ,IAAlBP,EAAOnc,aACH,IAAIoH,gBACRC,YAAUsV,sDAMY,IADP1iB,OAAOgH,KADZkb,EAAO,IAENnc,aACP,IAAIoH,gBACRC,YAAUuV,4CAQIvF,wCAAb,WACLwF,EACAC,mFAEMtD,EAAmBsD,EAAqB5R,KAAI,SAACpE,SAC1C,CACLgN,WAAYhN,EAAUkG,gBACtBgH,YAAalN,EAAU4M,cAAclB,mBAInCuJ,EAA6B,CACjCI,OAAQ,CAAC,CAAEY,eAAgBF,KAIzBrD,EAAiBxZ,OAAS,IAC5B+b,EAAa5F,WAAa,CACxBoG,OAAQ/C,IAINC,EAAUnT,KAAKE,UAAUuV,YACCtY,EAAWC,SAASG,OAAOC,KAAK2V,oJC3J/CuD,wBACCxF,uBAAAA,qBAMPyF,oDAAN,WAA+BC,8FAChCC,OAA6C9gB,EAC3C+gB,EAA6D,OAEzCF,mBAAfG,WAEOC,kBAAoBH,IAClCC,EAAqC3d,KAAK,IAC1C0d,EAAyBE,EAAYC,iBAEvCF,EACEA,EAAqCpd,OAAS,GAC9CP,KAAK4d,GAGHE,EAA4C,SACnBH,kDACvBI,EAAsBhgB,KAAKga,eAAeiG,wBADvCC,QAEU,GAAGJ,2BAE4BE,EAAoBG,4BACpED,WAEFH,EAAsB9d,WAAtB8d,sEAEKA,+GClBUK,wBAoBTpG,EACAC,EACAkC,EACAkE,EACAC,EACAC,EACAC,uBANAxG,kBACAC,8BACAkC,sBACAkE,wBACAC,oCACAC,kCACAC,mCArB2B,mCAKoC,QAkBlEC,kBAAoB,IAAIjB,EAAkBxF,8BAGpC0G,uDAAN,4FAC6B1gB,KAAKsgB,iBAAiBK,iCAAnDC,mIAMMC,mDAAN,uGAEC7gB,KAAK0gB,qCAEXxV,QAAQ7J,mDACRgZ,uBAAa,4EACXC,EAAKwG,4BAA6B,EAGlCxG,EAAKyG,yKAQFC,uBAAA,WACL9V,QAAQ7J,uDACHyf,4BAA6B,KAOvBC,+CAAN,WACLE,2HAAAA,IAAAA,GAA6B,qBAGrBjhB,KAAKkhB,+CAIPC,GAAmB,gBAGfC,EAA6BphB,KAAK4gB,qBACpC5gB,KAAK4gB,qBAAqBS,uBAC1BxiB,EACEyiB,EAA+BthB,KAAK4gB,qBACtC5gB,KAAK4gB,qBAAqBW,yBAC1B1iB,EACE2iB,EAA2BxhB,KAAK4gB,qBAClC5gB,KAAK4gB,qBAAqBd,gBAC1B,EAEA2B,GAAqC,EACrCC,SACEjH,EAAWC,cAEfxP,QAAQ7J,KACN,6DAEIsgB,OAC2B9iB,IAA/BuiB,EACIA,EAA6B,OAC7BviB,YACamB,KAAKia,WAAWuD,KACjCmE,EACAL,WAFFI,SAIAxW,QAAQ7J,gBAEJqgB,EAAWhC,aAAald,4DAC2BiY,EAASO,0EAI9D4G,gBAAiBhY,iBACjBgY,KAAMC,OAASC,kBAAgBC,qDAE/B7W,QAAQ7J,mCACwB+f,mBAA2CE,mCAE3EG,GAAqC,oDAMnC/B,EAAegC,EAAaA,EAAWhC,aAAe,GAC5DyB,IAAmBO,GAAaA,EAAWP,2BACTnhB,KAAKygB,kBAAkBhB,yBACvDC,WAEFK,GAHIA,UAG0CiC,MAC5C,SACEC,EACAC,UAEOD,EAAEZ,kBAAoBa,EAAEb,yBAKTtB,oDAKnBoC,4BAA4BlgB,KAJ3BmgB,EAAsB,CAC1BvC,YAFOA,UAGPwC,iBAAkBC,8BAA4BC,WAG5CtB,oCACIjhB,KAAKwiB,mBAAmB3C,EAAauC,mCAGtCpiB,KAAKwiB,mBAAmB3C,EAAauC,sCAO1CK,GAA8B,EAC9BhB,IAEAD,GAA4BxhB,KAAKia,WAAWY,gBAAgBC,MAE5D2H,GAA8B,EAC9BtB,GAAmB,GAEnBjW,QAAQ7J,4IAQRohB,0BACFvX,QAAQ7J,iDACFrB,KAAK0iB,2DACT,kBAGFxX,QAAQ7J,oDACFrB,KAAK2iB,oCACXzX,QAAQ7J,2FAMFrB,KAAK0iB,2DACT1iB,KAAKmc,gCAMLuD,GAAgBA,EAAald,OAAS,SACnCoe,qBAAuBlB,EAAaA,EAAald,OAAS,eAE1D2e,2CAEHnhB,KAAKkhB,uDACXhW,QAAQ7J,KACN,8FAIIrB,KAAK4iB,gCAAgC3B,6DAE3C/V,QAAQ/J,4FAGR+J,QAAQ/J,qCAEJnB,KAAK8gB,6BACP5V,QAAQ7J,oBACSrB,KAAKwgB,0FAEtBvF,qBACE,qGAAYC,EAAK6F,kEACiB,IAAlC/gB,KAAKwgB,0KAMCkC,sFAAN,WACNG,uEAEO7iB,KAAKmiB,4BAA4B3f,OAASqgB,mCAEzC7iB,KAAKkhB,+DAGL,IAAI5d,SAAQ,SAAC1C,UAAYqa,WAAWra,EAAS,uKAUzCgiB,2DAAN,WACN3B,sGAAAA,IAAAA,GAA6B,GAEvBxG,EAAWC,aACsB1a,KAAKugB,6BAA6BuC,gDAAnEC,SACN7X,QAAQ7J,gBAEJ0hB,EAAyBvgB,iDACeiY,EAASO,kBAI/CgI,EAAgC,OACZD,8CAKxBC,EAA8B/gB,KAJxBmgB,EAAsB,CAC1BvC,YAFOA,UAGPwC,iBAAkBC,8BAA4BC,WAI5CtB,oCACIjhB,KAAKwiB,mBAAmB3C,EAAauC,mCAGtCpiB,KAAKwiB,mBAAmB3C,EAAauC,uCAKvCY,EAA8BxgB,OAAS,wBAExCC,EAAI,EAENA,EAAIugB,EAA8BxgB,QAClCwgB,EAA8BvgB,GAAG4f,mBAC/BC,8BAA4BW,WAE9BxgB,WAIFugB,EAA8B/F,OAAO,EAAGxa,aAGlC,IAAIa,SAAQ,SAAC1C,UAAYqa,WAAWra,EAAS,yIAQzCsgB,iEAAN,kFACFze,EAAI,cAENA,EAAIzC,KAAKmiB,4BAA4B3f,QACrCxC,KAAKmiB,4BAA4B1f,GAAG4f,mBAClCC,8BAA4BW,2CAExBjjB,KAAKsgB,iBAAiB4C,eAC1BljB,KAAKmiB,4BAA4B1f,GAAGod,oBAEtCpd,+BAIG0f,4BAA4BlF,OAAO,EAAGxa,0GAQ/B+f,8CAAN,WACN3C,EACAsD,0FAKQC,EAA8CpjB,KAAKga,eAAeqJ,wBACtExD,EAAYC,0BAE2BsD,EAAqBZ,mBAC5D3C,UADFyD,yDAIApY,QAAQ/J,6DACiD0e,EAAYwB,wBAErEnW,QAAQ/J,YACRmiB,GAAmC,uBAGnCpY,QAAQ7J,yCAC8Bwe,EAAYwB,wBAElD8B,EAA2Bd,iBACzBC,8BAA4BW,WAE1BK,0BACFpY,QAAQ7J,8BACmBwe,EAAYwB,6EAEjCrhB,KAAKugB,6BAA6BgD,8BACtC1D,0CAGF3U,QAAQ7J,6DACkDwe,EAAYwB,oCAEhErhB,KAAKugB,6BAA6BiD,0CACtC3D,wJASM8C,qDAAN,sGAEwC3iB,KAAKsgB,iBAAiBmD,mDAA9DC,kBAGwC1jB,KAAKia,WAAW0J,yBAC5DD,iBAGIE,OACgC/kB,KALhCglB,eAMAhlB,EACAglB,EAAgCxC,kBACtCnW,QAAQ7J,6CACkCuiB,GAI1C1Y,QAAQ7J,KAAK,qCACPrB,KAAKqgB,sBAAsBuD,4BAG3B5jB,KAAKsgB,iBAAiBwD,4BAC1BF,4BAEI5jB,KAAKugB,6BAA6BwD,wCACtCH,gBAIGhD,qBAAuBiD,6GCzYXG,oCAOCjb,iCAAb,WAAmBwG,iFAElBe,EAAsBf,EAAgB/L,WACtC+M,EAAkBzH,KAAKC,MAAMuH,GAE7B2T,GAAmB,GADnBC,EAAgB3T,EAAgB9Q,QAGhBmQ,gBAAcC,gDAC3BP,EAAgBe,YACrBE,EACAhB,EACA0U,cAEOC,IAAkBtU,gBAAc8N,iDAClCD,EAAgBpN,YACrBE,EACAhB,EACA0U,eAEOC,IAAkBtU,gBAAcsH,kDAClCD,EAAiB5G,YACtBE,EACAhB,EACA0U,eAEOC,IAAkBtU,gBAAcwG,qDAClCH,EAAoB5F,YACzBE,EACAhB,EACA0U,kBAGI,IAAIra,gBAAcC,YAAUsa,sIArCfH,8BAA8B,OCgClCI,oCAILC,mBAAP,eACCC,EAAejH,cAAmB,WACrBxQ,UAAQqD,OAAOd,YAAUa,KAAKqU,OAU/BC,2CAAb,WACL5c,EACAM,4FAEsCoJ,EAAIC,uCAAxBG,gBACZ+S,EAAiB,CACrB7c,GAAAA,EACAlI,KAAM,6BACNsI,SACAE,QAASA,GAAWxL,OAAO2D,OAAO8H,uCAG7B,CAACsc,EAAgB/S,yGAMNgT,2DAAb,WACLrU,wFAEkCgU,EAAmBM,0DAW9C,CACL5L,iBAZI6L,UAYiC7L,gBACrC8L,iBAAkBD,EAAoBC,iBACtCC,uBAZ6B,CAC7BplB,KAAMmQ,gBAAcC,OACpBL,gBAAiBmV,EAAoB7L,gBAAgBtJ,gBACrDD,gBAAiBoV,EAAoB7L,gBAAgBvJ,gBACrD8R,kBAAmBjR,EAAMiR,kBACzBvB,gBAAiB1P,EAAM0P,gBACvBgF,eAAgB1U,EAAM0U,gBAOtBC,kBAAmBJ,EAAoBI,kBACvCC,mBAAoBL,EAAoBK,mBACxCC,gBAAiBN,EAAoBM,gBACrCC,iBAAkBP,EAAoBO,iBACtCC,iBAAkBR,EAAoBQ,iBACtCC,kBAAmBT,EAAoBS,kBACvCC,mCACEV,EAAoBU,wIAONX,mDAAb,qHACCY,EAAe,sBAIXjU,EAAIC,uCAFZyT,gBACAC,gBAKQ3T,EAAIC,uCAFZ2T,gBACAC,iBAKQd,EAAmBG,gBAAgBe,kBAF3CH,gBACAC,OAEIvc,EAAUub,EAAmBmB,yBAAyB,CAC1D,mCAG6BnB,EAAmBoB,+BAChDT,EACAE,EACA,CAACE,GACDtc,kBAJI+b,SAOArV,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAU4b,cAErBtV,EAAgBvG,MAAMwG,kBAA9CuJ,SAEAuM,EAAqCjW,YAAUqW,+BACnDN,EAAiBpd,uBAEZ,CACL+Q,gBAAAA,EACA8L,iBAAAA,EACAG,kBAAAA,EACAC,mBAAAA,EACAC,gBAAAA,EACAC,iBAAAA,EACAC,iBAAAA,EACAC,kBAAAA,EACAC,mCAAAA,uGAOgBK,oDAAb,WACLtV,uGAEMuV,EAAkB,yBAIdtU,EAAIC,uCAFZsU,gBACAC,gBAKQzB,EAAmBG,gBAAgBoB,iBAF3CG,gBACAC,iBAEsC3B,EAAmBG,gBACzD,yBADKyB,YAGDC,EAAW7B,EAAmBmB,yBAAyB,CAC3D,mCAOQnB,EAAmBG,gBAAgB,6BAF3CrG,gBACAgH,iBAG0Bd,EAAmB8B,gCAC7C9V,EAAMZ,gBACNY,EAAM4U,mBACNY,EACAE,EACAG,EACA,CAACD,mBAGGzW,EAAkBlJ,OAAOC,KAAKwC,KAAKE,6BACViO,EAAiBlO,MAAMwG,oCAE/C,CACL0J,wBACA1J,gBAAAA,EACAwV,kBAAmBa,EACnBZ,mBAAoBa,EACpBV,iBAAkBW,EAClBV,kBAAmBW,EACnB7H,WAAAA,EACAgH,iBAAAA,wGAOgBiB,mDAAb,WACL3W,EACAyV,EACAC,uFAEMkB,4BAIIhC,EAAmBG,gBAAgB6B,iBAF3CC,gBACAC,gBAG0BlC,EAAmBmC,0CAC7C/W,EACAyV,EACAC,EACAmB,EACAjX,YAAUqW,+BAA+BY,kBAGrC9W,EAAkBlJ,OAAOC,KAAKwC,KAAKE,6BACXyU,EAAgB1U,MAAMwG,oCAE7C,CACLiX,uBACAjX,gBAAAA,EACA6W,gBAAAA,EACAC,oBAAAA,EACAC,qBAAAA,EACAG,cAAeJ,EAAoBte,8GAOzB2e,+CAAP,SACLC,EACA7G,EACAuB,EACAyD,SAEuD,CACrDtV,gBAAiBmX,EAAenX,gBAChC/P,KAAMknB,EAAelnB,KACrB8P,gBAAiBoX,EAAepX,gBAChCuV,eAAAA,EACAzD,kBAAAA,EACAvB,gBAAAA,MAQgB0F,0DAAb,WACLT,EACAE,EACA2B,EACAne,2FAOMiB,EAAU,CACd,CACEc,OAAQ,UACRzD,SAR4B,CAC9BQ,YAAaqf,EACbne,kBAAAA,KAUIgB,EAAQ,CACZ0F,kBAAmBC,YAAUqW,+BAC3BR,GAEFvb,QAAAA,GAGIkS,EAAcvV,OAAOC,KAAKwC,KAAKE,UAAUS,IACzCyH,EAAarE,UAAQqD,OAAOd,YAAUa,KAAK2L,IAE3ClM,EAAa,CACjBwB,WAAYA,EACZE,oBAAqBhC,YAAUqW,+BAC7BV,IAIEjU,EAA0BjE,UAAQqD,OAAOpH,KAAKE,UAAU0G,IACxDf,EAAqB9B,UAAQqD,OAAO0L,qBACxB,CAChBnc,KAAMmQ,gBAAcC,OACpBc,YAAaG,EACbrH,MAAOkF,8GASSkY,0DAAb,WAA4CrX,gGACzB3Q,IAApB2Q,IACFA,EAAkB4U,EAAmBC,+BAETD,EAAmBG,gBAC/C,+BAEInb,EAA2BgG,YAAUqW,yCAC3B1d,cAGiBqc,EAAmBG,gBADnB,2BAI3B7a,EAAU,CACd,CACEc,OAAQ,kBACRjD,YAAa,wBAOP6c,EAAmBG,gBAJR,kCAEnBY,gBACAC,iBAEoBhB,EAAmB0C,6BACvCtX,EACA2V,EAAiBpd,IACjBqd,EACAhc,EACAM,kBALIqd,SAQAC,EAAS3gB,OAAOC,KAAKwC,KAAKE,UAAU+d,cACZtJ,EAAgB1U,MAAMie,oCAE7C,CACLD,QAAAA,EACAC,OAAAA,EACAR,6HAOgBM,wDAAb,WACLtX,EACAyV,EACAC,EACA9b,EACAM,qFAMMmF,EAAkB/F,KAAKE,UAJf,CACZU,QAAAA,EACAyF,kBAAmB/F,IAGf8H,EAAarE,UAAQqD,OACzBd,YAAUa,KAAK5J,OAAOC,KAAKuI,KAEvBoY,EAAqBpa,UAAQqD,OAAOrB,GAEpCqY,EAA0B,CAC9BhJ,WAAY+G,EACZ/T,WAAYA,YAEWkT,EAAmB+C,iBAC1CD,EACAhC,mCAG6B,CAC7BzlB,KAAMmQ,gBAAc8N,OACpBpH,WAAY9G,EACZ/F,MAAOwd,EACPzQ,iIASgB0P,2DAAb,WACL1W,EACAwV,EACAY,EACAE,EACArd,EACAlB,+EAEMR,EAAW,CACfQ,YAAaA,EACbkB,kBAAmBA,YAEU2b,EAAmBgD,8BAChD5X,EACAwV,EACAY,EACAxW,YAAUqW,+BAA+BK,EAAoB/d,KAC7DhB,wJAQgBqgB,yDAAb,WACL5X,EACAwV,EACAY,EACAxc,EACArC,uFAcM6U,EAAcvV,OAAOC,KAAKwC,KAAKE,UALvB,CACZU,QARc,CACd,CACEc,OAAQ,UACRzD,SAAAA,IAMFoI,kBAAmB/F,KAIf8H,EAAarE,UAAQqD,OAAOd,YAAUa,KAAK2L,IAE3CsL,EAA0B,CAC9BhW,WAAYA,EACZ6F,aAAc1F,EAAIuC,uBAChBoR,GAEF5T,oBAAqBhC,YAAUqW,+BAC7BG,aAGqBxB,EAAmB+C,iBAC1CD,EACAlC,iBAFI7O,SAKAxH,EAAqB9B,UAAQqD,OAAO0L,qBACxB,CAChBnc,KAAMmQ,gBAAcsH,QACpBZ,WAAY9G,EACZgH,YAAaL,EACb1M,MAAOkF,gHASS0Y,4DAAb,WACL7X,EACAwV,+EAEMkC,EAA0B,CAC9B5Q,WAAY9G,EACZuH,aAAc1F,EAAIuC,uBAChBoR,aAGqBZ,EAAmB+C,iBAC1CD,EACAlC,mCAGgB,CAChBvlB,KAAMmQ,gBAAcwG,WACpBE,WAAY9G,EACZgH,0HAWgB8Q,yDAAb,WACLvC,EACAI,EACA1c,kFAEwB2b,EAAmBoB,+BACzCT,EACAI,EAAiBpd,IACjB,CAACod,GACD1c,mCAGKpC,OAAOC,KAAKwC,KAAKE,2HAMNud,qEAAb,WACL/W,EACAyV,EACAC,EACAqC,EACAne,+EAEMM,EAAU,CACd,CACEc,OAAQ,kBACRjD,YAAa,CAACggB,cAImBnD,EAAmB0C,6BACtDtX,EACAyV,EACAC,EACA9b,EACAM,sJASgB8d,uEAAb,WACLhY,EACAyV,EACAC,EACA9b,EACAqe,EACAC,iFAEMhe,EAAU,QAEiB7K,IAA7B4oB,IACIld,EAAQ,CACZC,OAAQ,wBACR/B,kBAAmB2b,EAAmBmB,yBAAyB,CAC7DkC,KAIJ/d,EAAQzH,KAAKsI,IAGXmd,EAA6BllB,OAAS,GAMxCkH,EAAQzH,KALM,CACZuI,OAAQ,2BACRyB,IAAKyb,aAM4BtD,EAAmB0C,6BACtDtX,EACAyV,EACAC,EACA9b,EACAM,wJASgByd,4CAAb,WACL7S,EACA7C,+EAEM4C,EAAkB,CACtBO,IAAK,kBAGkBZ,EAAI6B,iBAC3BvB,EACA7C,EACA4C,gJAQgBsT,qDAAb,WACLnY,EACAwV,0FAE+BZ,EAAmBiD,iCAChD7X,EACAwV,iBAFIJ,SAIArV,EAAkBlJ,OAAOC,KAAKwC,KAAKE,UAAU4b,aACjB3O,EAAoBlN,MACpDwG,mCAGK,CACLqV,iBAAAA,EACArV,gBAAAA,EACA6J,kIAQUmM,yBAAP,SAAgCtZ,aAC/BxD,EAAoB,OACTwD,kBACfxD,EAAkBxG,KAAK,CACrB0F,WACAlI,KAAM,WACNkJ,SAAU,+BAGPF,QC5nBUmf,wBAET5N,EACAqG,uBADArG,sBACAqG,6BAQGzf,mCAAN,WAAc4O,uFACnBtE,QAAQ7J,qCAAqCmO,mBAEpBxP,KAAKqgB,eAAevS,IAAI0B,iBAC3CqY,EAAmBD,EAASE,4CAGb9nB,KAAK+nB,qBACxBF,EAAiBlQ,iCAIF9Y,KALb8H,yDAMK9H,kBAIHmpB,EAAiCH,EAAiBjQ,kBAAkBqQ,OACxEJ,EAAiBhQ,gCAE6B7X,KAAKkoB,yCACnDF,kBADIG,mBAGWnoB,KAAKooB,oCACpBzhB,EACAwhB,mBAI0CtpB,KAN5C8H,UAMaE,qEACJF,4BAIqC3G,KAAKkoB,yCACjDL,EAAiB7L,iCADbqM,mBAGWroB,KAAKsoB,sBACpB3hB,EACA0hB,oCAFF1hB,mHAQamhB,2BAAP,SACNnP,aAOMhB,EAAmB,GACnBC,EAAoB,GACpBoE,EAAmB,GACnBnE,EAAuB,OAELc,kBAAY,KAAzBrP,UACLA,EAAU7J,OAASmQ,gBAAcC,OACnC8H,EAAiB1V,KAAKqH,GACbA,EAAU7J,OAASmQ,gBAAcsH,QAC1CU,EAAkB3V,KAAKqH,GACdA,EAAU7J,OAASmQ,gBAAc8N,OAC1C1B,EAAiB/Z,KAAKqH,GAGtBuO,EAAqB5V,KAAKqH,SAGvB,CACLqO,iBAAAA,EACAC,kBAAAA,EACAoE,iBAAAA,EACAnE,qBAAAA,MAOUkQ,gDAAN,WACNpQ,kFAI8BA,kDAAnBmB,mBACQ9Y,KAAKuoB,eAAezP,OAAiBja,kBAGrCA,KAHjB8H,6GAQKA,4GAMKyhB,+DAAN,WACNI,EACAC,4EAEI9hB,EAAW6hB,aAGbC,EAA0BhjB,IAAIkB,EAASE,oDAOvC6hB,GALIA,EAA6DD,EAA0B3a,IACzFnH,EAASE,6BAIyDmb,MAClE,SAACC,EAAGC,UAAMD,EAAEZ,kBAAoBa,EAAEb,8BAKdrhB,KAAK2oB,yBACzBD,EACA/hB,kBAIkB9H,KARd+pB,qEAgBsC/pB,KAH5C8H,EAAWiiB,GAGE/hB,qEACJF,2DAIJA,8GAMK2hB,iDAAN,WACNE,EACAC,4EAEI9hB,EAAW6hB,aAERC,EAA0BhjB,IAAIkB,EAASyC,kDAM5Csf,GALIA,EAA6DD,EAA0B3a,IACzFnH,EAASyC,2BAIyD4Y,MAClE,SAACC,EAAGC,UAAMD,EAAEZ,kBAAoBa,EAAEb,8BAKdrhB,KAAK2oB,yBACzBD,EACA/hB,kBAIkB9H,KARd+pB,6DAaNjiB,EAAWiiB,kDAGNjiB,8GASK4hB,0CAAN,WACNjf,EACA3C,iFAEIkiB,EAAkBliB,WAIdmiB,EAAqB9oB,KAAKga,eAAe+O,sBAC7Czf,EAAUwW,0BAGYgJ,EAAmBE,MACzC1f,EACAuf,UAFFA,yDAKA3d,QAAQwK,qCAC2BpM,EAAUkG,4BACzClG,EAAUwW,4BACAlW,gBAAcZ,kDAIvB6f,sHAMKF,oDAAN,WACNhQ,EACAsQ,8EAEIL,EAAcK,MAGMtQ,kDAAbrP,mBACYtJ,KAAKuoB,eAAejf,EAAWsf,cAApDA,UAIcM,iCACZD,EAAiBC,wEAEVN,+DAKJ/pB,8GAOKqpB,oEAAN,WACNiB,wFAEMV,EAA4B,IAAIhb,QAMHzN,KAAKga,eACrCoP,oEACQC,cACeF,kDAChBL,EAAqB9oB,KAAKga,eAAe+O,uBADtCzf,WAEGwW,2BAEoBgJ,EAAmBQ,eACjDhgB,WAGIigB,EAAoBna,YAAUoa,sBAElCH,GAGEZ,EAA0BhjB,IAAI8jB,GAChCd,EAA0B3a,IAAIyb,GAAoBtnB,KAAKqH,GAEvDmf,EAA0B9a,IAAI4b,EAAmB,CAACjgB,mFAKjDmf,+GCxSUgB,wBAIPC,QACLA,YAAcA,qBAMdC,kBAAA,iBACE,CACL3mB,KAAMhD,KAAK0pB,YACXE,QAASH,EAAoBI,YAAYD,eAbrBH,cAAczjB,QAAQ,uBCD3B8jB,oCAWLC,6BAAP,SACLC,EACAC,MAEIA,GAAsB,QAClB,IAAIrgB,gBACRC,YAAUqgB,2FACsDD,UAY7CE,KAAKC,IAP1BJ,EACAnO,qBAAmBwO,yCACyBJ,EAKOD,MAczCM,oCAAP,SACLC,EACAN,EACAD,MAGIC,GAAsB,QAClB,IAAIrgB,gBACRC,YAAUqgB,wDACmBD,gCAI7BM,EAAqBP,QACjB,IAAIpgB,gBACRC,YAAU2gB,gEACcD,6DAA6EP,OAKnGS,EACJT,EACAnO,qBAAmBwO,4CAHSE,EAAqBN,EAKvBQ,QACpB,IAAI7gB,gBACRC,YAAU6gB,kDACcH,gCAAgDN,yBAAyCQ,aClEpGE,oCAQLC,sCAAP,SACLC,EACAC,WAEsBjsB,IAAlBgsB,SACKhP,qBAAmBkP,4CAGtBC,EAAkBF,EAAuBG,mBAC7CJ,EAAcK,qBAmBVC,EAAwBhB,KAAKiB,MALjCP,EAAcQ,cAFdR,EAAcb,cATdgB,EAAgBX,yCAEhBW,EAAgBM,uCAiBXnB,KAAKC,IACVe,EACAtP,qBAAmBkP,4CAcTQ,gCAAP,SACLV,EACAZ,EACAuB,EACAC,EACAX,QAIEb,GACApO,qBAAmBkP,6CAKjBF,EAAe,IAEbA,EAAca,QAAUD,QACpB,IAAI7hB,gBACRC,YAAU8hB,wFACsBF,oBAA2CZ,EAAca,UAM3FF,EAA0BX,EAAcK,qBACxCM,GAA2BX,EAAce,4BAEnC,IAAIhiB,gBACRC,YAAUgiB,oFAEqBL,wBAA6CX,EAAcK,sCAAqCL,EAAce,2BAK7IE,EAAwB9rB,KAAK4qB,sCACjCC,EACAC,MAGEb,EAAqB6B,QACjB,IAAIliB,gBACRC,YAAUkiB,6EACoBD,6BAAgD7B,UCrFjE+B,wBAETC,EACA5L,EACApG,EACA6Q,wBAHAmB,sBACA5L,kBACApG,8BACA6Q,6BAGGtI,8CAAN,WACL3C,gGAIQqM,EAAeC,yBAAuBC,YAC1CvM,EAAYwM,cAIdvC,EAAWQ,oCACTzK,EAAY0K,mBACZ2B,EAAajC,mBACbpK,EAAYyM,mCAIWtsB,KAAKusB,4BAC5B1M,EACAqM,EAAaM,eACbN,EAAajC,kCAHT3Q,kBAOgBtZ,KAAKysB,yBACzBnT,EACA4S,EAAajC,kCAFTpL,mBAMuB7e,KAAK0sB,2BAA2B7N,kBAAvD8N,mBAGmB3sB,KAAK4sB,+BAC5B/M,EACAvG,EACAuF,EACA8N,kBAJIhU,mBAQA3Y,KAAKqgB,eAAewM,IAAIlU,qCAEvB,0CAEHmU,gBAAiBljB,qCAGjBkjB,KAAMjL,OAAShY,YAAUkjB,iBACzBD,KAAMjL,OAAShY,YAAUmjB,2DAElB,kBAGT9hB,QAAQ7J,wBAAwByrB,KAAMG,4BAC/B,kBAEP/hB,QAAQ/J,4EACgE2rB,KAAMG,4BAEvE,qHAQCV,uDAAN,WACN1M,EACA2M,EACAU,iFAGIA,EAAqBrR,qBAAmBsR,6CACpC,IAAIvjB,gBACRC,YAAUujB,yEACYF,8CAA8DrR,qBAAmBsR,yCAI3GjiB,QAAQ7J,iCACsBmrB,4BAAwC3Q,qBAAmBwR,+CAGhErtB,KAAKstB,oBAC5Bd,EACA3Q,qBAAmBwR,wCAFfE,kBAImB/V,EAAWzO,MAAMwkB,gBAEpCC,GAFAlU,UAEwC5B,kBAAkBlV,QAC/B0qB,0BACzB,IAAItjB,gBACRC,YAAU4jB,6DACSD,yCAAiEN,eAKlE5T,EAAW7B,MAAMa,iDAC7BtY,KAAKia,WAAWyT,iBAAiBpU,EAAW7B,MAAMa,sEACxDzZ,iBACJ8rB,EAAsBY,qCAEpB2B,EACArN,EAAYC,gBACZD,EAAY8N,OACZ3tB,KAAK8qB,0CAGAxR,gHAYKmT,oDAAN,WACNnT,EACA4T,4FAGQjV,EAAkBqB,EAAW7B,MACnCvM,QAAQ7J,8BACmB4W,EAAgBO,uCAAsCqD,qBAAmB+R,sCAG3E5tB,KAAKstB,oBAC5BrV,EAAgBO,aAChBqD,qBAAmB+R,qCAFfL,kBAIgBpP,EAAQpV,MAAMwkB,iBAA9B1O,UAQ+B7C,iBACjC6C,EAAQ7C,iBAAiBxZ,OACzB,GALF0qB,EAFiC5T,EAAW5B,kBAAkBlV,uDASvD3D,cAKNuG,EAAaO,qBACZ2T,EAAW5B,kBACXmH,EAAQnH,kEAGH7Y,oCAGFggB,0CAEHgP,gBAAiBjkB,qCAGjBikB,KAAMhM,OAAShY,YAAUkjB,iBACzBc,KAAMhM,OAAShY,YAAUmjB,kFAKpBnuB,kBAEPqM,QAAQ/J,4CAEJmY,EAAW7B,MAAMe,4CACY5O,gBAAcZ,wCAExCnK,uHAcC6tB,sDAAN,WACN7N,kFAGgBhgB,IAAZggB,gDACKhgB,0BAKPwgB,EAAgBR,EAAQpH,MAAMkH,OAAO,GAAGY,eACxCrU,QAAQ7J,gCACqBge,uBAAkCxD,qBAAmBiS,wCAGzD9tB,KAAKstB,oBAC5BjO,EACAxD,qBAAmBiS,uCAFfP,mBAIuBpS,EAAUpS,MAAMwkB,mFAIzCQ,gBAAiBnkB,qCAGjBmkB,KAAMlM,OAAShY,YAAUkjB,iBACzBgB,KAAMlM,OAAShY,YAAUmjB,kFAKpBnuB,kBAEPqM,QAAQ/J,8CACkCke,iCAA4CzV,gBAAcZ,wCAI7FnK,qHAKC+tB,0DAAN,WACN/M,EACAvG,EACAuF,EACAmP,iHAGMpW,EAAoB0B,EAAW1B,kBAC/BC,EAAuByB,EAAWzB,qBAClCmE,EACJ6C,GAAWA,EAAQ7C,iBAAmB6C,EAAQ7C,iBAAmB,IAG7DrD,EAAa,IACR1W,WAAX0W,EARMhB,EAAmB2B,EAAW3B,kBASpCgB,EAAW1W,WAAX0W,EAAmBf,GACnBe,EAAW1W,WAAX0W,EAAmBqD,GACnBrD,EAAW1W,WAAX0W,EAAmBd,GAIboW,EAAoC,QACxBpvB,IAAdmvB,mBAIIE,EACJvW,EAAiBnV,OACjBoV,EAAkBpV,OAClBwZ,EAAiBxZ,OAEbC,EAAI,eACRA,EAAIyrB,GAAsCzrB,EAAIurB,EAAUvS,OAAOjZ,gCAIzD8N,GADAhH,EAAYqP,EAAWlW,IACS8M,gBAAgB/L,qBACxB4K,EAAUrF,MAAMuH,YAAxCC,UACU9Q,KAAO6J,EAAU7J,KACjC8Q,EAAgB9G,MAAQukB,EAAUvS,OAAOhZ,GAEnC0rB,EAAyB9nB,OAAOC,KACpCwC,KAAKE,UAAUuH,IAEjB0d,EAAwBhsB,KAAKksB,WAX7B1rB,4BAeKA,EAAI,eAAGA,EAAIoV,EAAqBrV,gCAEjC8N,GADAhH,EAAYuO,EAAqBpV,IACD8M,gBAAgB/L,qBACxB4K,EAAUrF,MAAMuH,YAAxCC,UACU9Q,KAAO6J,EAAU7J,KAE3B0uB,EAAyB9nB,OAAOC,KACpCwC,KAAKE,UAAUuH,IAEjB0d,EAAwBhsB,KAAKksB,WATkB1rB,gCAa3C2rB,EAA0B,GACvB3rB,EAAI,EAAGA,EAAIkW,EAAWnW,OAAQC,IAYrC2rB,EAAwBnsB,KAT+B,CACrDuN,iBAHIlG,EAAYqP,EAAWlW,IAGA+M,gBAC3B/P,KAAM6J,EAAU7J,KAChB8P,gBAAiB0e,EAAwBxrB,GACzCqiB,eAAgBriB,EAChB4e,kBAAmBxB,EAAYwB,kBAC/BvB,gBAAiBD,EAAYC,2CAK1BsO,6GAGKd,+CAAN,WACNe,EACAC,+EAEApjB,QAAQ7J,0BACegtB,uBAA6BC,kBAGtBtuB,KAAKisB,gBAAgB/O,SACjDmR,EACAC,cAFIC,UAKc1M,OAAS2M,kBAAgBC,kCACrC,IAAI7kB,gBACRC,YAAU6kB,kCACIL,sCAIdE,EAAgB1M,OAAS2M,kBAAgBG,sCACrC,IAAI/kB,gBACRC,YAAU+kB,yBACDP,kCAAwCC,uBAIjDC,EAAgB1M,OAAS2M,kBAAgBK,gCACrC,IAAIjlB,gBACRC,YAAUilB,8BACIT,0DAIdE,EAAgB1M,OAAS2M,kBAAgBzB,uCACrC,IAAInjB,gBACRC,YAAUkjB,+CACqBsB,mBAI/BE,EAAgB1M,OAAS2M,kBAAgBO,gCACrC,IAAInlB,gBACRC,YAAUmjB,yBACDqB,iCAIbnjB,QAAQ7J,cACGgtB,eACPE,EAAgBhR,QAAS/a,yCAItB+rB,EAAgBhR,uHCvYNyR,wBAGQ1O,yBAAAA,OACpB2O,8BACHpT,qBAAmBqT,6CAChBC,gCACHtT,qBAAmBuT,4CAGRC,4BAAP,kBASC,IAAIC,EAAc,CAAEC,WARR,SAACtN,EAAqBC,UAGrCD,EAAEsI,mBAAqBrI,EAAEqI,oBACzBrI,EAAEb,kBAAoBY,EAAEZ,iDAYjBlB,uDAAN,WACLT,iFAEKA,EAAald,gDACT,kBAGHgtB,EAA4BR,EAAoBK,8BAItDL,EAAoBS,qBAClB/P,EAHIC,EAAyBD,EAAa,GAAGI,iBAM/CkP,EAAoBU,sCAClBhQ,EACAC,EACA6P,YAMQxvB,KAAK2vB,6DACbhQ,iBAOIiQ,EAAuBZ,EAAoBa,oDAJ/C7vB,KAAKivB,4CAELjvB,KAAKmvB,qCAKLK,qBAGKI,4GAGMH,qBAAP,SACN/P,EACAC,iBAE0BD,6BAERI,kBAAoBH,QAC5B,IAAI/V,gBACRC,YAAUimB,2BACV,0FAMOJ,sCAAP,SACNhQ,EACAC,EACA6P,aAEMO,EAA+B,IAAItiB,QAEfiS,kBAAc,KAA7BG,aAELkQ,EAA6BtqB,IAAIoa,EAAY8N,QAAS,KAClDqC,EAA4BD,EAA6BjiB,IAC7D+R,EAAY8N,QAGdziB,QAAQ7J,wDAC6Cse,kBAAsCE,EAAY8N,oCAAmCqC,mBAA0CnQ,EAAYwB,wBAGhMmO,EAA0BvtB,KAAK4d,GAC/BkQ,EAA6BpiB,IAC3BkS,EAAY8N,OACZ9N,EAAYwB,uBAMNsO,wFAAN,WACN7P,kGAE2B9f,KAAKsgB,iBAAiB2P,4BAC/CnQ,EACAA,aAEEmK,EAAqB,EAJnBvK,iBAMsBA,kBAAc,CAA7BG,cAEDqQ,EAAsC/D,yBAAuBC,YACjEvM,EAAYwM,cACZpC,mBACFA,GAAsBiG,EACtB,MAAOC,GACPjlB,QAAQklB,8CACkCtnB,KAAKE,UAC3CmnB,EACA1zB,OAAO4zB,oBAAoBF,KAG/BjlB,QAAQ7J,uCAC4Bwe,EAAYwM,uEAM/C,CAACpC,EADqBvK,EAAeA,EAAald,OAAS,4GAOrDqtB,oDAAP,SACNS,EACAC,EACAf,WAEIgB,EAAyB,EACvBZ,EAAuB,GAG3BA,EAAqBptB,OAAS+tB,GAC9BC,EAAyBF,GACzBd,EAA0BhtB,OAAS,GACnC,KACMiuB,EAAqBjB,EAA0B5rB,WAKnD4sB,GAH4CrE,yBAAuBC,YACjEqE,EAAmBpE,cACnBpC,qBAE4BqG,GAC5BV,EAAqB3tB,KAAKwuB,GAE5B,MAAON,GACPjlB,QAAQklB,8CACkCtnB,KAAKE,UAC3CmnB,EACA1zB,OAAO4zB,oBAAoBF,KAG/BjlB,QAAQ7J,uCAC4BovB,EAAmBpE,sCAMpDuD,QC9LUc,eACnBA,YAC0BC,EAAMC,IAAI,WAGtBF,QAAQC,EAAME,MAGdH,SAASC,EAAMG,WCcVC,wBAETC,EACA/W,EACAmC,EACA0O,uBAHAkG,kBACA/W,WACAmC,8BACA0O,6BAGG/P,iCAAN,sIACuB/a,KAAKia,WAAWgX,OAC1CjxB,KAAKia,WAAWY,gBAAgBC,oBAD5BkP,kBAGoBhqB,KAAKia,WAAWiX,uCACpCC,EAAqBnxB,KAAKoxB,6BAD1BC,mBAIyBrxB,KAAKgxB,eAAeM,KAAKH,aAClDlH,GADAsH,UACsC/uB,OAGZ,IAA5B+uB,EAAiB/uB,+BACnB0I,QAAQ7J,yEAIV6J,QAAQ7J,KACNqvB,EAASc,0BACSd,EAASG,SAAS5G,eAIR3mB,QAAQmuB,IACpCF,EAAiB7jB,+BAAI,WAAOgkB,2FAC1B1N,EAAUjb,MAAM2oB,EAAgBniB,oIAG9BoI,GALAga,UAKmCzjB,QACvC,SAAC5E,UAAcA,EAAU7J,OAASmQ,gBAAcC,UAE5C+H,EAAoB+Z,EAAgBzjB,QACxC,SAAC5E,UAAcA,EAAU7J,OAASmQ,gBAAcsH,WAE5C8E,EAAmB2V,EAAgBzjB,QACvC,SAAC5E,UAAcA,EAAU7J,OAASmQ,gBAAc8N,UAE5C7F,EAAuB8Z,EAAgBzjB,QAC3C,SAAC5E,UAAcA,EAAU7J,OAASmQ,gBAAcwG,wBAKpB+E,EAAUtB,aACtClC,EACAC,EACAoE,kBAHIZ,mBAOsBpb,KAAKoc,IAAIrB,MAAMK,kBAArCiE,SACNnU,QAAQ7J,KACNqvB,EAASc,8BACad,EAASG,MAC3BxR,gDAMsBlB,EAAQtE,aAClCwF,EACArD,kBAFIoC,mBAIoBpe,KAAKoc,IAAIrB,MAAMqD,kBAAnC3E,SACNvO,QAAQ7J,KACNqvB,EAASc,4BACWd,EAASG,MACzBpX,sCAMAD,EAAe6X,EAAcA,EAAYO,gBAAa/yB,YAC7B2Y,EAAWqC,aACxCL,EACAC,EACA9B,EACAC,EACAC,kBALIC,mBAOuB9X,KAAKoc,IAAIrB,MAAMjD,kBAAtC0U,SACNthB,QAAQ7J,KACNqvB,EAASc,+BACcd,EAASG,MAC5BrE,sCAWAqF,EAA4B1F,yBAAuB2F,UALlB,CACrCtF,eAAAA,EACAvC,mBAAAA,IAMI8H,EAAMjI,EAAWC,6BACrBC,EACAC,GAEF/e,QAAQ7J,KACNqvB,EAASc,yCACwBd,EAASG,MACtCgB,4BACwBnB,EAASG,SAASkB,eAI1C/xB,KAAKia,WAAWc,MAAM8W,EAA2BE,4BAGjD/xB,KAAKgxB,eAAegB,QAAQT,EAAiB/uB,gHAG7C4uB,6BAAA,SACNvG,OAEMoH,EACJpW,qBAAmBsR,sBACf+E,EAA8BvH,EAAsBC,sCACxDC,EACA7qB,KAAK8qB,+BAGHoH,EAA8BD,GAEhC/mB,QAAQ7J,iEACsD6wB,yDAAkFD,GAI3I9H,KAAKgI,IACVD,EACAD,SCvJeG,uDACNpJ,iCAAN,WACLnE,EACAle,kFAIe9H,IAAb8H,GACAke,EAAuBplB,OAASmQ,gBAAcC,qDAEvChR,aAGHwzB,EAAqC1rB,EACvCA,EAASuiB,oCACTrqB,EAGAgmB,EAAuBplB,OAASmQ,gBAAcC,uCACxB7P,KAAK+nB,qBAC3BlD,EACAle,UAFFkiB,mCAIShE,EAAuBplB,OAASmQ,gBAAc8N,yCAC/B1d,KAAKqJ,qBAC3Bwb,EACAle,WAFFkiB,oCAIShE,EAAuBplB,OAASmQ,gBAAcsH,0CAC/BlX,KAAKsyB,sBAC3BzN,EACAle,WAFFkiB,oCAIShE,EAAuBplB,OAASmQ,gBAAcwG,6CAC/BpW,KAAKuyB,yBAC3B1N,EACAle,WAFFkiB,uCAKM,IAAIjf,gBAAcC,YAAU2oB,yDAMZ3zB,IAApBgqB,GACAA,EAAgBK,iCACdmJ,GAMFnnB,QAAQklB,4CADgBvL,EAAuBrV,qCADhCqV,EAAuBxD,gCADzBwD,EAAuB/E,wCADtB+E,EAAuBC,oBAQvC,MAAO3jB,GACP+J,QAAQwK,sBAAsBvU,gCAIzB0nB,8GAGIS,0CAAN,WACLzE,6EAEIA,EAAuBplB,OAASmQ,gBAAcC,6BAC1C,IAAIjG,gBACRC,YAAU4oB,gFAIUzO,EAAUjb,MAChC8b,EAAuBtV,8BADnBjG,UAKY7J,mBACXmQ,gBAAcsH,iBAMdtH,gBAAc8N,iCAJjBgV,EAAoBC,oBAAkBC,qBADbtpB,EAEN6M,WAAWY,gCAEvB2b,kBAGPA,EAAoBC,oBAAkBC,qBADdtpB,EAEN6M,WAAW+H,8BAEtBwU,kBAIPA,EAAoBC,oBAAkBC,qBADVtpB,EAEN6M,WAAWY,gCAE1B2b,uGAOC3K,gDAAN,WACNlD,EACAle,oFAGiB9H,IAAb8H,2CACKA,0BAGe2I,EAAgBvG,MACtC8b,EAAuBtV,2BAIDH,YAAUyjB,aAL5BvpB,UAMMqG,aACVrG,EAAUoG,WAAWwB,qDAGdvK,UAIH8C,EAAQH,EAAUG,MACpB1C,EAAW,kBAEClI,IAAV4K,IACF1C,EAAWN,EAAiB+C,aAAazC,EAAU0C,EAAMC,oEAK3DwB,QAAQklB,8DADkBvL,EAAuBxD,8BADzBwD,EAAuBrV,qBAG4D5F,gBAAcZ,uCAMlHrC,oCAGW,CAClB6I,gBAAiBlG,EAAUkG,gBAC3BzI,SAAAA,EACAF,2BAA4ByC,EAAUoG,WAAW0B,oBACjDhI,yBAA0BK,EAAQA,EAAM0F,uBAAoBtQ,EAC5DqqB,+BAAgCrE,EAAuBxD,yIAS7ChY,gDAAN,WACNwb,EACAle,0FAEwB8W,EAAgB1U,MACtC8b,EAAuBtV,2BAIAH,YAAU0jB,uBAL7BxpB,UAMM6M,WAAW+H,WACrBvX,EAASyC,mEAIFzC,0BAIsB2C,EAAU4M,cAAchB,gBACrD5L,EAAU6M,WAAW+H,uEAIdvX,cAIYyI,YAAUyjB,YAC7BvpB,EAAUqG,aACVrG,EAAU6M,WAAWjF,sDAIdvK,sCAKmBF,EAAiB4C,qBACzCC,EACA3C,EAASI,kBAFXgsB,mEAOA7nB,QAAQklB,8DADkBvL,EAAuBxD,8BADzBwD,EAAuBrV,qBAG4D5F,gBAAcZ,uCAMlHrC,oCAGW,CAClBE,2BAA4BF,EAASE,2BAErCE,SAAUgsB,EACV3pB,yBAA0BE,EAAUG,MAAO0F,kBAC3C+Z,+BAAgCrE,EAAuBxD,yIAS7CiR,iDAAN,WACNzN,EACAle,4FAEwBsQ,EAAiBlO,MACvC8b,EAAuBtV,2BAIEH,YAAU0jB,uBAL/BxpB,UAMM6M,WAAWY,aACrBpQ,EAASE,qEAGFF,0BAIsB2C,EAAU4M,cAAchB,gBACrD5L,EAAU6M,WAAWY,yEAGdpQ,cAIeyI,YAAUyjB,YAChCvpB,EAAUqG,aACVrG,EAAU6M,WAAWjF,sDAGdvK,WAIH8C,EAAQH,EAAUG,MACpB1C,EAAW,kBAEClI,IAAV4K,IACF1C,EAAWN,EAAiB+C,aAAazC,EAAU0C,EAAMC,oEAK3DwB,QAAQklB,8DADkBvL,EAAuBxD,8BADzBwD,EAAuBrV,qBAG4D5F,gBAAcZ,uCAMlHrC,oCAGW,CAClB6I,gBAAiBlG,EAAUkG,gBAC3BzI,SAAAA,EACAgQ,aAAczN,EAAU6M,WAAWY,aACnClQ,2BAA4ByC,EAAU6M,WAAW/E,oBACjDhI,yBAA0BK,EAAQA,EAAM0F,uBAAoBtQ,EAC5DqqB,+BAAgCrE,EAAuBxD,yIAS7CkR,oDAAN,WACN1N,EACAle,wFAEwBsP,EAAoBlN,MAC1C8b,EAAuBtV,2BAIEH,YAAU0jB,uBAL/BxpB,UAMM6M,WAAWY,aACrBpQ,EAASE,qEAGFF,0BAIsB2C,EAAU4M,cAAchB,gBACrD5L,EAAU6M,WAAWY,yEAGdpQ,oCAIW,CAClBI,SAAUJ,EAASI,SAEnBgQ,kBAAclY,EACdgI,gCAA4BhI,EAC5BuK,8BAA0BvK,EAC1BqqB,+BAAgCrE,EAAuBxD,6HCrVxC2R,yBAoBCpsB,EAAaqsB,QAC1BA,cAAgBA,MACfC,SAAmBD,UAEpBrsB,EAAIusB,WAAWD,SACZ,IAAItpB,gBAAcC,YAAUupB,wBAG9BC,EAA0BzsB,EAAI0sB,QAAQ,aAGrCC,YADHF,EAA0B,OAOvBG,aADHxzB,KAAKuzB,YACa3sB,EAAI6sB,UAAUP,EAAU1wB,QAGxBoE,EAAI6sB,UACtBP,EAAU1wB,OACV6wB,GAI6B,IAA7BrzB,KAAKwzB,aAAahxB,aACd,IAAIoH,gBAAcC,YAAU6pB,wBAG/BC,UAAYT,EAAYlzB,KAAKwzB,sBAOhBp1B,kCAAb,WACLw1B,EACAX,gFAEMrsB,EAAM,IAAIosB,EAAIY,EAAWX,IAGtBM,oCACDM,EAAeb,EAAIc,6BACvBF,EACAX,YAE4BD,EAAIe,yCAChCF,aAOwCzkB,YAAUyjB,aAR9C/Z,UASYrJ,kBAChB7I,EAAI4sB,oCAKE,IAAI5pB,gBACRC,YAAUmqB,gDAIdptB,EAAIkS,gBAAkBA,mCAGjBlS,yGAGMktB,6BAAP,SACNF,EACAK,OAEIC,OAAer1B,MAEjBq1B,EAAe,IAAIznB,MAAImnB,GACvB,eACM,IAAIhqB,gBAAcC,YAAUsqB,6BAShCC,IAHEC,EAAaJ,EAAwBhtB,MAAM,KAAK,GAElDqtB,EAAoB,MAIGJ,EAAaK,6BAAc,eAA1Ch3B,OAAKC,WACf82B,GAAqB,GACG,QAChB,IAAI1qB,gBAAcC,YAAU2qB,wCAKhCj3B,QADoB82B,MAAcrB,EAAIyB,kCAElC,IAAI7qB,gBACRC,YAAU6qB,+CAIdN,EAAoB52B,UAGIqB,IAAtBu1B,QACI,IAAIxqB,gBAAcC,YAAU8qB,uCAG7BP,KAGYL,oEAAb,WACNF,kFAIyB,KADnBe,EAAkBf,EAAaP,QAAQ,4BAErC,IAAI1pB,gBAAcC,YAAUgrB,6CAGbhB,EAAaiB,YAAY,OACzBF,wBACf,IAAIhrB,gBACRC,YAAUkrB,sDAIVH,IAAoBf,EAAarxB,OAAS,GAAyB,IAApBoyB,wBAC3C,IAAIhrB,gBACRC,YAAUmrB,0DAIRC,EAAoBpB,EAAa5sB,MAAM,KAGvCiuB,EAAyB,CAC7Bz1B,KAAMmQ,gBAAcC,OACpBc,YAJiBskB,EAAkB,GAKnCxrB,MAJYwrB,EAAkB,IAM1BE,EAAwB9uB,OAAOC,KACnCwC,KAAKE,UAAUksB,cAEa5lB,EAAgBe,YAC5C6kB,EACAC,GACA,mJA9KoBnC,+BAA8B,oBCSnCoC,yBAITC,EACArE,EACAiC,iBAFAoC,sBACArE,qBACAiC,OAEHnK,mBAAqB,IAAIsJ,8BAMnBkD,kDAAN,WAA6BvO,uFAClC7b,QAAQ7J,2CACgC0lB,EAAQvkB,sCAMf4L,EAAUrF,MAAMge,cAAzCnC,UAIanlB,OAASmQ,gBAAcC,QACxC+U,EAAiBnlB,OAASmQ,gBAAcsH,SACxC0N,EAAiBnlB,OAASmQ,gBAAc8N,8BAElC9B,EAAcvV,OAAOC,KAAKse,EAAiBnb,QACjCjH,OAASqZ,qBAAmBC,4CACpCyZ,iCAA8C3Z,EAAYpZ,6BAA4BqZ,qBAAmBC,oBAC/G5Q,QAAQ7J,KAAKk0B,GACP,IAAI3rB,gBACRC,YAAU2rB,sCACVD,4BAKiBvR,EAAUjb,MAAMge,kBAAvCJ,mBAGU3mB,KAAKgxB,eAAeyE,SAAS9O,EAAenX,2DAE9C,IAAI5F,gBACRC,YAAU6rB,oGAFkE/O,EAAenX,oHAQ3Fsd,gBAAiBljB,yCACnBsB,QAAQ7J,qBAAqByrB,KAAMjL,MACnC3W,QAAQ7J,uBAAuByrB,KAAMG,2BAC9B,CACLnmB,OAAQ6uB,iBAAeC,WACvBC,KAAM,CAAEhU,KAAMiL,KAAMjL,KAAMoL,QAASH,KAAMG,0BAK7C/hB,QAAQ7J,6CACD,CACLyF,OAAQ6uB,iBAAeC,+BAKzB1qB,QAAQ7J,yBACcslB,EAAelnB,+BAA8BknB,EAAenX,0BAK1EmX,EAAelnB,mBAChBmQ,gBAAcC,iBAIdD,gBAAc8N,eACd9N,gBAAcsH,gBACdtH,gBAAcwG,gDALApW,KAAK81B,oBAAoBnP,kBAA1CoP,6CAMAA,EAAW,CACTjvB,OAAQ6uB,iBAAeK,wCAKzBD,EAAW,CACTjvB,OAAQ6uB,iBAAeC,WACvBC,KAAM,CACJhU,KAAMhY,YAAUosB,mCAChBhJ,uCAAwCtG,EAAelnB,uBAM3Ds2B,EAASjvB,SAAW6uB,iBAAeK,4CAC/Bh2B,KAAKgxB,eAAekF,QACxBvP,EAAenX,gBACfmX,EAAepX,kDAIZwmB,2CAGHjJ,gBAAiBljB,yCACnBsB,QAAQ7J,wBAAwByrB,KAAMjL,SAAQiL,KAAMG,2BAC7C,CACLnmB,OAAQ6uB,iBAAeC,WACvBC,KAAM,CAAEhU,KAAMiL,KAAMjL,KAAMoL,QAASH,KAAMG,0BAI7C/hB,QAAQ7J,kDACD,CACLyF,OAAQ6uB,iBAAeQ,wIAKfL,+CAAN,WACNnP,0FAEuB3mB,KAAK+nB,qBAAqBpB,kBAGhC9nB,KAHX8H,mDAIG,CACLG,OAAQ6uB,iBAAeC,WACvBC,KAAM,4CAKJ9uB,EAAWN,EAAiBC,4BAChCC,SAFiB3G,KAAKizB,kBAAiBtM,EAAenX,mCAMjD,CACL1I,OAAQ6uB,iBAAeK,UACvBH,KAAM9uB,4GAUGqvB,gDAAN,WACLC,4FAGEnrB,QAAQ7J,yCAAyCg1B,kBAE/BrD,GAAI50B,OAAOi4B,EAAoBr2B,KAAKizB,2BAAhDrsB,UAGE2sB,6CACWvzB,KAAKq1B,SAASz0B,QAAQgG,EAAI4sB,qBAA3C7sB,kDAEiB3G,KAAKs2B,mBAAmB1vB,WAAzCD,yBAGe9H,IAAb8H,4CACK,CACLG,OAAQ6uB,iBAAe5G,0BAIrBhoB,EAAWN,EAAiBC,4BAChCC,EACA0vB,qBAGK,CACLvvB,OAAQ6uB,iBAAeK,UACvBH,KAAM9uB,2CAIJ8mB,gBAAiBjkB,2DACZ,CACL9C,OAAQ6uB,iBAAeC,WACvBC,KAAM,CAAEhU,KAAMgM,KAAMhM,KAAMoL,QAASY,KAAMZ,0BAI7C/hB,QAAQ7J,kDACD,CACLyF,OAAQ6uB,iBAAeQ,gIASfG,8CAAN,WAAyB1vB,wFAEV5G,KAAKq1B,SAASz0B,QAAQgG,EAAI4sB,6BAG9B30B,KAHb8H,mDAIKA,0BAKQ3G,KAAK+nB,qBAAqBnhB,EAAIkS,iDAA/CnS,kHAKYohB,gDAAN,WACNjP,+EAEMyd,EAAgC,CACpC/mB,gBAAiBsJ,EAAgBtJ,gBACjC/P,KAAMmQ,gBAAcC,OACpBiQ,gBAAiB,EACjBuB,kBAAmB,EACnByD,eAAgB,EAChBvV,gBAAiBuJ,EAAgBvJ,0BAGTvP,KAAK8oB,mBAAmBE,MAChDuN,OACA13B,sJC7Pe23B,uEAMZC,6BACH5a,qBAAmB4a,+BAChBpM,yCACHxO,qBAAmBwO,2CAChBiB,8BACHzP,qBAAmByP,0HAXoBoL,2BC2BxBC,yBAgBTC,EACRC,eADQD,kCAdoC,QAkBvCE,8BAAgCD,EAAiB7U,MACpD,SAACC,EAAGC,UAAMA,EAAE6U,uBAAyB9U,EAAE8U,+BAGpCC,aAAe,IAAIvpB,SACnBwpB,oBAAsB,IAAIxpB,SAC1BypB,gBAAkB,IAAIzpB,SACtB0pB,gBAAkB,IAAI1pB,SACtB2pB,sBAAwB,IAAI3pB,SAC5B4pB,qBAAuB,IAAI5pB,SAC3B6pB,iBAAmB,IAAI7pB,+BAMjB8pB,sCAAN,WACLtd,EACAmC,EACA6P,EACA5L,EACAgV,EACA/U,gGAM8BtgB,KAAK82B,8EAC3BlN,UAA0BA,iBAGI5pB,KAAKw3B,6BACvC5N,EACA,uCAEIoH,EAAiB,IAJjByG,UAKJz3B,KAAK42B,OAAOc,wBACZ13B,KAAK42B,OAAOe,wBAER3G,EAAeuG,iCAChBL,gBAAgBvpB,IAAIic,EAASoH,aAGChxB,KAAKw3B,6BACtC5N,EACA,uCAEIxG,EAAuB,IAJvB4I,UAKJC,EACA5L,EACApG,EACAja,WAEGo3B,sBAAsBzpB,IAAIic,EAASxG,aAGNpjB,KAAKw3B,6BACrC5N,EACA,sCAEI5J,EAAsB,IAJtBgP,UAI8C1O,QAC/C+W,qBAAqB1pB,IAAIic,EAAS5J,aAGbhgB,KAAKw3B,6BAC7B5N,EACA,8BAEIjP,EAAc,IAJdoW,UAKJC,EACA/W,EACAmC,EACApc,WAEGg3B,aAAarpB,IAAIic,EAASjP,aAGE3a,KAAKw3B,6BACpC5N,EACA,qCAEId,EAAqB,IAJrBsJ,eAKD6E,oBAAoBtpB,IAAIic,EAASd,aAGT9oB,KAAKw3B,6BAChC5N,EACA,iCAEIgO,EAAiB,IAJjBxC,UAKJC,EACArE,EACAhxB,KAAK42B,OAAO3D,oBAETkE,gBAAgBxpB,IAAIic,EAASgO,aAGJ53B,KAAKw3B,6BACjC5N,EACA,+BAEIoB,EAAkB,IAJlBwL,qBAK2BE,iDACzB,IAAI9sB,gBACRiuB,gBAAcC,4GACmDlO,gBAGhE0N,iBAAiB3pB,IAAIic,EAASoB,kCAI/B+M,EAA+BvwB,MAAMlB,KACzCtG,KAAKs3B,iBAAiBl3B,UACtB,SAAC5C,UAAUA,EAAMi5B,qCAEdrN,2BAA6B5hB,MAAMlB,KACtC,IAAId,IAAIuyB,uHAOLnd,eAAA,SAAeod,OACdpO,EAAU5pB,KAAKi4B,iBAAiBD,GAChCrd,EAAc3a,KAAKg3B,aAAalpB,IAAI8b,WAEtB/qB,IAAhB8b,QACI,IAAI/Q,gBACRiuB,gBAAcK,sEACsBF,wBAIjCrd,KAMFoO,sBAAA,SAAsBiP,OACrBpO,EAAU5pB,KAAKi4B,iBAAiBD,GAChClP,EAAqB9oB,KAAKi3B,oBAAoBnpB,IAAI8b,WAE7B/qB,IAAvBiqB,QACI,IAAIlf,gBACRiuB,gBAAcM,oFAC6BH,wBAIxClP,KAMFsP,kBAAA,SAAkBJ,OACjBpO,EAAU5pB,KAAKi4B,iBAAiBD,GAChCJ,EAAiB53B,KAAKm3B,gBAAgBrpB,IAAI8b,WAEzB/qB,IAAnB+4B,QACI,IAAIhuB,gBACRiuB,gBAAcQ,4EACyBL,wBAIpCJ,KAMFvU,wBAAA,SACL2U,OAEMpO,EAAU5pB,KAAKi4B,iBAAiBD,GAChC5U,EAAuBpjB,KAAKo3B,sBAAsBtpB,IAAI8b,WAE/B/qB,IAAzBukB,QACI,IAAIxZ,gBACRiuB,gBAAcS,wFAC+BN,wBAI1C5U,KAMFnD,uBAAA,SAAuB+X,OACtBpO,EAAU5pB,KAAKi4B,iBAAiBD,GAChChY,EAAsBhgB,KAAKq3B,qBAAqBvpB,IAAI8b,WAE9B/qB,IAAxBmhB,QACI,IAAIpW,gBACRiuB,gBAAcU,sFAC8BP,wBAIzChY,KAGFiL,mBAAA,SAAmB+M,OAClBQ,EAAgBx4B,KAAKi4B,iBAAiBD,UACpBh4B,KAAKs3B,iBAAiBxpB,IAAI0qB,MAK7CC,kBAAA,SAAkBT,OACjBQ,EAAgBx4B,KAAKi4B,iBAAiBD,UACrBh4B,KAAKk3B,gBAAgBppB,IAAI0qB,MAQ1CP,iBAAA,SAAiBD,iBAEOh4B,KAAK82B,8CAA+B,KAAvD4B,aACLV,GAAkBU,EAAgB3B,8BAC7B2B,EAAgB9O,cAIrB,IAAIhgB,gBACRiuB,gBAAcc,yFACuCX,UAI3CR,wDAAN,WACN5N,EACAgP,qEAEgB,WAAZhP,wBACMgP,SACD,iCAEA,gCAEA,+BAEA,uBAEA,8BAEA,0BAEA,qEAXInB,yDAEAzL,mCAEAgD,mCAEA+B,mCAEAqB,oCAEAgD,qCAEAoB,+DAKC,mDAAqB5M,MAAWgP"}